{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of experiments-utk.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5Y7mt_du6-GR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Age, gender and race prediction from face images using Pytorch"
      ]
    },
    {
      "metadata": {
        "id": "nwEi5WszAVun",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this task we have some cropped face images, each image is associated with three labels : \n",
        "* Age\n",
        "* Gender : `Male` or `Female`\n",
        "* Race : `White`, `Black`,  `Asian`, `Indian` or `Other`\n",
        "\n",
        "So the objective is to train a model that can predict these three characteristics from face image. This is referred to as multistak learning as we have mutiple labels to predict for each image, and we'll use Pytorch for this purpose. So let's start!"
      ]
    },
    {
      "metadata": {
        "id": "0zcLiRsp6-GU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Install packages\n",
        "I Gathered all my preprocessing and model training utility functions/classes in a small package I called DEmoClassi (sorry for the name, my inspiration went away at that time 😜) which stands for **D**emographic (Age, gender, race) and **Emo**tion **Classi**fication.\n",
        "\n",
        "This package contains three modules : `emotion_detection`, `multitask_rag` and `vision_utils`."
      ]
    },
    {
      "metadata": {
        "id": "Xu3mPWMN_rNG",
        "colab_type": "code",
        "outputId": "7e2ad155-b645-47a5-aa58-f23e27b49934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade democlassi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting democlassi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/76/3fc98684bca77b7e28bd79a43cd327d76c6f337caff89584b8e44b4f470e/democlassi-0.4-py3-none-any.whl (10.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 10.1MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.6/dist-packages (from democlassi) (0.2.2.post3)\n",
            "Requirement already satisfied, skipping upgrade: dlib in /usr/local/lib/python3.6/dist-packages (from democlassi) (19.16.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from democlassi) (1.0.1.post2)\n",
            "Collecting pytorch-ignite (from democlassi)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/7b/1da69e5fdcb70e8f40ff3955516550207d5f5c81b428a5056510e72c60c5/pytorch_ignite-0.2.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 28.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: kaggle in /usr/local/lib/python3.6/dist-packages (from democlassi) (1.5.3)\n",
            "Requirement already satisfied, skipping upgrade: imutils in /usr/local/lib/python3.6/dist-packages (from democlassi) (0.5.2)\n",
            "Collecting tensorboardX (from democlassi)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 31.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->democlassi) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision->democlassi) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->democlassi) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle->democlassi) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle->democlassi) (2019.3.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle->democlassi) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle->democlassi) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle->democlassi) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle->democlassi) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->democlassi) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->democlassi) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle->democlassi) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle->democlassi) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle->democlassi) (1.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX->democlassi) (40.9.0)\n",
            "Installing collected packages: pytorch-ignite, tensorboardX, democlassi\n",
            "Successfully installed democlassi-0.4 pytorch-ignite-0.2.0 tensorboardX-1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a02eEjNz6-GY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from vision_utils.custom_torch_utils import load_model\n",
        "from vision_utils.custom_architectures import SepConvModelMT, SepConvModel, initialize_model, PretrainedMT\n",
        "\n",
        "\n",
        "from multitask_rag.train import run_utk\n",
        "from multitask_rag.utk_data_utils import get_utk_dataloader, split_utk\n",
        "from multitask_rag.evaluate import evaluate_model as eval_utk\n",
        "\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7BMvL6wBFKN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The UTK face datasets which I am going to use and which can be [downloaded here](https://drive.google.com/open?id=0BxYys69jI14kYVM3aVhKS1VhRUk) is located in my google drive, so I need to mount my google drive folder in order to copy the data locally on googlr colab :"
      ]
    },
    {
      "metadata": {
        "id": "kZ8Hp3xpBExj",
        "colab_type": "code",
        "outputId": "f422e9e8-5dcd-4cc3-bbaf-071d33dbe29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tkFX8o4zB-en",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a directory where to store data\n",
        "os.makedirs('/content/data', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hiS84ofxr32n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# copy the data from google drive\n",
        "!cp gdrive/My\\ Drive/DeepLearning/Face_detection/utk_face.zip /content/data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IWqXz0qQGxFG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And finally extract the data"
      ]
    },
    {
      "metadata": {
        "id": "tSCbpC3rsC38",
        "colab_type": "code",
        "outputId": "873ad8fa-1c54-44ba-fb6d-01570019ee47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip data/utk_face.zip -d data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data/utk_face.zip\n",
            "  inflating: data/crop_part1.tar.gz  \n",
            "  inflating: data/UTKFace.tar.gz     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VzkX6nmVsG71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# extract the images\n",
        "!tar -C data/ -xzf data/UTKFace.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PExaIyGhBcIr",
        "colab_type": "code",
        "outputId": "672903dd-47d7-4585-cc4b-d6be926bdad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# print content of the data directory\n",
        "!ls /content/data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "crop_part1.tar.gz  UTKFace  UTKFace.tar.gz  utk_face.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2czpStHRsNOo",
        "colab_type": "code",
        "outputId": "987ce9d1-0589-41ca-9e5a-11ab9faef65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "list_images = glob.glob('/content/data/UTKFace/*jp*')\n",
        "print(len(list_images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-U_C4M_JG6wO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have 23708 images in total, and the labels are given in the image names. the image names format is the following : `age_gender_race_date`.\n",
        "for instance this image name `1_0_0_20161219140623097.jpg.chip.jpg` suggests that the image corresponds to a person whose age is `1`, gender is `0` (Male) and race is `0` (White).\n",
        "However there are few images for which the name is malfomed, so we remove them using the following code snippet :"
      ]
    },
    {
      "metadata": {
        "id": "iQPpWkkvseJV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to remove invalid images (that he filenames is not correctly formatted)\n",
        "def get_invalid_images(root_path='/content/data/UTKFace/'):\n",
        "    list_files = glob.glob(os.path.join(root_path, '*.[jJ][pP]*'))\n",
        "    filenames = [path.split('/')[-1].split('_') for path in list_files]\n",
        "    print()\n",
        "    invalid_images = []\n",
        "    for i, im in enumerate(tqdm.tqdm(filenames)):\n",
        "        if im[0].isdigit() and im[1].isdigit() and im[2].isdigit():\n",
        "            continue\n",
        "        else:\n",
        "            invalid_images.append(list_files[i])\n",
        "    return invalid_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvPN2c8CsrHW",
        "colab_type": "code",
        "outputId": "18585f99-18f9-4fb7-d545-a97a86e64901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "invalid_images = get_invalid_images()\n",
        "print(invalid_images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23708/23708 [00:00<00:00, 1356726.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "['/content/data/UTKFace/39_1_20170116174525125.jpg.chip.jpg', '/content/data/UTKFace/61_1_20170109150557335.jpg.chip.jpg', '/content/data/UTKFace/61_1_20170109142408075.jpg.chip.jpg']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "29YQ2IGMsvlD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove invalid files\n",
        "for f in invalid_images:\n",
        "    os.remove(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z6Q6N6Ga6-Gh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Some data pre-processing operations\n",
        "\n",
        "Now that we have our dataset ready let's split it into training (70%), test (15%) and validation (15%) sets:"
      ]
    },
    {
      "metadata": {
        "id": "tZ_WKloZt1vz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split the dataset into train, test and validation sets \n",
        "SRC_DIR = '/content/data/UTKFace/'  # path to the folder containing all images\n",
        "DEST_DIR = '/content/data/utk_split/' # path where to save the split dataset, 3 subdirectories will be created (train, valid and test)\n",
        "SPLIT = 0.7 # ratio of the train set, the remaining (30%) will be split equally between validation and test sets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RfGSvdSXuTkv",
        "colab_type": "code",
        "outputId": "d36d9ff4-a875-4173-dede-26f1855da4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "split_utk(SRC_DIR, DEST_DIR, SPLIT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 654/16593 [00:00<00:02, 6538.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------Copying train images-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16593/16593 [00:02<00:00, 6386.52it/s]\n",
            " 18%|█▊        | 627/3556 [00:00<00:00, 6267.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------Copying valid images-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3556/3556 [00:00<00:00, 6267.90it/s]\n",
            " 17%|█▋        | 587/3556 [00:00<00:00, 5868.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------Copying test images-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3556/3556 [00:00<00:00, 4139.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ak1q1vWwJM3t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEYIhW97JQHN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's also define some transformations we would like to apply :\n",
        "* Resize all images to 128 x 128\n",
        "* convert them to pytorch tensors before feeding to the model"
      ]
    },
    {
      "metadata": {
        "id": "07NvuKaBvJie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIFoPIGJKfC-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The last step before training is to create  DataLoader objects, which are pytorch generator-like objects for yielding data into batches during training :"
      ]
    },
    {
      "metadata": {
        "id": "K30DAfY2tmIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = get_utk_dataloader(batch_size=128, data_dir=DEST_DIR, data_transforms=data_transforms, flag='train')\n",
        "val_loader = get_utk_dataloader(batch_size=128, data_dir=DEST_DIR, data_transforms=data_transforms, flag='valid')\n",
        "\n",
        "my_data_loaders = {\n",
        "    'train': train_loader,\n",
        "    'valid': val_loader\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N2E7a5w7LD0l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Training"
      ]
    },
    {
      "metadata": {
        "id": "QFldsxJeLcDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll trry three different architectures : \n",
        "* CNN based on Depthwise separable convolutions blocks\n",
        "* Finetuning a pretrained Resnet50\n",
        "* Finetuning a pretrained VGG19"
      ]
    },
    {
      "metadata": {
        "id": "LQeEdKHtLQpY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1 Deptwhise Separable Convolutions architecture"
      ]
    },
    {
      "metadata": {
        "id": "LjuzVpeYwPeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sepconv with adam\n",
        "\n",
        "my_model = SepConvModelMT(dropout=0.7, n_class=[1, 2, 5], n_filters=[64, 128, 256, 512], kernels_size=[3, 3, 3, 3])\n",
        "my_optimizer = torch.optim.Adam(my_model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w_mbLvWRL7ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have created above a model and an Adam optimizer. The model has the following parameters :\n",
        "* `dropout` = 0.7 : we apply a droput of 70%\n",
        "* `n_class` = [1, 2, 5] : the model has 3 outputs that are age (a scalar thus a shape of 1), gender (male or female thus a shape of 2) and race (white, black, asian, indian or other thus a shape of 5).\n",
        "*`n_filters` =  [64, 128, 256, 512] : number of features maps for each conv block\n",
        "* `kernels_size` = [3, 3, 3, 3] : conv kernel size for each conv block"
      ]
    },
    {
      "metadata": {
        "id": "25jpOuvnNieu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I also need to periodically backup the model's checkpoints in my google drive in case I get disconnected to google colab due to connectivity issues or anything else :\n"
      ]
    },
    {
      "metadata": {
        "id": "8Q1zRw85xcVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "backup_path = \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/sep_conv_adam\"\n",
        "os.makedirs(backup_path, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LnRkLNkvOa7N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before starting training, let's clarify some important input arguments to the training function that are not quite clear :\n",
        "* `log_interval` : print the training loss each `log_interval` iterations\n",
        "* `dirname` : path to the directory where to locally save the best model checkpoint after each epoch\n",
        "* `filename_prefix` : file name under which to save the model checkpoint\n",
        "* `n_saved` : save the `n_saved` best models\n",
        "* `launch_tensorboard` and `log_dir` :  whether to write tensorboard summaries, and if True, write them under `log_dir` folder\n",
        "* `patience`: number of epochs to wait for before stopping training if no improvement is observed\n",
        "* `resume_model` and `resume_optimizer` : optional paths to previously trained model and optimizer to start use them as starting point for the training\n",
        "* `backup_step` and `backup_path` : copy the saved checkpoints from `dirname` to `backup_path` each `backup_step` epochs\n",
        "* `n_epochs_freeze` : unfreeze the frozen layers after `n_epochs_freeze`, this is particularly used in case of finetuning a pretrained model\n",
        "* `lr_after_freeze` : in case of finetuning a pretrained model, new learning rate to set after unfreezing frozen layers\n",
        "* `loss_weights` : the model's outputs (age, gender, race) are not of the same magnitude, wo we made need to assign them different weights representing their respective contributions to the global loss\n",
        "\n",
        "\n",
        "\n",
        "Now that it's a little bit clearer let's start training :"
      ]
    },
    {
      "metadata": {
        "id": "ZhUlXkCcw3VT",
        "colab_type": "code",
        "outputId": "21617fd4-36c8-46a1-d6c4-0901f242574e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2752
        }
      },
      "cell_type": "code",
      "source": [
        "run_utk(my_model, my_optimizer, epochs=300, log_interval=1, dataloaders=my_data_loaders,\n",
        "        dirname='/content/checkpoints/sep_conv_adam', filename_prefix='sep_conv_adam', n_saved=1,\n",
        "        log_dir=None, launch_tensorboard=False, patience=50,\n",
        "        resume_model=None, resume_optimizer=None, backup_step=5, backup_path=backup_path,\n",
        "        n_epochs_freeze=0, lr_after_freeze=None,\n",
        "        loss_weights=[1/10, 1/0.16, 1/0.44])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters : 706,278\n",
            "Number of non-trainable parameters : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 10.693: 100%|██████████| 130/130 [02:54<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 1 Age L1-loss: 31.704 ** Gender accuracy: 0.525 ** Race accuracy: 0.462 ** Avg loss: 13.038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 10.693: 100%|██████████| 130/130 [03:06<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 1 Age L1-loss: 31.058 ** Gender accuracy: 0.526 ** Race accuracy: 0.456 ** Avg loss: 12.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 9.345: 100%|██████████| 130/130 [06:01<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 2 Age L1-loss: 30.515 ** Gender accuracy: 0.749 ** Race accuracy: 0.510 ** Avg loss: 9.207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 9.345: 100%|██████████| 130/130 [06:12<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 2 Age L1-loss: 29.866 ** Gender accuracy: 0.759 ** Race accuracy: 0.510 ** Avg loss: 9.084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 7.820: 100%|██████████| 130/130 [09:07<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 3 Age L1-loss: 27.112 ** Gender accuracy: 0.763 ** Race accuracy: 0.509 ** Avg loss: 9.077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 7.820: 100%|██████████| 130/130 [09:19<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 3 Age L1-loss: 26.565 ** Gender accuracy: 0.767 ** Race accuracy: 0.516 ** Avg loss: 9.015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.379: 100%|██████████| 130/130 [12:20<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 4 Age L1-loss: 18.477 ** Gender accuracy: 0.729 ** Race accuracy: 0.513 ** Avg loss: 8.391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.379: 100%|██████████| 130/130 [12:32<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 4 Age L1-loss: 18.202 ** Gender accuracy: 0.710 ** Race accuracy: 0.511 ** Avg loss: 8.657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.373: 100%|██████████| 130/130 [15:34<00:00,  1.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 5 Age L1-loss: 15.677 ** Gender accuracy: 0.867 ** Race accuracy: 0.570 ** Avg loss: 6.075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.373: 100%|██████████| 130/130 [15:47<00:00,  1.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 5 Age L1-loss: 15.503 ** Gender accuracy: 0.853 ** Race accuracy: 0.569 ** Avg loss: 6.243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.033: 100%|██████████| 130/130 [18:47<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 6 Age L1-loss: 15.069 ** Gender accuracy: 0.889 ** Race accuracy: 0.601 ** Avg loss: 5.577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.033: 100%|██████████| 130/130 [18:59<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 6 Age L1-loss: 14.962 ** Gender accuracy: 0.870 ** Race accuracy: 0.593 ** Avg loss: 5.822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.625: 100%|██████████| 130/130 [21:55<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 7 Age L1-loss: 15.065 ** Gender accuracy: 0.888 ** Race accuracy: 0.621 ** Avg loss: 5.478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.625: 100%|██████████| 130/130 [22:07<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 7 Age L1-loss: 14.959 ** Gender accuracy: 0.873 ** Race accuracy: 0.621 ** Avg loss: 5.773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.260: 100%|██████████| 130/130 [25:04<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 8 Age L1-loss: 15.059 ** Gender accuracy: 0.873 ** Race accuracy: 0.619 ** Avg loss: 5.819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.260: 100%|██████████| 130/130 [25:15<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 8 Age L1-loss: 14.958 ** Gender accuracy: 0.859 ** Race accuracy: 0.618 ** Avg loss: 6.026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.159: 100%|██████████| 130/130 [28:17<00:00,  1.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 9 Age L1-loss: 15.034 ** Gender accuracy: 0.901 ** Race accuracy: 0.654 ** Avg loss: 5.177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.159: 100%|██████████| 130/130 [28:29<00:00,  1.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 9 Age L1-loss: 14.930 ** Gender accuracy: 0.886 ** Race accuracy: 0.650 ** Avg loss: 5.484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.772: 100%|██████████| 130/130 [31:31<00:00,  1.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 10 Age L1-loss: 15.024 ** Gender accuracy: 0.901 ** Race accuracy: 0.710 ** Avg loss: 4.833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.772: 100%|██████████| 130/130 [31:44<00:00,  1.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 10 Age L1-loss: 14.925 ** Gender accuracy: 0.876 ** Race accuracy: 0.696 ** Avg loss: 5.216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.954: 100%|██████████| 130/130 [34:47<00:00,  1.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 11 Age L1-loss: 15.145 ** Gender accuracy: 0.837 ** Race accuracy: 0.728 ** Avg loss: 5.829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.954: 100%|██████████| 130/130 [34:59<00:00,  1.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 11 Age L1-loss: 15.056 ** Gender accuracy: 0.828 ** Race accuracy: 0.710 ** Avg loss: 6.374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.071: 100%|██████████| 130/130 [37:59<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 12 Age L1-loss: 15.049 ** Gender accuracy: 0.908 ** Race accuracy: 0.622 ** Avg loss: 5.431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.071: 100%|██████████| 130/130 [38:11<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 12 Age L1-loss: 14.945 ** Gender accuracy: 0.871 ** Race accuracy: 0.616 ** Avg loss: 5.819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.286: 100%|██████████| 130/130 [41:11<00:00,  1.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 13 Age L1-loss: 15.028 ** Gender accuracy: 0.918 ** Race accuracy: 0.755 ** Avg loss: 4.356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.286: 100%|██████████| 130/130 [41:23<00:00,  1.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 13 Age L1-loss: 14.926 ** Gender accuracy: 0.884 ** Race accuracy: 0.734 ** Avg loss: 4.926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.503: 100%|██████████| 130/130 [44:23<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 14 Age L1-loss: 15.032 ** Gender accuracy: 0.931 ** Race accuracy: 0.773 ** Avg loss: 4.110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.503: 100%|██████████| 130/130 [44:35<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 14 Age L1-loss: 14.931 ** Gender accuracy: 0.898 ** Race accuracy: 0.745 ** Avg loss: 4.729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.452: 100%|██████████| 130/130 [47:34<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 15 Age L1-loss: 15.028 ** Gender accuracy: 0.925 ** Race accuracy: 0.783 ** Avg loss: 4.090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.452: 100%|██████████| 130/130 [47:46<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 15 Age L1-loss: 14.925 ** Gender accuracy: 0.887 ** Race accuracy: 0.756 ** Avg loss: 4.730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.767: 100%|██████████| 130/130 [50:46<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 16 Age L1-loss: 15.041 ** Gender accuracy: 0.934 ** Race accuracy: 0.770 ** Avg loss: 4.090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.767: 100%|██████████| 130/130 [50:58<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 16 Age L1-loss: 14.948 ** Gender accuracy: 0.904 ** Race accuracy: 0.746 ** Avg loss: 4.715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.967: 100%|██████████| 130/130 [53:58<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 17 Age L1-loss: 15.024 ** Gender accuracy: 0.927 ** Race accuracy: 0.761 ** Avg loss: 4.218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.967: 100%|██████████| 130/130 [54:10<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 17 Age L1-loss: 14.919 ** Gender accuracy: 0.888 ** Race accuracy: 0.737 ** Avg loss: 4.899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.054: 100%|██████████| 130/130 [57:10<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 18 Age L1-loss: 15.041 ** Gender accuracy: 0.872 ** Race accuracy: 0.744 ** Avg loss: 5.296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.054: 100%|██████████| 130/130 [57:22<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 18 Age L1-loss: 14.942 ** Gender accuracy: 0.855 ** Race accuracy: 0.713 ** Avg loss: 6.120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.418: 100%|██████████| 130/130 [1:00:22<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 19 Age L1-loss: 15.025 ** Gender accuracy: 0.819 ** Race accuracy: 0.776 ** Avg loss: 5.582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.418: 100%|██████████| 130/130 [1:00:34<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 19 Age L1-loss: 14.928 ** Gender accuracy: 0.787 ** Race accuracy: 0.746 ** Avg loss: 6.498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.200: 100%|██████████| 130/130 [1:03:34<00:00,  1.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 20 Age L1-loss: 15.029 ** Gender accuracy: 0.929 ** Race accuracy: 0.756 ** Avg loss: 4.229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.200: 100%|██████████| 130/130 [1:03:46<00:00,  1.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 20 Age L1-loss: 14.926 ** Gender accuracy: 0.882 ** Race accuracy: 0.732 ** Avg loss: 5.281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.817: 100%|██████████| 130/130 [1:06:43<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 21 Age L1-loss: 15.028 ** Gender accuracy: 0.899 ** Race accuracy: 0.827 ** Avg loss: 4.188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.817: 100%|██████████| 130/130 [1:06:54<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 21 Age L1-loss: 14.933 ** Gender accuracy: 0.857 ** Race accuracy: 0.787 ** Avg loss: 5.231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.379: 100%|██████████| 130/130 [1:09:49<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 22 Age L1-loss: 15.026 ** Gender accuracy: 0.863 ** Race accuracy: 0.784 ** Avg loss: 5.072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.379: 100%|██████████| 130/130 [1:10:00<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 22 Age L1-loss: 14.928 ** Gender accuracy: 0.821 ** Race accuracy: 0.754 ** Avg loss: 6.184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.148: 100%|██████████| 130/130 [1:12:55<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 23 Age L1-loss: 15.019 ** Gender accuracy: 0.933 ** Race accuracy: 0.767 ** Avg loss: 4.048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.148: 100%|██████████| 130/130 [1:13:07<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 23 Age L1-loss: 14.916 ** Gender accuracy: 0.897 ** Race accuracy: 0.741 ** Avg loss: 4.886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.057: 100%|██████████| 130/130 [1:16:02<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 24 Age L1-loss: 15.030 ** Gender accuracy: 0.882 ** Race accuracy: 0.823 ** Avg loss: 4.468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.057: 100%|██████████| 130/130 [1:16:14<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 24 Age L1-loss: 14.929 ** Gender accuracy: 0.841 ** Race accuracy: 0.771 ** Avg loss: 5.729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.918: 100%|██████████| 130/130 [1:19:10<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 25 Age L1-loss: 15.024 ** Gender accuracy: 0.961 ** Race accuracy: 0.812 ** Avg loss: 3.434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.918: 100%|██████████| 130/130 [1:19:22<00:00,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 25 Age L1-loss: 14.924 ** Gender accuracy: 0.899 ** Race accuracy: 0.770 ** Avg loss: 4.783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.337: 100%|██████████| 130/130 [1:22:17<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 26 Age L1-loss: 15.025 ** Gender accuracy: 0.956 ** Race accuracy: 0.818 ** Avg loss: 3.501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.337: 100%|██████████| 130/130 [1:22:29<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 26 Age L1-loss: 14.928 ** Gender accuracy: 0.900 ** Race accuracy: 0.768 ** Avg loss: 4.877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.798: 100%|██████████| 130/130 [1:25:25<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 27 Age L1-loss: 15.023 ** Gender accuracy: 0.952 ** Race accuracy: 0.807 ** Avg loss: 3.539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.798: 100%|██████████| 130/130 [1:25:37<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 27 Age L1-loss: 14.919 ** Gender accuracy: 0.900 ** Race accuracy: 0.761 ** Avg loss: 5.039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.218: 100%|██████████| 130/130 [1:28:32<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 28 Age L1-loss: 15.034 ** Gender accuracy: 0.953 ** Race accuracy: 0.846 ** Avg loss: 3.285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.218: 100%|██████████| 130/130 [1:28:44<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 28 Age L1-loss: 14.929 ** Gender accuracy: 0.902 ** Race accuracy: 0.788 ** Avg loss: 4.818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.553: 100%|██████████| 130/130 [1:31:40<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 29 Age L1-loss: 15.024 ** Gender accuracy: 0.959 ** Race accuracy: 0.796 ** Avg loss: 3.566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.553: 100%|██████████| 130/130 [1:31:52<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 29 Age L1-loss: 14.920 ** Gender accuracy: 0.902 ** Race accuracy: 0.748 ** Avg loss: 5.051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.482: 100%|██████████| 130/130 [1:34:47<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 30 Age L1-loss: 15.038 ** Gender accuracy: 0.901 ** Race accuracy: 0.845 ** Avg loss: 4.045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.482: 100%|██████████| 130/130 [1:34:59<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 30 Age L1-loss: 14.939 ** Gender accuracy: 0.863 ** Race accuracy: 0.787 ** Avg loss: 5.802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.335: 100%|██████████| 130/130 [1:37:55<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 31 Age L1-loss: 15.036 ** Gender accuracy: 0.959 ** Race accuracy: 0.791 ** Avg loss: 3.575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.335: 100%|██████████| 130/130 [1:38:06<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 31 Age L1-loss: 14.943 ** Gender accuracy: 0.896 ** Race accuracy: 0.749 ** Avg loss: 5.267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.056: 100%|██████████| 130/130 [1:41:02<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 32 Age L1-loss: 15.023 ** Gender accuracy: 0.966 ** Race accuracy: 0.838 ** Avg loss: 3.186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.056: 100%|██████████| 130/130 [1:41:13<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 32 Age L1-loss: 14.919 ** Gender accuracy: 0.906 ** Race accuracy: 0.778 ** Avg loss: 4.796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.510: 100%|██████████| 130/130 [1:44:09<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 33 Age L1-loss: 15.025 ** Gender accuracy: 0.966 ** Race accuracy: 0.841 ** Avg loss: 3.120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.510: 100%|██████████| 130/130 [1:44:21<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 33 Age L1-loss: 14.925 ** Gender accuracy: 0.903 ** Race accuracy: 0.779 ** Avg loss: 5.074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.898: 100%|██████████| 130/130 [1:47:16<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 34 Age L1-loss: 15.025 ** Gender accuracy: 0.892 ** Race accuracy: 0.838 ** Avg loss: 4.416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.898: 100%|██████████| 130/130 [1:47:28<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 34 Age L1-loss: 14.927 ** Gender accuracy: 0.855 ** Race accuracy: 0.772 ** Avg loss: 6.559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.225: 100%|██████████| 130/130 [1:50:23<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 35 Age L1-loss: 15.020 ** Gender accuracy: 0.834 ** Race accuracy: 0.702 ** Avg loss: 6.667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.225: 100%|██████████| 130/130 [1:50:35<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 35 Age L1-loss: 14.925 ** Gender accuracy: 0.801 ** Race accuracy: 0.673 ** Avg loss: 7.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.964: 100%|██████████| 130/130 [1:53:31<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 36 Age L1-loss: 15.019 ** Gender accuracy: 0.971 ** Race accuracy: 0.841 ** Avg loss: 3.056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.964: 100%|██████████| 130/130 [1:53:43<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 36 Age L1-loss: 14.917 ** Gender accuracy: 0.899 ** Race accuracy: 0.774 ** Avg loss: 5.015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.769: 100%|██████████| 130/130 [1:56:38<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 37 Age L1-loss: 15.020 ** Gender accuracy: 0.975 ** Race accuracy: 0.805 ** Avg loss: 3.215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.769: 100%|██████████| 130/130 [1:56:50<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 37 Age L1-loss: 14.915 ** Gender accuracy: 0.902 ** Race accuracy: 0.752 ** Avg loss: 5.203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.989: 100%|██████████| 130/130 [1:59:45<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 38 Age L1-loss: 15.023 ** Gender accuracy: 0.980 ** Race accuracy: 0.861 ** Avg loss: 2.809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.989: 100%|██████████| 130/130 [1:59:57<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 38 Age L1-loss: 14.924 ** Gender accuracy: 0.898 ** Race accuracy: 0.786 ** Avg loss: 4.951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.505: 100%|██████████| 130/130 [2:02:54<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 39 Age L1-loss: 15.027 ** Gender accuracy: 0.970 ** Race accuracy: 0.789 ** Avg loss: 3.425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.505: 100%|██████████| 130/130 [2:03:06<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 39 Age L1-loss: 14.928 ** Gender accuracy: 0.893 ** Race accuracy: 0.731 ** Avg loss: 5.734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.636: 100%|██████████| 130/130 [2:06:00<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 40 Age L1-loss: 15.025 ** Gender accuracy: 0.978 ** Race accuracy: 0.854 ** Avg loss: 2.825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.636: 100%|██████████| 130/130 [2:06:12<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 40 Age L1-loss: 14.925 ** Gender accuracy: 0.905 ** Race accuracy: 0.770 ** Avg loss: 5.148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.306: 100%|██████████| 130/130 [2:09:07<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 41 Age L1-loss: 15.024 ** Gender accuracy: 0.963 ** Race accuracy: 0.861 ** Avg loss: 3.009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.306: 100%|██████████| 130/130 [2:09:19<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 41 Age L1-loss: 14.920 ** Gender accuracy: 0.882 ** Race accuracy: 0.775 ** Avg loss: 5.688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.354: 100%|██████████| 130/130 [2:12:13<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 42 Age L1-loss: 15.020 ** Gender accuracy: 0.955 ** Race accuracy: 0.858 ** Avg loss: 3.163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.354: 100%|██████████| 130/130 [2:12:25<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 42 Age L1-loss: 14.917 ** Gender accuracy: 0.874 ** Race accuracy: 0.776 ** Avg loss: 5.779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.609: 100%|██████████| 130/130 [2:15:22<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 43 Age L1-loss: 15.030 ** Gender accuracy: 0.936 ** Race accuracy: 0.794 ** Avg loss: 4.144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.609: 100%|██████████| 130/130 [2:15:34<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 43 Age L1-loss: 14.923 ** Gender accuracy: 0.875 ** Race accuracy: 0.735 ** Avg loss: 6.772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.155: 100%|██████████| 130/130 [2:18:29<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 44 Age L1-loss: 15.020 ** Gender accuracy: 0.958 ** Race accuracy: 0.803 ** Avg loss: 3.456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.155: 100%|██████████| 130/130 [2:18:41<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 44 Age L1-loss: 14.916 ** Gender accuracy: 0.880 ** Race accuracy: 0.726 ** Avg loss: 6.078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.596: 100%|██████████| 130/130 [2:21:37<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 45 Age L1-loss: 15.053 ** Gender accuracy: 0.770 ** Race accuracy: 0.716 ** Avg loss: 10.016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.596: 100%|██████████| 130/130 [2:21:49<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 45 Age L1-loss: 14.950 ** Gender accuracy: 0.761 ** Race accuracy: 0.675 ** Avg loss: 12.666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.927: 100%|██████████| 130/130 [2:24:44<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 46 Age L1-loss: 15.028 ** Gender accuracy: 0.961 ** Race accuracy: 0.811 ** Avg loss: 3.381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.927: 100%|██████████| 130/130 [2:24:56<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 46 Age L1-loss: 14.924 ** Gender accuracy: 0.882 ** Race accuracy: 0.735 ** Avg loss: 5.905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.495: 100%|██████████| 130/130 [2:27:54<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 47 Age L1-loss: 15.020 ** Gender accuracy: 0.958 ** Race accuracy: 0.879 ** Avg loss: 2.952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.495: 100%|██████████| 130/130 [2:28:07<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 47 Age L1-loss: 14.918 ** Gender accuracy: 0.888 ** Race accuracy: 0.787 ** Avg loss: 5.500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.765: 100%|██████████| 130/130 [2:31:04<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 48 Age L1-loss: 15.022 ** Gender accuracy: 0.981 ** Race accuracy: 0.901 ** Avg loss: 2.503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.765: 100%|██████████| 130/130 [2:31:16<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 48 Age L1-loss: 14.922 ** Gender accuracy: 0.900 ** Race accuracy: 0.794 ** Avg loss: 5.419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.456: 100%|██████████| 130/130 [2:34:12<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 49 Age L1-loss: 15.021 ** Gender accuracy: 0.962 ** Race accuracy: 0.882 ** Avg loss: 2.902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.456: 100%|██████████| 130/130 [2:34:24<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 49 Age L1-loss: 14.917 ** Gender accuracy: 0.883 ** Race accuracy: 0.773 ** Avg loss: 5.770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.581: 100%|██████████| 130/130 [2:37:20<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 50 Age L1-loss: 15.025 ** Gender accuracy: 0.905 ** Race accuracy: 0.834 ** Avg loss: 4.150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.581: 100%|██████████| 130/130 [2:37:32<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 50 Age L1-loss: 14.919 ** Gender accuracy: 0.835 ** Race accuracy: 0.730 ** Avg loss: 6.961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.508: 100%|██████████| 130/130 [2:40:28<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 51 Age L1-loss: 15.019 ** Gender accuracy: 0.989 ** Race accuracy: 0.845 ** Avg loss: 2.716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.508: 100%|██████████| 130/130 [2:40:40<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 51 Age L1-loss: 14.917 ** Gender accuracy: 0.900 ** Race accuracy: 0.750 ** Avg loss: 5.584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.568: 100%|██████████| 130/130 [2:43:36<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 52 Age L1-loss: 15.025 ** Gender accuracy: 0.964 ** Race accuracy: 0.795 ** Avg loss: 3.405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.568: 100%|██████████| 130/130 [2:43:48<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 52 Age L1-loss: 14.920 ** Gender accuracy: 0.893 ** Race accuracy: 0.701 ** Avg loss: 6.505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.520: 100%|██████████| 130/130 [2:46:43<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 53 Age L1-loss: 15.023 ** Gender accuracy: 0.989 ** Race accuracy: 0.846 ** Avg loss: 2.700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.520: 100%|██████████| 130/130 [2:46:55<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 53 Age L1-loss: 14.919 ** Gender accuracy: 0.902 ** Race accuracy: 0.744 ** Avg loss: 5.855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.423: 100%|██████████| 130/130 [2:49:50<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 54 Age L1-loss: 15.024 ** Gender accuracy: 0.987 ** Race accuracy: 0.818 ** Avg loss: 3.017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.423: 100%|██████████| 130/130 [2:50:02<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 54 Age L1-loss: 14.924 ** Gender accuracy: 0.900 ** Race accuracy: 0.733 ** Avg loss: 6.490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.710: 100%|██████████| 130/130 [2:52:59<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 55 Age L1-loss: 15.025 ** Gender accuracy: 0.989 ** Race accuracy: 0.893 ** Avg loss: 2.384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.710: 100%|██████████| 130/130 [2:53:12<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 55 Age L1-loss: 14.924 ** Gender accuracy: 0.903 ** Race accuracy: 0.776 ** Avg loss: 5.888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.543: 100%|██████████| 130/130 [2:56:09<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 56 Age L1-loss: 15.023 ** Gender accuracy: 0.953 ** Race accuracy: 0.906 ** Avg loss: 2.874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.543: 100%|██████████| 130/130 [2:56:21<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 56 Age L1-loss: 14.912 ** Gender accuracy: 0.874 ** Race accuracy: 0.789 ** Avg loss: 6.440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.796: 100%|██████████| 130/130 [2:59:15<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 57 Age L1-loss: 15.019 ** Gender accuracy: 0.993 ** Race accuracy: 0.864 ** Avg loss: 2.533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.796: 100%|██████████| 130/130 [2:59:28<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 57 Age L1-loss: 14.916 ** Gender accuracy: 0.903 ** Race accuracy: 0.750 ** Avg loss: 5.843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.686: 100%|██████████| 130/130 [3:02:22<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 58 Age L1-loss: 15.023 ** Gender accuracy: 0.984 ** Race accuracy: 0.857 ** Avg loss: 2.704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.686: 100%|██████████| 130/130 [3:02:34<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 58 Age L1-loss: 14.920 ** Gender accuracy: 0.900 ** Race accuracy: 0.750 ** Avg loss: 6.138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.301: 100%|██████████| 130/130 [3:05:28<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 59 Age L1-loss: 15.038 ** Gender accuracy: 0.884 ** Race accuracy: 0.821 ** Avg loss: 4.808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.301: 100%|██████████| 130/130 [3:05:40<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 59 Age L1-loss: 14.925 ** Gender accuracy: 0.816 ** Race accuracy: 0.719 ** Avg loss: 8.526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.850: 100%|██████████| 130/130 [3:08:35<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 60 Age L1-loss: 15.023 ** Gender accuracy: 0.992 ** Race accuracy: 0.885 ** Avg loss: 2.423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.850: 100%|██████████| 130/130 [3:08:47<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 60 Age L1-loss: 14.921 ** Gender accuracy: 0.907 ** Race accuracy: 0.771 ** Avg loss: 5.943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.401: 100%|██████████| 130/130 [3:11:41<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 61 Age L1-loss: 15.024 ** Gender accuracy: 0.935 ** Race accuracy: 0.907 ** Avg loss: 3.143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.401: 100%|██████████| 130/130 [3:11:53<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 61 Age L1-loss: 14.922 ** Gender accuracy: 0.846 ** Race accuracy: 0.776 ** Avg loss: 6.801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.938: 100%|██████████| 130/130 [3:14:47<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 62 Age L1-loss: 15.023 ** Gender accuracy: 0.986 ** Race accuracy: 0.841 ** Avg loss: 2.825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.938: 100%|██████████| 130/130 [3:14:59<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 62 Age L1-loss: 14.924 ** Gender accuracy: 0.893 ** Race accuracy: 0.741 ** Avg loss: 6.771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.682: 100%|██████████| 130/130 [3:17:54<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 63 Age L1-loss: 15.016 ** Gender accuracy: 0.991 ** Race accuracy: 0.668 ** Avg loss: 3.660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.682: 100%|██████████| 130/130 [3:18:06<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 63 Age L1-loss: 14.910 ** Gender accuracy: 0.899 ** Race accuracy: 0.596 ** Avg loss: 6.682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.206: 100%|██████████| 130/130 [3:21:02<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 64 Age L1-loss: 15.030 ** Gender accuracy: 0.850 ** Race accuracy: 0.927 ** Avg loss: 4.858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.206: 100%|██████████| 130/130 [3:21:15<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 64 Age L1-loss: 14.924 ** Gender accuracy: 0.784 ** Race accuracy: 0.781 ** Avg loss: 9.070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.550: 100%|██████████| 130/130 [3:24:11<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 65 Age L1-loss: 15.025 ** Gender accuracy: 0.951 ** Race accuracy: 0.920 ** Avg loss: 2.873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.550: 100%|██████████| 130/130 [3:24:22<00:00,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 65 Age L1-loss: 14.926 ** Gender accuracy: 0.862 ** Race accuracy: 0.790 ** Avg loss: 6.483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.956: 100%|██████████| 130/130 [3:27:18<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 66 Age L1-loss: 15.024 ** Gender accuracy: 0.986 ** Race accuracy: 0.790 ** Avg loss: 3.162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.956: 100%|██████████| 130/130 [3:27:30<00:00,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 66 Age L1-loss: 14.924 ** Gender accuracy: 0.905 ** Race accuracy: 0.688 ** Avg loss: 6.718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.224: 100%|██████████| 130/130 [3:30:26<00:00,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 67 Age L1-loss: 15.031 ** Gender accuracy: 0.993 ** Race accuracy: 0.926 ** Avg loss: 2.081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 67 Age L1-loss: 14.934 ** Gender accuracy: 0.899 ** Race accuracy: 0.791 ** Avg loss: 5.943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGCCAYAAACb9gvzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABbBAAAAWP8fAM43vAWlMpEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The execution took 3.0 hours | 30.0 minutes | 42.0 seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZXY329vfmGK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0fd6xS6S1qw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Finetunig a pretrained Resnet50\n",
        "\n",
        "We are going to :\n",
        "* freeze all other layers and only train the classification using a learning rate of 1e-3\n",
        "* unfreeze all layers after 10 epochs and finetune the whole model using a learning rate of 1e-4"
      ]
    },
    {
      "metadata": {
        "id": "1JylvWdOnJmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "backup_path = \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/resnet_adam\"\n",
        "os.makedirs(backup_path, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d31f4MrQmGxa",
        "colab_type": "code",
        "outputId": "c252d71d-2765-46da-c3bc-d7b06ec1e373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "my_model = PretrainedMT(model_name='resnet', feature_extract=True, use_pretrained=True)\n",
        "my_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, my_model.parameters()), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
            "102502400it [00:05, 18020355.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rPMvktmyncQ1",
        "colab_type": "code",
        "outputId": "c2f4bead-4f4b-44b0-c405-215d4b71bc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2599
        }
      },
      "cell_type": "code",
      "source": [
        "run_utk(my_model, my_optimizer, epochs=300, log_interval=1, dataloaders=my_data_loaders,\n",
        "        dirname='/content/checkpoints/resnet_adam', filename_prefix='resnet', n_saved=1,\n",
        "        log_dir='/content/logs', launch_tensorboard=False, patience=50,\n",
        "        resume_model=None, resume_optimizer=None, backup_step=5, backup_path=backup_path,\n",
        "        n_epochs_freeze=10, n_cycle=None, lr_after_freeze=1e-4,\n",
        "        loss_weights=[1/10, 1/0.16, 1/0.44], lr_plot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rITERATION - loss: 0.000:   0%|          | 0/130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters : 263,304\n",
            "Number of non-trainable parameters : 23,508,032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.230: 100%|██████████| 130/130 [01:42<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 1 Age L1-loss: 15.746 ** Gender accuracy: 0.766 ** Race accuracy: 0.615 ** Avg loss: 6.978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.230: 100%|██████████| 130/130 [01:56<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 1 Age L1-loss: 15.637 ** Gender accuracy: 0.749 ** Race accuracy: 0.598 ** Avg loss: 7.201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.093: 100%|██████████| 130/130 [03:40<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 2 Age L1-loss: 15.535 ** Gender accuracy: 0.822 ** Race accuracy: 0.642 ** Avg loss: 6.197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.093: 100%|██████████| 130/130 [03:54<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 2 Age L1-loss: 15.436 ** Gender accuracy: 0.802 ** Race accuracy: 0.623 ** Avg loss: 6.481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.312: 100%|██████████| 130/130 [05:38<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 3 Age L1-loss: 15.425 ** Gender accuracy: 0.806 ** Race accuracy: 0.656 ** Avg loss: 6.258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.312: 100%|██████████| 130/130 [05:53<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 3 Age L1-loss: 15.322 ** Gender accuracy: 0.782 ** Race accuracy: 0.631 ** Avg loss: 6.664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.221: 100%|██████████| 130/130 [07:37<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 4 Age L1-loss: 15.333 ** Gender accuracy: 0.810 ** Race accuracy: 0.659 ** Avg loss: 6.212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.221: 100%|██████████| 130/130 [07:51<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 4 Age L1-loss: 15.237 ** Gender accuracy: 0.793 ** Race accuracy: 0.622 ** Avg loss: 6.600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.989: 100%|██████████| 130/130 [09:35<00:00,  3.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 5 Age L1-loss: 15.264 ** Gender accuracy: 0.831 ** Race accuracy: 0.669 ** Avg loss: 5.890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.989: 100%|██████████| 130/130 [09:49<00:00,  3.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 5 Age L1-loss: 15.174 ** Gender accuracy: 0.809 ** Race accuracy: 0.634 ** Avg loss: 6.288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.762: 100%|██████████| 130/130 [11:35<00:00,  3.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 6 Age L1-loss: 15.214 ** Gender accuracy: 0.780 ** Race accuracy: 0.666 ** Avg loss: 6.468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.762: 100%|██████████| 130/130 [11:49<00:00,  3.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 6 Age L1-loss: 15.113 ** Gender accuracy: 0.758 ** Race accuracy: 0.633 ** Avg loss: 6.972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.546: 100%|██████████| 130/130 [13:34<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 7 Age L1-loss: 15.192 ** Gender accuracy: 0.840 ** Race accuracy: 0.660 ** Avg loss: 5.900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.546: 100%|██████████| 130/130 [13:48<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 7 Age L1-loss: 15.106 ** Gender accuracy: 0.813 ** Race accuracy: 0.628 ** Avg loss: 6.385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.393: 100%|██████████| 130/130 [15:33<00:00,  3.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 8 Age L1-loss: 15.162 ** Gender accuracy: 0.830 ** Race accuracy: 0.690 ** Avg loss: 5.813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 6.393: 100%|██████████| 130/130 [15:48<00:00,  3.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 8 Age L1-loss: 15.071 ** Gender accuracy: 0.801 ** Race accuracy: 0.652 ** Avg loss: 6.359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.998: 100%|██████████| 130/130 [17:34<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 9 Age L1-loss: 15.198 ** Gender accuracy: 0.844 ** Race accuracy: 0.687 ** Avg loss: 5.674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 5.998: 100%|██████████| 130/130 [17:49<00:00,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 9 Age L1-loss: 15.129 ** Gender accuracy: 0.815 ** Race accuracy: 0.643 ** Avg loss: 6.204\n",
            "****Unfreezing frozen layers ... ***\n",
            "Number of trainable parameters : 23,771,336\n",
            "Number of non-trainable parameters : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.946: 100%|██████████| 130/130 [21:21<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 10 Age L1-loss: 15.090 ** Gender accuracy: 0.965 ** Race accuracy: 0.865 ** Avg loss: 3.047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 4.946: 100%|██████████| 130/130 [21:35<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 10 Age L1-loss: 15.008 ** Gender accuracy: 0.915 ** Race accuracy: 0.786 ** Avg loss: 4.276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.955: 100%|██████████| 130/130 [25:08<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 11 Age L1-loss: 15.052 ** Gender accuracy: 0.976 ** Race accuracy: 0.911 ** Avg loss: 2.521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.955: 100%|██████████| 130/130 [25:21<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 11 Age L1-loss: 14.942 ** Gender accuracy: 0.901 ** Race accuracy: 0.781 ** Avg loss: 4.861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.235: 100%|██████████| 130/130 [28:51<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 12 Age L1-loss: 15.044 ** Gender accuracy: 0.982 ** Race accuracy: 0.943 ** Avg loss: 2.200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 3.235: 100%|██████████| 130/130 [29:05<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 12 Age L1-loss: 14.934 ** Gender accuracy: 0.904 ** Race accuracy: 0.792 ** Avg loss: 5.271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.395: 100%|██████████| 130/130 [32:36<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 13 Age L1-loss: 15.049 ** Gender accuracy: 0.977 ** Race accuracy: 0.963 ** Avg loss: 2.119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.395: 100%|██████████| 130/130 [32:49<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 13 Age L1-loss: 14.945 ** Gender accuracy: 0.900 ** Race accuracy: 0.775 ** Avg loss: 5.893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.885: 100%|██████████| 130/130 [36:19<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 14 Age L1-loss: 15.183 ** Gender accuracy: 0.991 ** Race accuracy: 0.954 ** Avg loss: 1.998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.885: 100%|██████████| 130/130 [36:32<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 14 Age L1-loss: 15.102 ** Gender accuracy: 0.909 ** Race accuracy: 0.781 ** Avg loss: 6.417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.335: 100%|██████████| 130/130 [40:02<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 15 Age L1-loss: 15.032 ** Gender accuracy: 0.993 ** Race accuracy: 0.985 ** Avg loss: 1.746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.335: 100%|██████████| 130/130 [40:15<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 15 Age L1-loss: 14.926 ** Gender accuracy: 0.915 ** Race accuracy: 0.803 ** Avg loss: 5.865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.877: 100%|██████████| 130/130 [43:46<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 16 Age L1-loss: 15.035 ** Gender accuracy: 0.991 ** Race accuracy: 0.980 ** Avg loss: 1.763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.877: 100%|██████████| 130/130 [44:00<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 16 Age L1-loss: 14.937 ** Gender accuracy: 0.904 ** Race accuracy: 0.806 ** Avg loss: 6.852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.123: 100%|██████████| 130/130 [47:29<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 17 Age L1-loss: 15.073 ** Gender accuracy: 0.994 ** Race accuracy: 0.987 ** Avg loss: 1.693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.123: 100%|██████████| 130/130 [47:42<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 17 Age L1-loss: 14.948 ** Gender accuracy: 0.919 ** Race accuracy: 0.799 ** Avg loss: 6.312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.658: 100%|██████████| 130/130 [51:11<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 18 Age L1-loss: 15.303 ** Gender accuracy: 0.989 ** Race accuracy: 0.983 ** Avg loss: 1.826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.658: 100%|██████████| 130/130 [51:25<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 18 Age L1-loss: 15.148 ** Gender accuracy: 0.911 ** Race accuracy: 0.796 ** Avg loss: 6.311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.469: 100%|██████████| 130/130 [54:55<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 19 Age L1-loss: 15.125 ** Gender accuracy: 0.990 ** Race accuracy: 0.948 ** Avg loss: 2.074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.469: 100%|██████████| 130/130 [55:08<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 19 Age L1-loss: 15.044 ** Gender accuracy: 0.913 ** Race accuracy: 0.777 ** Avg loss: 6.876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.640: 100%|██████████| 130/130 [58:39<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 20 Age L1-loss: 15.182 ** Gender accuracy: 0.996 ** Race accuracy: 0.981 ** Avg loss: 1.709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.640: 100%|██████████| 130/130 [58:52<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 20 Age L1-loss: 15.032 ** Gender accuracy: 0.926 ** Race accuracy: 0.793 ** Avg loss: 6.356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.853: 100%|██████████| 130/130 [1:02:23<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 21 Age L1-loss: 15.021 ** Gender accuracy: 0.996 ** Race accuracy: 0.983 ** Avg loss: 1.692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.853: 100%|██████████| 130/130 [1:02:37<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 21 Age L1-loss: 14.919 ** Gender accuracy: 0.919 ** Race accuracy: 0.811 ** Avg loss: 6.508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.145: 100%|██████████| 130/130 [1:06:08<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 22 Age L1-loss: 15.200 ** Gender accuracy: 0.989 ** Race accuracy: 0.966 ** Avg loss: 1.919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.145: 100%|██████████| 130/130 [1:06:21<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 22 Age L1-loss: 15.129 ** Gender accuracy: 0.912 ** Race accuracy: 0.789 ** Avg loss: 6.666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.747: 100%|██████████| 130/130 [1:09:53<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 23 Age L1-loss: 15.066 ** Gender accuracy: 0.997 ** Race accuracy: 0.989 ** Avg loss: 1.628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.747: 100%|██████████| 130/130 [1:10:06<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 23 Age L1-loss: 14.975 ** Gender accuracy: 0.922 ** Race accuracy: 0.805 ** Avg loss: 6.545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.898: 100%|██████████| 130/130 [1:13:37<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 24 Age L1-loss: 15.021 ** Gender accuracy: 0.995 ** Race accuracy: 0.974 ** Avg loss: 1.767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.898: 100%|██████████| 130/130 [1:13:50<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 24 Age L1-loss: 14.916 ** Gender accuracy: 0.909 ** Race accuracy: 0.787 ** Avg loss: 6.800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.898: 100%|██████████| 130/130 [1:17:19<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 25 Age L1-loss: 15.029 ** Gender accuracy: 0.997 ** Race accuracy: 0.992 ** Avg loss: 1.598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.898: 100%|██████████| 130/130 [1:17:33<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 25 Age L1-loss: 14.925 ** Gender accuracy: 0.917 ** Race accuracy: 0.807 ** Avg loss: 6.633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.138: 100%|██████████| 130/130 [1:21:03<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 26 Age L1-loss: 15.013 ** Gender accuracy: 0.993 ** Race accuracy: 0.928 ** Avg loss: 2.251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.138: 100%|██████████| 130/130 [1:21:16<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 26 Age L1-loss: 14.905 ** Gender accuracy: 0.908 ** Race accuracy: 0.760 ** Avg loss: 8.684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.746: 100%|██████████| 130/130 [1:24:45<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 27 Age L1-loss: 15.144 ** Gender accuracy: 0.996 ** Race accuracy: 0.981 ** Avg loss: 1.711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.746: 100%|██████████| 130/130 [1:24:59<00:00,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 27 Age L1-loss: 15.064 ** Gender accuracy: 0.917 ** Race accuracy: 0.801 ** Avg loss: 7.580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.899: 100%|██████████| 130/130 [1:28:28<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 28 Age L1-loss: 15.013 ** Gender accuracy: 0.997 ** Race accuracy: 0.990 ** Avg loss: 1.617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.899: 100%|██████████| 130/130 [1:28:41<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 28 Age L1-loss: 14.909 ** Gender accuracy: 0.914 ** Race accuracy: 0.803 ** Avg loss: 7.586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.813: 100%|██████████| 130/130 [1:32:11<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 29 Age L1-loss: 15.448 ** Gender accuracy: 0.998 ** Race accuracy: 0.987 ** Avg loss: 1.670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.813: 100%|██████████| 130/130 [1:32:24<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 29 Age L1-loss: 15.378 ** Gender accuracy: 0.921 ** Race accuracy: 0.796 ** Avg loss: 7.049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.815: 100%|██████████| 130/130 [1:35:54<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 30 Age L1-loss: 15.016 ** Gender accuracy: 0.998 ** Race accuracy: 0.991 ** Avg loss: 1.585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.815: 100%|██████████| 130/130 [1:36:08<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 30 Age L1-loss: 14.913 ** Gender accuracy: 0.918 ** Race accuracy: 0.808 ** Avg loss: 7.282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.490: 100%|██████████| 130/130 [1:39:41<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 31 Age L1-loss: 15.019 ** Gender accuracy: 0.998 ** Race accuracy: 0.995 ** Avg loss: 1.564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.490: 100%|██████████| 130/130 [1:39:54<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 31 Age L1-loss: 14.903 ** Gender accuracy: 0.916 ** Race accuracy: 0.813 ** Avg loss: 7.831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.456: 100%|██████████| 130/130 [1:43:26<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 32 Age L1-loss: 15.171 ** Gender accuracy: 0.989 ** Race accuracy: 0.978 ** Avg loss: 1.879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.456: 100%|██████████| 130/130 [1:43:39<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 32 Age L1-loss: 15.097 ** Gender accuracy: 0.903 ** Race accuracy: 0.785 ** Avg loss: 8.416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.850: 100%|██████████| 130/130 [1:47:09<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 33 Age L1-loss: 15.427 ** Gender accuracy: 0.997 ** Race accuracy: 0.989 ** Avg loss: 1.656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.850: 100%|██████████| 130/130 [1:47:22<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 33 Age L1-loss: 15.360 ** Gender accuracy: 0.918 ** Race accuracy: 0.805 ** Avg loss: 7.160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.586: 100%|██████████| 130/130 [1:50:53<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 34 Age L1-loss: 15.059 ** Gender accuracy: 0.992 ** Race accuracy: 0.974 ** Avg loss: 1.837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.586: 100%|██████████| 130/130 [1:51:06<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 34 Age L1-loss: 14.970 ** Gender accuracy: 0.913 ** Race accuracy: 0.801 ** Avg loss: 7.740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.788: 100%|██████████| 130/130 [1:54:36<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 35 Age L1-loss: 15.111 ** Gender accuracy: 0.994 ** Race accuracy: 0.979 ** Avg loss: 1.754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.788: 100%|██████████| 130/130 [1:54:49<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 35 Age L1-loss: 15.035 ** Gender accuracy: 0.913 ** Race accuracy: 0.801 ** Avg loss: 7.291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.564: 100%|██████████| 130/130 [1:58:21<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 36 Age L1-loss: 15.022 ** Gender accuracy: 0.996 ** Race accuracy: 0.992 ** Avg loss: 1.606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.564: 100%|██████████| 130/130 [1:58:34<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 36 Age L1-loss: 14.925 ** Gender accuracy: 0.919 ** Race accuracy: 0.801 ** Avg loss: 7.436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.587: 100%|██████████| 130/130 [2:02:05<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 37 Age L1-loss: 15.013 ** Gender accuracy: 0.998 ** Race accuracy: 0.991 ** Avg loss: 1.586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.587: 100%|██████████| 130/130 [2:02:18<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 37 Age L1-loss: 14.908 ** Gender accuracy: 0.925 ** Race accuracy: 0.814 ** Avg loss: 7.165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.637: 100%|██████████| 130/130 [2:05:48<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 38 Age L1-loss: 15.024 ** Gender accuracy: 0.997 ** Race accuracy: 0.993 ** Avg loss: 1.600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.637: 100%|██████████| 130/130 [2:06:02<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 38 Age L1-loss: 14.903 ** Gender accuracy: 0.919 ** Race accuracy: 0.806 ** Avg loss: 7.429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.992: 100%|██████████| 130/130 [2:09:31<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 39 Age L1-loss: 15.012 ** Gender accuracy: 0.993 ** Race accuracy: 0.986 ** Avg loss: 1.712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.992: 100%|██████████| 130/130 [2:09:45<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 39 Age L1-loss: 14.910 ** Gender accuracy: 0.911 ** Race accuracy: 0.808 ** Avg loss: 7.024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.815: 100%|██████████| 130/130 [2:13:16<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 40 Age L1-loss: 15.045 ** Gender accuracy: 0.998 ** Race accuracy: 0.986 ** Avg loss: 1.634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.815: 100%|██████████| 130/130 [2:13:30<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 40 Age L1-loss: 14.949 ** Gender accuracy: 0.922 ** Race accuracy: 0.804 ** Avg loss: 7.191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.890: 100%|██████████| 130/130 [2:17:02<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 41 Age L1-loss: 15.048 ** Gender accuracy: 0.998 ** Race accuracy: 0.996 ** Avg loss: 1.562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.890: 100%|██████████| 130/130 [2:17:16<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 41 Age L1-loss: 14.921 ** Gender accuracy: 0.920 ** Race accuracy: 0.820 ** Avg loss: 6.882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.669: 100%|██████████| 130/130 [2:20:46<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 42 Age L1-loss: 15.048 ** Gender accuracy: 0.998 ** Race accuracy: 0.993 ** Avg loss: 1.575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.669: 100%|██████████| 130/130 [2:21:00<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 42 Age L1-loss: 14.954 ** Gender accuracy: 0.923 ** Race accuracy: 0.807 ** Avg loss: 7.299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.819: 100%|██████████| 130/130 [2:24:31<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 43 Age L1-loss: 15.052 ** Gender accuracy: 0.997 ** Race accuracy: 0.994 ** Avg loss: 1.594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.819: 100%|██████████| 130/130 [2:24:44<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 43 Age L1-loss: 14.953 ** Gender accuracy: 0.913 ** Race accuracy: 0.807 ** Avg loss: 7.272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.649: 100%|██████████| 130/130 [2:28:15<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 44 Age L1-loss: 15.042 ** Gender accuracy: 0.997 ** Race accuracy: 0.994 ** Avg loss: 1.587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.649: 100%|██████████| 130/130 [2:28:29<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 44 Age L1-loss: 14.940 ** Gender accuracy: 0.922 ** Race accuracy: 0.811 ** Avg loss: 7.256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.485: 100%|██████████| 130/130 [2:31:59<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 45 Age L1-loss: 15.051 ** Gender accuracy: 0.998 ** Race accuracy: 0.987 ** Avg loss: 1.612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.485: 100%|██████████| 130/130 [2:32:12<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 45 Age L1-loss: 14.920 ** Gender accuracy: 0.927 ** Race accuracy: 0.800 ** Avg loss: 8.209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.688: 100%|██████████| 130/130 [2:35:44<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 46 Age L1-loss: 15.168 ** Gender accuracy: 0.996 ** Race accuracy: 0.993 ** Avg loss: 1.630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.688: 100%|██████████| 130/130 [2:35:57<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 46 Age L1-loss: 15.085 ** Gender accuracy: 0.923 ** Race accuracy: 0.812 ** Avg loss: 7.659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.470: 100%|██████████| 130/130 [2:39:27<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 47 Age L1-loss: 15.061 ** Gender accuracy: 0.995 ** Race accuracy: 0.992 ** Avg loss: 1.660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.470: 100%|██████████| 130/130 [2:39:40<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 47 Age L1-loss: 14.924 ** Gender accuracy: 0.923 ** Race accuracy: 0.809 ** Avg loss: 7.250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.362: 100%|██████████| 130/130 [2:43:09<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 48 Age L1-loss: 15.129 ** Gender accuracy: 0.989 ** Race accuracy: 0.986 ** Avg loss: 1.824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.362: 100%|██████████| 130/130 [2:43:22<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 48 Age L1-loss: 14.975 ** Gender accuracy: 0.909 ** Race accuracy: 0.817 ** Avg loss: 7.714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.751: 100%|██████████| 130/130 [2:46:52<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 49 Age L1-loss: 15.031 ** Gender accuracy: 0.998 ** Race accuracy: 0.986 ** Avg loss: 1.613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.751: 100%|██████████| 130/130 [2:47:05<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 49 Age L1-loss: 14.937 ** Gender accuracy: 0.928 ** Race accuracy: 0.808 ** Avg loss: 6.863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.549: 100%|██████████| 130/130 [2:50:35<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 50 Age L1-loss: 15.110 ** Gender accuracy: 0.998 ** Race accuracy: 0.993 ** Avg loss: 1.575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.549: 100%|██████████| 130/130 [2:50:48<00:00,  1.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 50 Age L1-loss: 15.023 ** Gender accuracy: 0.920 ** Race accuracy: 0.814 ** Avg loss: 7.241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.583: 100%|██████████| 130/130 [2:54:21<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 51 Age L1-loss: 15.064 ** Gender accuracy: 0.997 ** Race accuracy: 0.989 ** Avg loss: 1.631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.583: 100%|██████████| 130/130 [2:54:35<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 51 Age L1-loss: 14.927 ** Gender accuracy: 0.916 ** Race accuracy: 0.807 ** Avg loss: 7.241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.779: 100%|██████████| 130/130 [2:58:06<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 52 Age L1-loss: 15.013 ** Gender accuracy: 0.998 ** Race accuracy: 0.992 ** Avg loss: 1.580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.779: 100%|██████████| 130/130 [2:58:20<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 52 Age L1-loss: 14.909 ** Gender accuracy: 0.915 ** Race accuracy: 0.810 ** Avg loss: 7.896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.948: 100%|██████████| 130/130 [3:01:50<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 53 Age L1-loss: 15.015 ** Gender accuracy: 0.999 ** Race accuracy: 0.997 ** Avg loss: 1.538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.948: 100%|██████████| 130/130 [3:02:03<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 53 Age L1-loss: 14.901 ** Gender accuracy: 0.927 ** Race accuracy: 0.821 ** Avg loss: 6.944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.575: 100%|██████████| 130/130 [3:05:34<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 54 Age L1-loss: 15.036 ** Gender accuracy: 0.999 ** Race accuracy: 0.996 ** Avg loss: 1.538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.575: 100%|██████████| 130/130 [3:05:47<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 54 Age L1-loss: 14.947 ** Gender accuracy: 0.924 ** Race accuracy: 0.815 ** Avg loss: 7.518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.729: 100%|██████████| 130/130 [3:09:17<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 55 Age L1-loss: 15.011 ** Gender accuracy: 0.999 ** Race accuracy: 0.997 ** Avg loss: 1.531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.729: 100%|██████████| 130/130 [3:09:30<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 55 Age L1-loss: 14.905 ** Gender accuracy: 0.924 ** Race accuracy: 0.819 ** Avg loss: 7.692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.487: 100%|██████████| 130/130 [3:13:02<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 56 Age L1-loss: 15.015 ** Gender accuracy: 0.997 ** Race accuracy: 0.991 ** Avg loss: 1.601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.487: 100%|██████████| 130/130 [3:13:15<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 56 Age L1-loss: 14.907 ** Gender accuracy: 0.916 ** Race accuracy: 0.823 ** Avg loss: 8.535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.952: 100%|██████████| 130/130 [3:16:45<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 57 Age L1-loss: 15.040 ** Gender accuracy: 0.996 ** Race accuracy: 0.980 ** Avg loss: 1.720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.952: 100%|██████████| 130/130 [3:16:58<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 57 Age L1-loss: 14.945 ** Gender accuracy: 0.915 ** Race accuracy: 0.804 ** Avg loss: 7.286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.430: 100%|██████████| 130/130 [3:20:28<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 58 Age L1-loss: 15.299 ** Gender accuracy: 0.997 ** Race accuracy: 0.974 ** Avg loss: 1.798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.430: 100%|██████████| 130/130 [3:20:41<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 58 Age L1-loss: 15.209 ** Gender accuracy: 0.923 ** Race accuracy: 0.784 ** Avg loss: 7.614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.758: 100%|██████████| 130/130 [3:24:12<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 59 Age L1-loss: 15.078 ** Gender accuracy: 0.996 ** Race accuracy: 0.990 ** Avg loss: 1.633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.758: 100%|██████████| 130/130 [3:24:25<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 59 Age L1-loss: 14.935 ** Gender accuracy: 0.921 ** Race accuracy: 0.804 ** Avg loss: 7.677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.063: 100%|██████████| 130/130 [3:27:55<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 60 Age L1-loss: 15.106 ** Gender accuracy: 0.996 ** Race accuracy: 0.989 ** Avg loss: 1.639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 2.063: 100%|██████████| 130/130 [3:28:08<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 60 Age L1-loss: 15.011 ** Gender accuracy: 0.924 ** Race accuracy: 0.808 ** Avg loss: 6.503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.479: 100%|██████████| 130/130 [3:31:42<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 61 Age L1-loss: 15.013 ** Gender accuracy: 0.997 ** Race accuracy: 0.994 ** Avg loss: 1.589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ITERATION - loss: 1.479: 100%|██████████| 130/130 [3:31:55<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 61 Age L1-loss: 14.911 ** Gender accuracy: 0.922 ** Race accuracy: 0.817 ** Avg loss: 6.650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGCCAYAAACb9gvzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK4cdURcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The execution took 3.0 hours | 31.0 minutes | 57.5 seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TQNjrG_LePFl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q45G7NAbUeu9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3 Finetuning a pretrained VGG19"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "g1c4Z5xpePkl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "backup_path = \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/vgg_adam\"\n",
        "os.makedirs(backup_path, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f6588db9-d826-45fe-aeba-f3534498fda0",
        "id": "G8cAnX-eePkp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "my_model = PretrainedMT(model_name='vgg', feature_extract=True, use_pretrained=True)\n",
        "my_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, my_model.parameters()), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.torch/models/vgg19_bn-c79401a0.pth\n",
            "574769405it [00:06, 83291644.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9e26dde3-eb6c-446f-e1f9-480528054fe3",
        "id": "UGuIp90fePkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53621
        }
      },
      "cell_type": "code",
      "source": [
        "run_utk(my_model, my_optimizer, epochs=300, log_interval=1, dataloaders=my_data_loaders,\n",
        "        dirname='/content/checkpoints/vgg_adam', filename_prefix='vgg', n_saved=1,\n",
        "        log_dir='/content/logs', launch_tensorboard=False, patience=50,\n",
        "        resume_model=None, resume_optimizer=None, backup_step=5, backup_path=backup_path,\n",
        "        n_epochs_freeze=10, n_cycle=None, lr_after_freeze=1e-4,\n",
        "        loss_weights=[1/10, 1/0.16, 1/0.44], lr_plot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 0.000:   0%|          | 0/130 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters : 525,448\n",
            "Number of non-trainable parameters : 139,581,248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.420:   1%|          | 1/130 [00:04<08:36,  4.00s/it]\u001b[A\n",
            "ITERATION - loss: 8.672:   2%|▏         | 2/130 [00:05<06:48,  3.19s/it]\u001b[A\n",
            "ITERATION - loss: 7.899:   2%|▏         | 3/130 [00:06<05:32,  2.62s/it]\u001b[A\n",
            "ITERATION - loss: 7.681:   3%|▎         | 4/130 [00:07<04:38,  2.21s/it]\u001b[A\n",
            "ITERATION - loss: 7.555:   4%|▍         | 5/130 [00:09<04:01,  1.93s/it]\u001b[A\n",
            "ITERATION - loss: 8.807:   5%|▍         | 6/130 [00:10<03:34,  1.73s/it]\u001b[A\n",
            "ITERATION - loss: 7.650:   5%|▌         | 7/130 [00:11<03:15,  1.59s/it]\u001b[A\n",
            "ITERATION - loss: 6.962:   6%|▌         | 8/130 [00:12<03:02,  1.49s/it]\u001b[A\n",
            "ITERATION - loss: 7.780:   7%|▋         | 9/130 [00:14<02:53,  1.43s/it]\u001b[A\n",
            "ITERATION - loss: 6.818:   8%|▊         | 10/130 [00:15<02:45,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 7.324:   8%|▊         | 11/130 [00:16<02:40,  1.34s/it]\u001b[A\n",
            "ITERATION - loss: 8.033:   9%|▉         | 12/130 [00:18<02:36,  1.32s/it]\u001b[A\n",
            "ITERATION - loss: 8.030:  10%|█         | 13/130 [00:19<02:32,  1.31s/it]\u001b[A\n",
            "ITERATION - loss: 8.092:  11%|█         | 14/130 [00:20<02:29,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.803:  12%|█▏        | 15/130 [00:21<02:27,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.590:  12%|█▏        | 16/130 [00:23<02:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.378:  13%|█▎        | 17/130 [00:24<02:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.387:  14%|█▍        | 18/130 [00:25<02:22,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.532:  15%|█▍        | 19/130 [00:26<02:21,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.876:  15%|█▌        | 20/130 [00:28<02:19,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.110:  16%|█▌        | 21/130 [00:29<02:18,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.804:  17%|█▋        | 22/130 [00:30<02:17,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.195:  18%|█▊        | 23/130 [00:31<02:16,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.748:  18%|█▊        | 24/130 [00:33<02:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.004:  19%|█▉        | 25/130 [00:34<02:13,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.510:  20%|██        | 26/130 [00:35<02:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.166:  21%|██        | 27/130 [00:37<02:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.389:  22%|██▏       | 28/130 [00:38<02:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.116:  22%|██▏       | 29/130 [00:39<02:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.288:  23%|██▎       | 30/130 [00:40<02:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.599:  24%|██▍       | 31/130 [00:42<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.309:  25%|██▍       | 32/130 [00:43<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.256:  25%|██▌       | 33/130 [00:44<02:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.398:  26%|██▌       | 34/130 [00:46<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.971:  27%|██▋       | 35/130 [00:47<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.275:  28%|██▊       | 36/130 [00:48<02:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.458:  28%|██▊       | 37/130 [00:49<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.103:  29%|██▉       | 38/130 [00:51<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.653:  30%|███       | 39/130 [00:52<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.309:  31%|███       | 40/130 [00:53<01:55,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.122:  32%|███▏      | 41/130 [00:54<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.530:  32%|███▏      | 42/130 [00:56<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.631:  33%|███▎      | 43/130 [00:57<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 8.134:  34%|███▍      | 44/130 [00:58<01:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.393:  35%|███▍      | 45/130 [01:00<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.731:  35%|███▌      | 46/130 [01:01<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.219:  36%|███▌      | 47/130 [01:02<01:45,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.429:  37%|███▋      | 48/130 [01:03<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.078:  38%|███▊      | 49/130 [01:05<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.492:  38%|███▊      | 50/130 [01:06<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.170:  39%|███▉      | 51/130 [01:07<01:41,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.088:  40%|████      | 52/130 [01:09<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.189:  41%|████      | 53/130 [01:10<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.636:  42%|████▏     | 54/130 [01:11<01:36,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.832:  42%|████▏     | 55/130 [01:12<01:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.903:  43%|████▎     | 56/130 [01:14<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.187:  44%|████▍     | 57/130 [01:15<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.329:  45%|████▍     | 58/130 [01:16<01:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.695:  45%|████▌     | 59/130 [01:17<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.766:  46%|████▌     | 60/130 [01:19<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.028:  47%|████▋     | 61/130 [01:20<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.962:  48%|████▊     | 62/130 [01:21<01:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.476:  48%|████▊     | 63/130 [01:23<01:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.762:  49%|████▉     | 64/130 [01:24<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.903:  50%|█████     | 65/130 [01:25<01:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.764:  51%|█████     | 66/130 [01:26<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.147:  52%|█████▏    | 67/130 [01:28<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.061:  52%|█████▏    | 68/130 [01:29<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.753:  53%|█████▎    | 69/130 [01:30<01:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.939:  54%|█████▍    | 70/130 [01:32<01:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.161:  55%|█████▍    | 71/130 [01:33<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.443:  55%|█████▌    | 72/130 [01:34<01:13,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.812:  56%|█████▌    | 73/130 [01:35<01:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.377:  57%|█████▋    | 74/130 [01:37<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.464:  58%|█████▊    | 75/130 [01:38<01:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.608:  58%|█████▊    | 76/130 [01:39<01:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.317:  59%|█████▉    | 77/130 [01:40<01:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.458:  60%|██████    | 78/130 [01:42<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.926:  61%|██████    | 79/130 [01:43<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.036:  62%|██████▏   | 80/130 [01:44<01:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.605:  62%|██████▏   | 81/130 [01:46<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.135:  63%|██████▎   | 82/130 [01:47<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.869:  64%|██████▍   | 83/130 [01:48<01:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.574:  65%|██████▍   | 84/130 [01:49<00:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.187:  65%|██████▌   | 85/130 [01:51<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.870:  66%|██████▌   | 86/130 [01:52<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.413:  67%|██████▋   | 87/130 [01:53<00:55,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.392:  68%|██████▊   | 88/130 [01:55<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.641:  68%|██████▊   | 89/130 [01:56<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.651:  69%|██████▉   | 90/130 [01:57<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.924:  70%|███████   | 91/130 [01:58<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.247:  71%|███████   | 92/130 [02:00<00:48,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.329:  72%|███████▏  | 93/130 [02:01<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.813:  72%|███████▏  | 94/130 [02:02<00:45,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.342:  73%|███████▎  | 95/130 [02:04<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.110:  74%|███████▍  | 96/130 [02:05<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.853:  75%|███████▍  | 97/130 [02:06<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.688:  75%|███████▌  | 98/130 [02:07<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.802:  76%|███████▌  | 99/130 [02:09<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.685:  77%|███████▋  | 100/130 [02:10<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.753:  78%|███████▊  | 101/130 [02:11<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.927:  78%|███████▊  | 102/130 [02:12<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.814:  79%|███████▉  | 103/130 [02:14<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.722:  80%|████████  | 104/130 [02:15<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.508:  81%|████████  | 105/130 [02:16<00:32,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.739:  82%|████████▏ | 106/130 [02:18<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.626:  82%|████████▏ | 107/130 [02:19<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.523:  83%|████████▎ | 108/130 [02:20<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.427:  84%|████████▍ | 109/130 [02:21<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.118:  85%|████████▍ | 110/130 [02:23<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.783:  85%|████████▌ | 111/130 [02:24<00:24,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.982:  86%|████████▌ | 112/130 [02:25<00:22,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.026:  87%|████████▋ | 113/130 [02:27<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.578:  88%|████████▊ | 114/130 [02:28<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.033:  88%|████████▊ | 115/130 [02:29<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.410:  89%|████████▉ | 116/130 [02:30<00:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.519:  90%|█████████ | 117/130 [02:32<00:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.398:  91%|█████████ | 118/130 [02:33<00:15,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.218:  92%|█████████▏| 119/130 [02:34<00:14,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.924:  92%|█████████▏| 120/130 [02:35<00:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.329:  93%|█████████▎| 121/130 [02:37<00:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.303:  94%|█████████▍| 122/130 [02:38<00:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 8.318:  95%|█████████▍| 123/130 [02:39<00:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.726:  95%|█████████▌| 124/130 [02:41<00:07,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.229:  96%|█████████▌| 125/130 [02:42<00:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.392:  97%|█████████▋| 126/130 [02:43<00:05,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.674:  98%|█████████▊| 127/130 [02:44<00:03,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.266:  98%|█████████▊| 128/130 [02:46<00:02,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.495:  99%|█████████▉| 129/130 [02:47<00:01,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.304: 100%|██████████| 130/130 [02:48<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [06:09<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.304: 100%|██████████| 130/130 [05:35<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 1 Age L1-loss: 15.653 ** Gender accuracy: 0.782 ** Race accuracy: 0.605 ** Avg loss: 6.787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [06:48<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.304: 100%|██████████| 130/130 [06:13<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 1 Age L1-loss: 15.503 ** Gender accuracy: 0.775 ** Race accuracy: 0.575 ** Avg loss: 7.002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 7.011:   1%|          | 1/130 [06:18<2:16:59, 63.72s/it]\u001b[A\n",
            "ITERATION - loss: 7.147:   2%|▏         | 2/130 [06:19<1:36:00, 45.00s/it]\u001b[A\n",
            "ITERATION - loss: 7.149:   2%|▏         | 3/130 [06:20<1:07:30, 31.89s/it]\u001b[A\n",
            "ITERATION - loss: 7.808:   3%|▎         | 4/130 [06:21<47:41, 22.71s/it]  \u001b[A\n",
            "ITERATION - loss: 6.481:   4%|▍         | 5/130 [06:23<33:54, 16.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.031:   5%|▍         | 6/130 [06:24<24:20, 11.78s/it]\u001b[A\n",
            "ITERATION - loss: 7.747:   5%|▌         | 7/130 [06:25<17:41,  8.63s/it]\u001b[A\n",
            "ITERATION - loss: 6.697:   6%|▌         | 8/130 [06:27<13:03,  6.42s/it]\u001b[A\n",
            "ITERATION - loss: 8.311:   7%|▋         | 9/130 [06:28<09:50,  4.88s/it]\u001b[A\n",
            "ITERATION - loss: 6.224:   8%|▊         | 10/130 [06:29<07:35,  3.80s/it]\u001b[A\n",
            "ITERATION - loss: 7.331:   8%|▊         | 11/130 [06:30<06:02,  3.04s/it]\u001b[A\n",
            "ITERATION - loss: 6.733:   9%|▉         | 12/130 [06:32<04:56,  2.52s/it]\u001b[A\n",
            "ITERATION - loss: 6.654:  10%|█         | 13/130 [06:33<04:10,  2.14s/it]\u001b[A\n",
            "ITERATION - loss: 7.457:  11%|█         | 14/130 [06:34<03:38,  1.89s/it]\u001b[A\n",
            "ITERATION - loss: 7.312:  12%|█▏        | 15/130 [06:35<03:15,  1.70s/it]\u001b[A\n",
            "ITERATION - loss: 7.442:  12%|█▏        | 16/130 [06:37<02:59,  1.57s/it]\u001b[A\n",
            "ITERATION - loss: 6.736:  13%|█▎        | 17/130 [06:38<02:47,  1.48s/it]\u001b[A\n",
            "ITERATION - loss: 6.631:  14%|█▍        | 18/130 [06:39<02:39,  1.42s/it]\u001b[A\n",
            "ITERATION - loss: 6.555:  15%|█▍        | 19/130 [06:41<02:33,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 7.468:  15%|█▌        | 20/130 [06:42<02:28,  1.35s/it]\u001b[A\n",
            "ITERATION - loss: 7.283:  16%|█▌        | 21/130 [06:43<02:24,  1.33s/it]\u001b[A\n",
            "ITERATION - loss: 6.881:  17%|█▋        | 22/130 [06:44<02:21,  1.31s/it]\u001b[A\n",
            "ITERATION - loss: 6.534:  18%|█▊        | 23/130 [06:46<02:19,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.559:  18%|█▊        | 24/130 [06:47<02:17,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.466:  19%|█▉        | 25/130 [06:48<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.388:  20%|██        | 26/130 [06:50<02:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.272:  21%|██        | 27/130 [06:51<02:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.306:  22%|██▏       | 28/130 [06:52<02:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.773:  22%|██▏       | 29/130 [06:53<02:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.785:  23%|██▎       | 30/130 [06:55<02:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.257:  24%|██▍       | 31/130 [06:56<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.950:  25%|██▍       | 32/130 [06:57<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.760:  25%|██▌       | 33/130 [06:58<02:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.627:  26%|██▌       | 34/130 [07:00<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.550:  27%|██▋       | 35/130 [07:01<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.010:  28%|██▊       | 36/130 [07:02<02:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.465:  28%|██▊       | 37/130 [07:04<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.986:  29%|██▉       | 38/130 [07:05<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.662:  30%|███       | 39/130 [07:06<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.366:  31%|███       | 40/130 [07:07<01:54,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.539:  32%|███▏      | 41/130 [07:09<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.051:  32%|███▏      | 42/130 [07:10<01:52,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.093:  33%|███▎      | 43/130 [07:11<01:50,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.411:  34%|███▍      | 44/130 [07:13<01:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.596:  35%|███▍      | 45/130 [07:14<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.883:  35%|███▌      | 46/130 [07:15<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.950:  36%|███▌      | 47/130 [07:16<01:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.737:  37%|███▋      | 48/130 [07:18<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.272:  38%|███▊      | 49/130 [07:19<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.260:  38%|███▊      | 50/130 [07:20<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.465:  39%|███▉      | 51/130 [07:21<01:41,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.873:  40%|████      | 52/130 [07:23<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.885:  41%|████      | 53/130 [07:24<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.694:  42%|████▏     | 54/130 [07:25<01:36,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.616:  42%|████▏     | 55/130 [07:27<01:35,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.384:  43%|████▎     | 56/130 [07:28<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.227:  44%|████▍     | 57/130 [07:29<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.635:  45%|████▍     | 58/130 [07:30<01:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.754:  45%|████▌     | 59/130 [07:32<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.335:  46%|████▌     | 60/130 [07:33<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.688:  47%|████▋     | 61/130 [07:34<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.186:  48%|████▊     | 62/130 [07:36<01:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.325:  48%|████▊     | 63/130 [07:37<01:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.132:  49%|████▉     | 64/130 [07:38<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.546:  50%|█████     | 65/130 [07:39<01:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.367:  51%|█████     | 66/130 [07:41<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.647:  52%|█████▏    | 67/130 [07:42<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.357:  52%|█████▏    | 68/130 [07:43<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.960:  53%|█████▎    | 69/130 [07:44<01:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.605:  54%|█████▍    | 70/130 [07:46<01:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.874:  55%|█████▍    | 71/130 [07:47<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.759:  55%|█████▌    | 72/130 [07:48<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.511:  56%|█████▌    | 73/130 [07:50<01:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.179:  57%|█████▋    | 74/130 [07:51<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.731:  58%|█████▊    | 75/130 [07:52<01:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.894:  58%|█████▊    | 76/130 [07:53<01:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.146:  59%|█████▉    | 77/130 [07:55<01:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.838:  60%|██████    | 78/130 [07:56<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.854:  61%|██████    | 79/130 [07:57<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.298:  62%|██████▏   | 80/130 [07:59<01:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.927:  62%|██████▏   | 81/130 [08:00<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.737:  63%|██████▎   | 82/130 [08:01<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.336:  64%|██████▍   | 83/130 [08:02<01:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.584:  65%|██████▍   | 84/130 [08:04<00:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.912:  65%|██████▌   | 85/130 [08:05<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.115:  66%|██████▌   | 86/130 [08:06<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.515:  67%|██████▋   | 87/130 [08:07<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.570:  68%|██████▊   | 88/130 [08:09<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.258:  68%|██████▊   | 89/130 [08:10<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.905:  69%|██████▉   | 90/130 [08:11<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.315:  70%|███████   | 91/130 [08:13<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.085:  71%|███████   | 92/130 [08:14<00:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.749:  72%|███████▏  | 93/130 [08:15<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.646:  72%|███████▏  | 94/130 [08:16<00:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.885:  73%|███████▎  | 95/130 [08:18<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.099:  74%|███████▍  | 96/130 [08:19<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.910:  75%|███████▍  | 97/130 [08:20<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.452:  75%|███████▌  | 98/130 [08:22<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.025:  76%|███████▌  | 99/130 [08:23<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.920:  77%|███████▋  | 100/130 [08:24<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.170:  78%|███████▊  | 101/130 [08:25<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.908:  78%|███████▊  | 102/130 [08:27<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.996:  79%|███████▉  | 103/130 [08:28<00:35,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 7.134:  80%|████████  | 104/130 [08:29<00:33,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.693:  81%|████████  | 105/130 [08:31<00:32,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.091:  82%|████████▏ | 106/130 [08:32<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.975:  82%|████████▏ | 107/130 [08:33<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.425:  83%|████████▎ | 108/130 [08:34<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.459:  84%|████████▍ | 109/130 [08:36<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.323:  85%|████████▍ | 110/130 [08:37<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.034:  85%|████████▌ | 111/130 [08:38<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.307:  86%|████████▌ | 112/130 [08:40<00:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.970:  87%|████████▋ | 113/130 [08:41<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.993:  88%|████████▊ | 114/130 [08:42<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.474:  88%|████████▊ | 115/130 [08:43<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.688:  89%|████████▉ | 116/130 [08:45<00:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.840:  90%|█████████ | 117/130 [08:46<00:16,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.882:  91%|█████████ | 118/130 [08:47<00:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.747:  92%|█████████▏| 119/130 [08:48<00:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.462:  92%|█████████▏| 120/130 [08:50<00:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.591:  93%|█████████▎| 121/130 [08:51<00:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.401:  94%|█████████▍| 122/130 [08:52<00:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.877:  95%|█████████▍| 123/130 [08:54<00:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.413:  95%|█████████▌| 124/130 [08:55<00:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.293:  96%|█████████▌| 125/130 [08:56<00:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.488:  97%|█████████▋| 126/130 [08:57<00:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.761:  98%|█████████▊| 127/130 [08:59<00:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.660:  98%|█████████▊| 128/130 [09:00<00:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.506:  99%|█████████▉| 129/130 [09:01<00:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.455: 100%|██████████| 130/130 [09:02<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [12:21<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.455: 100%|██████████| 130/130 [11:47<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 2 Age L1-loss: 15.590 ** Gender accuracy: 0.822 ** Race accuracy: 0.629 ** Avg loss: 6.313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [12:59<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.455: 100%|██████████| 130/130 [12:25<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 2 Age L1-loss: 15.451 ** Gender accuracy: 0.810 ** Race accuracy: 0.599 ** Avg loss: 6.573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 6.296:   1%|          | 1/130 [12:29<2:15:20, 62.95s/it]\u001b[A\n",
            "ITERATION - loss: 6.742:   2%|▏         | 2/130 [12:31<1:34:51, 44.46s/it]\u001b[A\n",
            "ITERATION - loss: 6.636:   2%|▏         | 3/130 [12:32<1:06:42, 31.52s/it]\u001b[A\n",
            "ITERATION - loss: 7.373:   3%|▎         | 4/130 [12:33<47:08, 22.45s/it]  \u001b[A\n",
            "ITERATION - loss: 6.420:   4%|▍         | 5/130 [12:34<33:31, 16.09s/it]\u001b[A\n",
            "ITERATION - loss: 6.931:   5%|▍         | 6/130 [12:36<24:04, 11.65s/it]\u001b[A\n",
            "ITERATION - loss: 6.666:   5%|▌         | 7/130 [12:37<17:29,  8.53s/it]\u001b[A\n",
            "ITERATION - loss: 6.235:   6%|▌         | 8/130 [12:38<12:55,  6.35s/it]\u001b[A\n",
            "ITERATION - loss: 6.616:   7%|▋         | 9/130 [12:40<09:45,  4.83s/it]\u001b[A\n",
            "ITERATION - loss: 6.888:   8%|▊         | 10/130 [12:41<07:32,  3.77s/it]\u001b[A\n",
            "ITERATION - loss: 6.504:   8%|▊         | 11/130 [12:42<06:00,  3.03s/it]\u001b[A\n",
            "ITERATION - loss: 6.745:   9%|▉         | 12/130 [12:43<04:55,  2.50s/it]\u001b[A\n",
            "ITERATION - loss: 6.971:  10%|█         | 13/130 [12:45<04:09,  2.13s/it]\u001b[A\n",
            "ITERATION - loss: 6.550:  11%|█         | 14/130 [12:46<03:37,  1.88s/it]\u001b[A\n",
            "ITERATION - loss: 6.496:  12%|█▏        | 15/130 [12:47<03:14,  1.70s/it]\u001b[A\n",
            "ITERATION - loss: 6.971:  12%|█▏        | 16/130 [12:48<02:58,  1.57s/it]\u001b[A\n",
            "ITERATION - loss: 7.127:  13%|█▎        | 17/130 [12:50<02:47,  1.48s/it]\u001b[A\n",
            "ITERATION - loss: 7.113:  14%|█▍        | 18/130 [12:51<02:39,  1.42s/it]\u001b[A\n",
            "ITERATION - loss: 6.216:  15%|█▍        | 19/130 [12:52<02:33,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 6.393:  15%|█▌        | 20/130 [12:54<02:28,  1.35s/it]\u001b[A\n",
            "ITERATION - loss: 6.285:  16%|█▌        | 21/130 [12:55<02:24,  1.33s/it]\u001b[A\n",
            "ITERATION - loss: 6.478:  17%|█▋        | 22/130 [12:56<02:22,  1.32s/it]\u001b[A\n",
            "ITERATION - loss: 6.200:  18%|█▊        | 23/130 [12:57<02:19,  1.31s/it]\u001b[A\n",
            "ITERATION - loss: 6.993:  18%|█▊        | 24/130 [12:59<02:17,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.624:  19%|█▉        | 25/130 [13:00<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.771:  20%|██        | 26/130 [13:01<02:14,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.013:  21%|██        | 27/130 [13:03<02:12,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.160:  22%|██▏       | 28/130 [13:04<02:11,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.321:  22%|██▏       | 29/130 [13:05<02:10,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.555:  23%|██▎       | 30/130 [13:06<02:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.087:  24%|██▍       | 31/130 [13:08<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.035:  25%|██▍       | 32/130 [13:09<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.634:  25%|██▌       | 33/130 [13:10<02:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.020:  26%|██▌       | 34/130 [13:12<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.002:  27%|██▋       | 35/130 [13:13<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.947:  28%|██▊       | 36/130 [13:14<02:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.385:  28%|██▊       | 37/130 [13:15<01:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.745:  29%|██▉       | 38/130 [13:17<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.225:  30%|███       | 39/130 [13:18<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.032:  31%|███       | 40/130 [13:19<01:55,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.466:  32%|███▏      | 41/130 [13:21<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.533:  32%|███▏      | 42/130 [13:22<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.993:  33%|███▎      | 43/130 [13:23<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.288:  34%|███▍      | 44/130 [13:24<01:50,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.864:  35%|███▍      | 45/130 [13:26<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.455:  35%|███▌      | 46/130 [13:27<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.703:  36%|███▌      | 47/130 [13:28<01:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.477:  37%|███▋      | 48/130 [13:29<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.299:  38%|███▊      | 49/130 [13:31<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.735:  38%|███▊      | 50/130 [13:32<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.192:  39%|███▉      | 51/130 [13:33<01:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.408:  40%|████      | 52/130 [13:35<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.592:  41%|████      | 53/130 [13:36<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.583:  42%|████▏     | 54/130 [13:37<01:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.179:  42%|████▏     | 55/130 [13:38<01:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.724:  43%|████▎     | 56/130 [13:40<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.824:  44%|████▍     | 57/130 [13:41<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.907:  45%|████▍     | 58/130 [13:42<01:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.168:  45%|████▌     | 59/130 [13:44<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.214:  46%|████▌     | 60/130 [13:45<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.771:  47%|████▋     | 61/130 [13:46<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.641:  48%|████▊     | 62/130 [13:47<01:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.170:  48%|████▊     | 63/130 [13:49<01:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.462:  49%|████▉     | 64/130 [13:50<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.465:  50%|█████     | 65/130 [13:51<01:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.363:  51%|█████     | 66/130 [13:52<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.107:  52%|█████▏    | 67/130 [13:54<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.653:  52%|█████▏    | 68/130 [13:55<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.719:  53%|█████▎    | 69/130 [13:56<01:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.457:  54%|█████▍    | 70/130 [13:58<01:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.088:  55%|█████▍    | 71/130 [13:59<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.092:  55%|█████▌    | 72/130 [14:00<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.524:  56%|█████▌    | 73/130 [14:01<01:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.990:  57%|█████▋    | 74/130 [14:03<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.557:  58%|█████▊    | 75/130 [14:04<01:10,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.184:  58%|█████▊    | 76/130 [14:05<01:08,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.398:  59%|█████▉    | 77/130 [14:06<01:07,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 5.957:  60%|██████    | 78/130 [14:08<01:06,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.513:  61%|██████    | 79/130 [14:09<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.073:  62%|██████▏   | 80/130 [14:10<01:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.898:  62%|██████▏   | 81/130 [14:12<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.728:  63%|██████▎   | 82/130 [14:13<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.438:  64%|██████▍   | 83/130 [14:14<00:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.095:  65%|██████▍   | 84/130 [14:15<00:58,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.277:  65%|██████▌   | 85/130 [14:17<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.055:  66%|██████▌   | 86/130 [14:18<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.851:  67%|██████▋   | 87/130 [14:19<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.072:  68%|██████▊   | 88/130 [14:21<00:53,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.061:  68%|██████▊   | 89/130 [14:22<00:52,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.489:  69%|██████▉   | 90/130 [14:23<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.692:  70%|███████   | 91/130 [14:24<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.732:  71%|███████   | 92/130 [14:26<00:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.862:  72%|███████▏  | 93/130 [14:27<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.589:  72%|███████▏  | 94/130 [14:28<00:45,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.409:  73%|███████▎  | 95/130 [14:29<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.956:  74%|███████▍  | 96/130 [14:31<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.135:  75%|███████▍  | 97/130 [14:32<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.655:  75%|███████▌  | 98/130 [14:33<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.065:  76%|███████▌  | 99/130 [14:35<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.426:  77%|███████▋  | 100/130 [14:36<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.892:  78%|███████▊  | 101/130 [14:37<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.551:  78%|███████▊  | 102/130 [14:38<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.450:  79%|███████▉  | 103/130 [14:40<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.386:  80%|████████  | 104/130 [14:41<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.335:  81%|████████  | 105/130 [14:42<00:32,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.927:  82%|████████▏ | 106/130 [14:44<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.129:  82%|████████▏ | 107/130 [14:45<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.628:  83%|████████▎ | 108/130 [14:46<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.363:  84%|████████▍ | 109/130 [14:47<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.454:  85%|████████▍ | 110/130 [14:49<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.102:  85%|████████▌ | 111/130 [14:50<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.927:  86%|████████▌ | 112/130 [14:51<00:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.663:  87%|████████▋ | 113/130 [14:53<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.734:  88%|████████▊ | 114/130 [14:54<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.338:  88%|████████▊ | 115/130 [14:55<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.959:  89%|████████▉ | 116/130 [14:56<00:17,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.794:  90%|█████████ | 117/130 [14:58<00:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.068:  91%|█████████ | 118/130 [14:59<00:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.478:  92%|█████████▏| 119/130 [15:00<00:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.734:  92%|█████████▏| 120/130 [15:01<00:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.266:  93%|█████████▎| 121/130 [15:03<00:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.534:  94%|█████████▍| 122/130 [15:04<00:10,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.836:  95%|█████████▍| 123/130 [15:05<00:08,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.165:  95%|█████████▌| 124/130 [15:07<00:07,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.320:  96%|█████████▌| 125/130 [15:08<00:06,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.753:  97%|█████████▋| 126/130 [15:09<00:05,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.473:  98%|█████████▊| 127/130 [15:10<00:03,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.625:  98%|█████████▊| 128/130 [15:12<00:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.896:  99%|█████████▉| 129/130 [15:13<00:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.612: 100%|██████████| 130/130 [15:14<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [18:36<02:22,  1.26s/it]\n",
            "ITERATION - loss: 7.612: 100%|██████████| 130/130 [18:02<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 3 Age L1-loss: 15.476 ** Gender accuracy: 0.821 ** Race accuracy: 0.631 ** Avg loss: 6.273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [19:14<02:22,  1.26s/it]\n",
            "ITERATION - loss: 7.612: 100%|██████████| 130/130 [18:40<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 3 Age L1-loss: 15.344 ** Gender accuracy: 0.803 ** Race accuracy: 0.605 ** Avg loss: 6.596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 7.539:   1%|          | 1/130 [18:44<2:17:22, 63.89s/it]\u001b[A\n",
            "ITERATION - loss: 6.305:   2%|▏         | 2/130 [18:45<1:36:16, 45.13s/it]\u001b[A\n",
            "ITERATION - loss: 6.800:   2%|▏         | 3/130 [18:47<1:07:41, 31.98s/it]\u001b[A\n",
            "ITERATION - loss: 6.562:   3%|▎         | 4/130 [18:48<47:49, 22.77s/it]  \u001b[A\n",
            "ITERATION - loss: 6.485:   4%|▍         | 5/130 [18:49<34:00, 16.33s/it]\u001b[A\n",
            "ITERATION - loss: 6.792:   5%|▍         | 6/130 [18:51<24:24, 11.81s/it]\u001b[A\n",
            "ITERATION - loss: 6.834:   5%|▌         | 7/130 [18:52<17:43,  8.65s/it]\u001b[A\n",
            "ITERATION - loss: 7.107:   6%|▌         | 8/130 [18:53<13:05,  6.44s/it]\u001b[A\n",
            "ITERATION - loss: 6.506:   7%|▋         | 9/130 [18:54<09:51,  4.89s/it]\u001b[A\n",
            "ITERATION - loss: 6.308:   8%|▊         | 10/130 [18:56<07:37,  3.81s/it]\u001b[A\n",
            "ITERATION - loss: 7.210:   8%|▊         | 11/130 [18:57<06:02,  3.05s/it]\u001b[A\n",
            "ITERATION - loss: 6.781:   9%|▉         | 12/130 [18:58<04:57,  2.52s/it]\u001b[A\n",
            "ITERATION - loss: 6.644:  10%|█         | 13/130 [19:00<04:11,  2.15s/it]\u001b[A\n",
            "ITERATION - loss: 6.454:  11%|█         | 14/130 [19:01<03:39,  1.89s/it]\u001b[A\n",
            "ITERATION - loss: 6.422:  12%|█▏        | 15/130 [19:02<03:15,  1.70s/it]\u001b[A\n",
            "ITERATION - loss: 6.637:  12%|█▏        | 16/130 [19:03<03:00,  1.58s/it]\u001b[A\n",
            "ITERATION - loss: 6.919:  13%|█▎        | 17/130 [19:05<02:48,  1.49s/it]\u001b[A\n",
            "ITERATION - loss: 6.253:  14%|█▍        | 18/130 [19:06<02:39,  1.43s/it]\u001b[A\n",
            "ITERATION - loss: 7.236:  15%|█▍        | 19/130 [19:07<02:33,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 6.892:  15%|█▌        | 20/130 [19:08<02:28,  1.35s/it]\u001b[A\n",
            "ITERATION - loss: 7.259:  16%|█▌        | 21/130 [19:10<02:25,  1.33s/it]\u001b[A\n",
            "ITERATION - loss: 6.163:  17%|█▋        | 22/130 [19:11<02:22,  1.32s/it]\u001b[A\n",
            "ITERATION - loss: 7.051:  18%|█▊        | 23/130 [19:12<02:19,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.440:  18%|█▊        | 24/130 [19:14<02:17,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.321:  19%|█▉        | 25/130 [19:15<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.259:  20%|██        | 26/130 [19:16<02:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.464:  21%|██        | 27/130 [19:17<02:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.152:  22%|██▏       | 28/130 [19:19<02:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.135:  22%|██▏       | 29/130 [19:20<02:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.214:  23%|██▎       | 30/130 [19:21<02:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.660:  24%|██▍       | 31/130 [19:23<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.537:  25%|██▍       | 32/130 [19:24<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.559:  25%|██▌       | 33/130 [19:25<02:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.907:  26%|██▌       | 34/130 [19:26<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.131:  27%|██▋       | 35/130 [19:28<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.795:  28%|██▊       | 36/130 [19:29<01:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.835:  28%|██▊       | 37/130 [19:30<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.265:  29%|██▉       | 38/130 [19:31<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.651:  30%|███       | 39/130 [19:33<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.624:  31%|███       | 40/130 [19:34<01:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.891:  32%|███▏      | 41/130 [19:35<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.854:  32%|███▏      | 42/130 [19:37<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.057:  33%|███▎      | 43/130 [19:38<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.374:  34%|███▍      | 44/130 [19:39<01:50,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.651:  35%|███▍      | 45/130 [19:40<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.036:  35%|███▌      | 46/130 [19:42<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.961:  36%|███▌      | 47/130 [19:43<01:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.914:  37%|███▋      | 48/130 [19:44<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.711:  38%|███▊      | 49/130 [19:46<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.400:  38%|███▊      | 50/130 [19:47<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.243:  39%|███▉      | 51/130 [19:48<01:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.922:  40%|████      | 52/130 [19:49<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.597:  41%|████      | 53/130 [19:51<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.298:  42%|████▏     | 54/130 [19:52<01:36,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.694:  42%|████▏     | 55/130 [19:53<01:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.188:  43%|████▎     | 56/130 [19:55<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.208:  44%|████▍     | 57/130 [19:56<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.921:  45%|████▍     | 58/130 [19:57<01:32,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.041:  45%|████▌     | 59/130 [19:58<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.439:  46%|████▌     | 60/130 [20:00<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.527:  47%|████▋     | 61/130 [20:01<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.775:  48%|████▊     | 62/130 [20:02<01:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.504:  48%|████▊     | 63/130 [20:03<01:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.980:  49%|████▉     | 64/130 [20:05<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.485:  50%|█████     | 65/130 [20:06<01:22,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.727:  51%|█████     | 66/130 [20:07<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.303:  52%|█████▏    | 67/130 [20:09<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.559:  52%|█████▏    | 68/130 [20:10<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.243:  53%|█████▎    | 69/130 [20:11<01:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.034:  54%|█████▍    | 70/130 [20:12<01:17,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.340:  55%|█████▍    | 71/130 [20:14<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.549:  55%|█████▌    | 72/130 [20:15<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.653:  56%|█████▌    | 73/130 [20:16<01:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.891:  57%|█████▋    | 74/130 [20:18<01:12,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.604:  58%|█████▊    | 75/130 [20:19<01:10,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.878:  58%|█████▊    | 76/130 [20:20<01:09,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.989:  59%|█████▉    | 77/130 [20:21<01:08,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.938:  60%|██████    | 78/130 [20:23<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.118:  61%|██████    | 79/130 [20:24<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.798:  62%|██████▏   | 80/130 [20:25<01:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.411:  62%|██████▏   | 81/130 [20:27<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.117:  63%|██████▎   | 82/130 [20:28<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.789:  64%|██████▍   | 83/130 [20:29<01:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.282:  65%|██████▍   | 84/130 [20:30<00:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.377:  65%|██████▌   | 85/130 [20:32<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.547:  66%|██████▌   | 86/130 [20:33<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.992:  67%|██████▋   | 87/130 [20:34<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.472:  68%|██████▊   | 88/130 [20:36<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.023:  68%|██████▊   | 89/130 [20:37<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.607:  69%|██████▉   | 90/130 [20:38<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.834:  70%|███████   | 91/130 [20:39<00:50,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.158:  71%|███████   | 92/130 [20:41<00:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.128:  72%|███████▏  | 93/130 [20:42<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.122:  72%|███████▏  | 94/130 [20:43<00:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.771:  73%|███████▎  | 95/130 [20:45<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.896:  74%|███████▍  | 96/130 [20:46<00:43,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.164:  75%|███████▍  | 97/130 [20:47<00:42,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.061:  75%|███████▌  | 98/130 [20:48<00:41,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.736:  76%|███████▌  | 99/130 [20:50<00:39,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.488:  77%|███████▋  | 100/130 [20:51<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.808:  78%|███████▊  | 101/130 [20:52<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.364:  78%|███████▊  | 102/130 [20:53<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.473:  79%|███████▉  | 103/130 [20:55<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.956:  80%|████████  | 104/130 [20:56<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.614:  81%|████████  | 105/130 [20:57<00:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.715:  82%|████████▏ | 106/130 [20:59<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.444:  82%|████████▏ | 107/130 [21:00<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.449:  83%|████████▎ | 108/130 [21:01<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.640:  84%|████████▍ | 109/130 [21:02<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.526:  85%|████████▍ | 110/130 [21:04<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.767:  85%|████████▌ | 111/130 [21:05<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.373:  86%|████████▌ | 112/130 [21:06<00:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.645:  87%|████████▋ | 113/130 [21:08<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.938:  88%|████████▊ | 114/130 [21:09<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.239:  88%|████████▊ | 115/130 [21:10<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.132:  89%|████████▉ | 116/130 [21:11<00:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.068:  90%|█████████ | 117/130 [21:13<00:16,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.620:  91%|█████████ | 118/130 [21:14<00:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.970:  92%|█████████▏| 119/130 [21:15<00:14,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.140:  92%|█████████▏| 120/130 [21:16<00:12,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.041:  93%|█████████▎| 121/130 [21:18<00:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.036:  94%|█████████▍| 122/130 [21:19<00:10,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.157:  95%|█████████▍| 123/130 [21:20<00:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.389:  95%|█████████▌| 124/130 [21:22<00:07,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.038:  96%|█████████▌| 125/130 [21:23<00:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.762:  97%|█████████▋| 126/130 [21:24<00:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.160:  98%|█████████▊| 127/130 [21:25<00:03,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 5.859:  98%|█████████▊| 128/130 [21:27<00:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.299:  99%|█████████▉| 129/130 [21:28<00:01,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.437: 100%|██████████| 130/130 [21:29<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [24:48<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.437: 100%|██████████| 130/130 [24:14<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 4 Age L1-loss: 15.347 ** Gender accuracy: 0.820 ** Race accuracy: 0.648 ** Avg loss: 6.194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [25:26<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.437: 100%|██████████| 130/130 [24:52<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 4 Age L1-loss: 15.235 ** Gender accuracy: 0.808 ** Race accuracy: 0.606 ** Avg loss: 6.510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 6.411:   1%|          | 1/130 [24:56<2:15:10, 62.87s/it]\u001b[A\n",
            "ITERATION - loss: 7.188:   2%|▏         | 2/130 [24:57<1:34:45, 44.42s/it]\u001b[A\n",
            "ITERATION - loss: 6.295:   2%|▏         | 3/130 [24:58<1:06:39, 31.49s/it]\u001b[A\n",
            "ITERATION - loss: 6.864:   3%|▎         | 4/130 [25:00<47:05, 22.43s/it]  \u001b[A\n",
            "ITERATION - loss: 6.401:   4%|▍         | 5/130 [25:01<33:30, 16.08s/it]\u001b[A\n",
            "ITERATION - loss: 6.268:   5%|▍         | 6/130 [25:02<24:03, 11.64s/it]\u001b[A\n",
            "ITERATION - loss: 6.402:   5%|▌         | 7/130 [25:04<17:29,  8.53s/it]\u001b[A\n",
            "ITERATION - loss: 6.776:   6%|▌         | 8/130 [25:05<12:55,  6.35s/it]\u001b[A\n",
            "ITERATION - loss: 6.593:   7%|▋         | 9/130 [25:06<09:44,  4.83s/it]\u001b[A\n",
            "ITERATION - loss: 7.646:   8%|▊         | 10/130 [25:07<07:31,  3.77s/it]\u001b[A\n",
            "ITERATION - loss: 7.197:   8%|▊         | 11/130 [25:09<05:59,  3.02s/it]\u001b[A\n",
            "ITERATION - loss: 6.502:   9%|▉         | 12/130 [25:10<04:55,  2.50s/it]\u001b[A\n",
            "ITERATION - loss: 6.873:  10%|█         | 13/130 [25:11<04:09,  2.13s/it]\u001b[A\n",
            "ITERATION - loss: 6.618:  11%|█         | 14/130 [25:12<03:37,  1.88s/it]\u001b[A\n",
            "ITERATION - loss: 6.276:  12%|█▏        | 15/130 [25:14<03:15,  1.70s/it]\u001b[A\n",
            "ITERATION - loss: 6.752:  12%|█▏        | 16/130 [25:15<02:58,  1.57s/it]\u001b[A\n",
            "ITERATION - loss: 6.514:  13%|█▎        | 17/130 [25:16<02:47,  1.48s/it]\u001b[A\n",
            "ITERATION - loss: 6.424:  14%|█▍        | 18/130 [25:18<02:39,  1.42s/it]\u001b[A\n",
            "ITERATION - loss: 6.869:  15%|█▍        | 19/130 [25:19<02:33,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 6.211:  15%|█▌        | 20/130 [25:20<02:28,  1.35s/it]\u001b[A\n",
            "ITERATION - loss: 6.779:  16%|█▌        | 21/130 [25:21<02:25,  1.33s/it]\u001b[A\n",
            "ITERATION - loss: 6.256:  17%|█▋        | 22/130 [25:23<02:21,  1.31s/it]\u001b[A\n",
            "ITERATION - loss: 6.779:  18%|█▊        | 23/130 [25:24<02:19,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.018:  18%|█▊        | 24/130 [25:25<02:17,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.898:  19%|█▉        | 25/130 [25:27<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.729:  20%|██        | 26/130 [25:28<02:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.207:  21%|██        | 27/130 [25:29<02:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.968:  22%|██▏       | 28/130 [25:30<02:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.584:  22%|██▏       | 29/130 [25:32<02:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.969:  23%|██▎       | 30/130 [25:33<02:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.464:  24%|██▍       | 31/130 [25:34<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.419:  25%|██▍       | 32/130 [25:35<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.100:  25%|██▌       | 33/130 [25:37<02:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.407:  26%|██▌       | 34/130 [25:38<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.588:  27%|██▋       | 35/130 [25:39<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.531:  28%|██▊       | 36/130 [25:41<01:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.660:  28%|██▊       | 37/130 [25:42<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.893:  29%|██▉       | 38/130 [25:43<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.025:  30%|███       | 39/130 [25:44<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.214:  31%|███       | 40/130 [25:46<01:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.787:  32%|███▏      | 41/130 [25:47<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.844:  32%|███▏      | 42/130 [25:48<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.957:  33%|███▎      | 43/130 [25:50<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.558:  34%|███▍      | 44/130 [25:51<01:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.288:  35%|███▍      | 45/130 [25:52<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.787:  35%|███▌      | 46/130 [25:53<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.441:  36%|███▌      | 47/130 [25:55<01:45,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.290:  37%|███▋      | 48/130 [25:56<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.197:  38%|███▊      | 49/130 [25:57<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.924:  38%|███▊      | 50/130 [25:58<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.846:  39%|███▉      | 51/130 [26:00<01:41,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.245:  40%|████      | 52/130 [26:01<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.474:  41%|████      | 53/130 [26:02<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.249:  42%|████▏     | 54/130 [26:04<01:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.745:  42%|████▏     | 55/130 [26:05<01:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.267:  43%|████▎     | 56/130 [26:06<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.946:  44%|████▍     | 57/130 [26:07<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.555:  45%|████▍     | 58/130 [26:09<01:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.545:  45%|████▌     | 59/130 [26:10<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.979:  46%|████▌     | 60/130 [26:11<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.375:  47%|████▋     | 61/130 [26:12<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.807:  48%|████▊     | 62/130 [26:14<01:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.610:  48%|████▊     | 63/130 [26:15<01:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.135:  49%|████▉     | 64/130 [26:16<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.167:  50%|█████     | 65/130 [26:18<01:22,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.905:  51%|█████     | 66/130 [26:19<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.823:  52%|█████▏    | 67/130 [26:20<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.448:  52%|█████▏    | 68/130 [26:21<01:19,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.892:  53%|█████▎    | 69/130 [26:23<01:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.111:  54%|█████▍    | 70/130 [26:24<01:16,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.017:  55%|█████▍    | 71/130 [26:25<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.168:  55%|█████▌    | 72/130 [26:27<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.570:  56%|█████▌    | 73/130 [26:28<01:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.636:  57%|█████▋    | 74/130 [26:29<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.329:  58%|█████▊    | 75/130 [26:30<01:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.373:  58%|█████▊    | 76/130 [26:32<01:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.174:  59%|█████▉    | 77/130 [26:33<01:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.926:  60%|██████    | 78/130 [26:34<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.845:  61%|██████    | 79/130 [26:35<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.822:  62%|██████▏   | 80/130 [26:37<01:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.103:  62%|██████▏   | 81/130 [26:38<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.437:  63%|██████▎   | 82/130 [26:39<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.858:  64%|██████▍   | 83/130 [26:41<00:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.295:  65%|██████▍   | 84/130 [26:42<00:58,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.370:  65%|██████▌   | 85/130 [26:43<00:57,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.531:  66%|██████▌   | 86/130 [26:44<00:56,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.715:  67%|██████▋   | 87/130 [26:46<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.563:  68%|██████▊   | 88/130 [26:47<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.620:  68%|██████▊   | 89/130 [26:48<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.201:  69%|██████▉   | 90/130 [26:50<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.455:  70%|███████   | 91/130 [26:51<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.486:  71%|███████   | 92/130 [26:52<00:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.326:  72%|███████▏  | 93/130 [26:53<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.557:  72%|███████▏  | 94/130 [26:55<00:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.848:  73%|███████▎  | 95/130 [26:56<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.141:  74%|███████▍  | 96/130 [26:57<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.361:  75%|███████▍  | 97/130 [26:58<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.684:  75%|███████▌  | 98/130 [27:00<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.870:  76%|███████▌  | 99/130 [27:01<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.592:  77%|███████▋  | 100/130 [27:02<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.751:  78%|███████▊  | 101/130 [27:04<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.592:  78%|███████▊  | 102/130 [27:05<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.451:  79%|███████▉  | 103/130 [27:06<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.132:  80%|████████  | 104/130 [27:07<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.723:  81%|████████  | 105/130 [27:09<00:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.475:  82%|████████▏ | 106/130 [27:10<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.956:  82%|████████▏ | 107/130 [27:11<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.898:  83%|████████▎ | 108/130 [27:13<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.735:  84%|████████▍ | 109/130 [27:14<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.588:  85%|████████▍ | 110/130 [27:15<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.779:  85%|████████▌ | 111/130 [27:16<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.954:  86%|████████▌ | 112/130 [27:18<00:22,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.761:  87%|████████▋ | 113/130 [27:19<00:21,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.246:  88%|████████▊ | 114/130 [27:20<00:20,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.586:  88%|████████▊ | 115/130 [27:21<00:19,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.656:  89%|████████▉ | 116/130 [27:23<00:17,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.515:  90%|█████████ | 117/130 [27:24<00:16,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.602:  91%|█████████ | 118/130 [27:25<00:15,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.645:  92%|█████████▏| 119/130 [27:27<00:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.674:  92%|█████████▏| 120/130 [27:28<00:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.635:  93%|█████████▎| 121/130 [27:29<00:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.456:  94%|█████████▍| 122/130 [27:30<00:10,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.124:  95%|█████████▍| 123/130 [27:32<00:08,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.552:  95%|█████████▌| 124/130 [27:33<00:07,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.055:  96%|█████████▌| 125/130 [27:34<00:06,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.666:  97%|█████████▋| 126/130 [27:35<00:05,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.001:  98%|█████████▊| 127/130 [27:37<00:03,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.253:  98%|█████████▊| 128/130 [27:38<00:02,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.935:  99%|█████████▉| 129/130 [27:39<00:01,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.872: 100%|██████████| 130/130 [27:40<00:00,  1.16s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [31:02<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.872: 100%|██████████| 130/130 [30:28<00:00,  1.16s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 5 Age L1-loss: 15.369 ** Gender accuracy: 0.826 ** Race accuracy: 0.648 ** Avg loss: 6.133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [31:40<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.872: 100%|██████████| 130/130 [31:05<00:00,  1.16s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 5 Age L1-loss: 15.244 ** Gender accuracy: 0.810 ** Race accuracy: 0.612 ** Avg loss: 6.464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 6.370:   1%|          | 1/130 [31:13<2:18:45, 64.54s/it]\u001b[A\n",
            "ITERATION - loss: 6.971:   2%|▏         | 2/130 [31:14<1:37:15, 45.59s/it]\u001b[A\n",
            "ITERATION - loss: 7.084:   2%|▏         | 3/130 [31:15<1:08:21, 32.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.539:   3%|▎         | 4/130 [31:17<48:16, 22.99s/it]  \u001b[A\n",
            "ITERATION - loss: 6.815:   4%|▍         | 5/130 [31:18<34:19, 16.48s/it]\u001b[A\n",
            "ITERATION - loss: 6.270:   5%|▍         | 6/130 [31:19<24:37, 11.92s/it]\u001b[A\n",
            "ITERATION - loss: 7.042:   5%|▌         | 7/130 [31:20<17:53,  8.73s/it]\u001b[A\n",
            "ITERATION - loss: 6.890:   6%|▌         | 8/130 [31:22<13:12,  6.50s/it]\u001b[A\n",
            "ITERATION - loss: 6.373:   7%|▋         | 9/130 [31:23<09:56,  4.93s/it]\u001b[A\n",
            "ITERATION - loss: 6.362:   8%|▊         | 10/130 [31:24<07:40,  3.84s/it]\u001b[A\n",
            "ITERATION - loss: 6.337:   8%|▊         | 11/130 [31:26<06:05,  3.07s/it]\u001b[A\n",
            "ITERATION - loss: 6.580:   9%|▉         | 12/130 [31:27<04:58,  2.53s/it]\u001b[A\n",
            "ITERATION - loss: 6.177:  10%|█         | 13/130 [31:28<04:12,  2.15s/it]\u001b[A\n",
            "ITERATION - loss: 6.446:  11%|█         | 14/130 [31:29<03:39,  1.89s/it]\u001b[A\n",
            "ITERATION - loss: 5.862:  12%|█▏        | 15/130 [31:31<03:16,  1.71s/it]\u001b[A\n",
            "ITERATION - loss: 6.231:  12%|█▏        | 16/130 [31:32<03:00,  1.58s/it]\u001b[A\n",
            "ITERATION - loss: 6.419:  13%|█▎        | 17/130 [31:33<02:48,  1.49s/it]\u001b[A\n",
            "ITERATION - loss: 6.960:  14%|█▍        | 18/130 [31:34<02:39,  1.43s/it]\u001b[A\n",
            "ITERATION - loss: 6.543:  15%|█▍        | 19/130 [31:36<02:33,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 6.685:  15%|█▌        | 20/130 [31:37<02:28,  1.35s/it]\u001b[A\n",
            "ITERATION - loss: 6.243:  16%|█▌        | 21/130 [31:38<02:24,  1.33s/it]\u001b[A\n",
            "ITERATION - loss: 6.763:  17%|█▋        | 22/130 [31:40<02:21,  1.31s/it]\u001b[A\n",
            "ITERATION - loss: 6.642:  18%|█▊        | 23/130 [31:41<02:19,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.556:  18%|█▊        | 24/130 [31:42<02:17,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.641:  19%|█▉        | 25/130 [31:43<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.548:  20%|██        | 26/130 [31:45<02:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.674:  21%|██        | 27/130 [31:46<02:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.968:  22%|██▏       | 28/130 [31:47<02:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.901:  22%|██▏       | 29/130 [31:49<02:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.359:  23%|██▎       | 30/130 [31:50<02:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.989:  24%|██▍       | 31/130 [31:51<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.227:  25%|██▍       | 32/130 [31:52<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.704:  25%|██▌       | 33/130 [31:54<02:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.646:  26%|██▌       | 34/130 [31:55<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.408:  27%|██▋       | 35/130 [31:56<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.526:  28%|██▊       | 36/130 [31:57<02:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.838:  28%|██▊       | 37/130 [31:59<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.393:  29%|██▉       | 38/130 [32:00<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.674:  30%|███       | 39/130 [32:01<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.373:  31%|███       | 40/130 [32:03<01:55,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.844:  32%|███▏      | 41/130 [32:04<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.930:  32%|███▏      | 42/130 [32:05<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.032:  33%|███▎      | 43/130 [32:06<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.729:  34%|███▍      | 44/130 [32:08<01:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.385:  35%|███▍      | 45/130 [32:09<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.302:  35%|███▌      | 46/130 [32:10<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.105:  36%|███▌      | 47/130 [32:12<01:45,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.798:  37%|███▋      | 48/130 [32:13<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.446:  38%|███▊      | 49/130 [32:14<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.320:  38%|███▊      | 50/130 [32:15<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.646:  39%|███▉      | 51/130 [32:17<01:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.707:  40%|████      | 52/130 [32:18<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.702:  41%|████      | 53/130 [32:19<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.534:  42%|████▏     | 54/130 [32:20<01:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.094:  42%|████▏     | 55/130 [32:22<01:36,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.674:  43%|████▎     | 56/130 [32:23<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.410:  44%|████▍     | 57/130 [32:24<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.433:  45%|████▍     | 58/130 [32:26<01:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.868:  45%|████▌     | 59/130 [32:27<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.553:  46%|████▌     | 60/130 [32:28<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.079:  47%|████▋     | 61/130 [32:29<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.565:  48%|████▊     | 62/130 [32:31<01:27,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.524:  48%|████▊     | 63/130 [32:32<01:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.199:  49%|████▉     | 64/130 [32:33<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.840:  50%|█████     | 65/130 [32:35<01:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.890:  51%|█████     | 66/130 [32:36<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.670:  52%|█████▏    | 67/130 [32:37<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.288:  52%|█████▏    | 68/130 [32:38<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.311:  53%|█████▎    | 69/130 [32:40<01:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.944:  54%|█████▍    | 70/130 [32:41<01:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.238:  55%|█████▍    | 71/130 [32:42<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.924:  55%|█████▌    | 72/130 [32:43<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.864:  56%|█████▌    | 73/130 [32:45<01:13,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.308:  57%|█████▋    | 74/130 [32:46<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.964:  58%|█████▊    | 75/130 [32:47<01:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.494:  58%|█████▊    | 76/130 [32:49<01:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.702:  59%|█████▉    | 77/130 [32:50<01:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.605:  60%|██████    | 78/130 [32:51<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.170:  61%|██████    | 79/130 [32:52<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.195:  62%|██████▏   | 80/130 [32:54<01:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.438:  62%|██████▏   | 81/130 [32:55<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.102:  63%|██████▎   | 82/130 [32:56<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.981:  64%|██████▍   | 83/130 [32:58<01:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.415:  65%|██████▍   | 84/130 [32:59<00:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.189:  65%|██████▌   | 85/130 [33:00<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.727:  66%|██████▌   | 86/130 [33:01<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.485:  67%|██████▋   | 87/130 [33:03<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.554:  68%|██████▊   | 88/130 [33:04<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.864:  68%|██████▊   | 89/130 [33:05<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.584:  69%|██████▉   | 90/130 [33:06<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.600:  70%|███████   | 91/130 [33:08<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.676:  71%|███████   | 92/130 [33:09<00:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.885:  72%|███████▏  | 93/130 [33:10<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.614:  72%|███████▏  | 94/130 [33:12<00:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.095:  73%|███████▎  | 95/130 [33:13<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.997:  74%|███████▍  | 96/130 [33:14<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.036:  75%|███████▍  | 97/130 [33:15<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.354:  75%|███████▌  | 98/130 [33:17<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.751:  76%|███████▌  | 99/130 [33:18<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.480:  77%|███████▋  | 100/130 [33:19<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.624:  78%|███████▊  | 101/130 [33:21<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.211:  78%|███████▊  | 102/130 [33:22<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.881:  79%|███████▉  | 103/130 [33:23<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.519:  80%|████████  | 104/130 [33:24<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.843:  81%|████████  | 105/130 [33:26<00:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.170:  82%|████████▏ | 106/130 [33:27<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.770:  82%|████████▏ | 107/130 [33:28<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.831:  83%|████████▎ | 108/130 [33:29<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.124:  84%|████████▍ | 109/130 [33:31<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.406:  85%|████████▍ | 110/130 [33:32<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.120:  85%|████████▌ | 111/130 [33:33<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.262:  86%|████████▌ | 112/130 [33:35<00:22,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.004:  87%|████████▋ | 113/130 [33:36<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.092:  88%|████████▊ | 114/130 [33:37<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.597:  88%|████████▊ | 115/130 [33:38<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.397:  89%|████████▉ | 116/130 [33:40<00:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.887:  90%|█████████ | 117/130 [33:41<00:16,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.178:  91%|█████████ | 118/130 [33:42<00:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.054:  92%|█████████▏| 119/130 [33:44<00:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.200:  92%|█████████▏| 120/130 [33:45<00:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.970:  93%|█████████▎| 121/130 [33:46<00:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.180:  94%|█████████▍| 122/130 [33:47<00:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.010:  95%|█████████▍| 123/130 [33:49<00:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.684:  95%|█████████▌| 124/130 [33:50<00:07,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.469:  96%|█████████▌| 125/130 [33:51<00:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.719:  97%|█████████▋| 126/130 [33:52<00:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.177:  98%|█████████▊| 127/130 [33:54<00:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.479:  98%|█████████▊| 128/130 [33:55<00:02,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.426:  99%|█████████▉| 129/130 [33:56<00:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.914: 100%|██████████| 130/130 [33:57<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [37:19<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.914: 100%|██████████| 130/130 [36:45<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 6 Age L1-loss: 16.008 ** Gender accuracy: 0.825 ** Race accuracy: 0.652 ** Avg loss: 6.188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [37:57<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.914: 100%|██████████| 130/130 [37:23<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 6 Age L1-loss: 15.827 ** Gender accuracy: 0.808 ** Race accuracy: 0.617 ** Avg loss: 6.520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 6.535:   1%|          | 1/130 [37:27<2:16:44, 63.60s/it]\u001b[A\n",
            "ITERATION - loss: 6.282:   2%|▏         | 2/130 [37:28<1:35:50, 44.93s/it]\u001b[A\n",
            "ITERATION - loss: 6.106:   2%|▏         | 3/130 [37:29<1:07:23, 31.84s/it]\u001b[A\n",
            "ITERATION - loss: 6.598:   3%|▎         | 4/130 [37:30<47:36, 22.67s/it]  \u001b[A\n",
            "ITERATION - loss: 6.842:   4%|▍         | 5/130 [37:32<33:51, 16.25s/it]\u001b[A\n",
            "ITERATION - loss: 6.223:   5%|▍         | 6/130 [37:33<24:18, 11.76s/it]\u001b[A\n",
            "ITERATION - loss: 6.306:   5%|▌         | 7/130 [37:34<17:39,  8.62s/it]\u001b[A\n",
            "ITERATION - loss: 6.108:   6%|▌         | 8/130 [37:36<13:02,  6.41s/it]\u001b[A\n",
            "ITERATION - loss: 7.247:   7%|▋         | 9/130 [37:37<09:49,  4.87s/it]\u001b[A\n",
            "ITERATION - loss: 6.379:   8%|▊         | 10/130 [37:38<07:35,  3.80s/it]\u001b[A\n",
            "ITERATION - loss: 6.829:   8%|▊         | 11/130 [37:39<06:02,  3.04s/it]\u001b[A\n",
            "ITERATION - loss: 6.816:   9%|▉         | 12/130 [37:41<04:56,  2.51s/it]\u001b[A\n",
            "ITERATION - loss: 6.927:  10%|█         | 13/130 [37:42<04:10,  2.14s/it]\u001b[A\n",
            "ITERATION - loss: 7.049:  11%|█         | 14/130 [37:43<03:38,  1.88s/it]\u001b[A\n",
            "ITERATION - loss: 6.176:  12%|█▏        | 15/130 [37:44<03:15,  1.70s/it]\u001b[A\n",
            "ITERATION - loss: 6.531:  12%|█▏        | 16/130 [37:46<02:58,  1.57s/it]\u001b[A\n",
            "ITERATION - loss: 6.456:  13%|█▎        | 17/130 [37:47<02:47,  1.48s/it]\u001b[A\n",
            "ITERATION - loss: 6.393:  14%|█▍        | 18/130 [37:48<02:39,  1.42s/it]\u001b[A\n",
            "ITERATION - loss: 6.825:  15%|█▍        | 19/130 [37:50<02:32,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 5.869:  15%|█▌        | 20/130 [37:51<02:28,  1.35s/it]\u001b[A\n",
            "ITERATION - loss: 6.928:  16%|█▌        | 21/130 [37:52<02:24,  1.32s/it]\u001b[A\n",
            "ITERATION - loss: 6.633:  17%|█▋        | 22/130 [37:53<02:21,  1.31s/it]\u001b[A\n",
            "ITERATION - loss: 6.829:  18%|█▊        | 23/130 [37:55<02:18,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.804:  18%|█▊        | 24/130 [37:56<02:17,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.320:  19%|█▉        | 25/130 [37:57<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.974:  20%|██        | 26/130 [37:59<02:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.770:  21%|██        | 27/130 [38:00<02:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.395:  22%|██▏       | 28/130 [38:01<02:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.097:  22%|██▏       | 29/130 [38:02<02:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.129:  23%|██▎       | 30/130 [38:04<02:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.237:  24%|██▍       | 31/130 [38:05<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.187:  25%|██▍       | 32/130 [38:06<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.998:  25%|██▌       | 33/130 [38:07<02:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.062:  26%|██▌       | 34/130 [38:09<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.876:  27%|██▋       | 35/130 [38:10<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.615:  28%|██▊       | 36/130 [38:11<01:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.264:  28%|██▊       | 37/130 [38:13<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.472:  29%|██▉       | 38/130 [38:14<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.982:  30%|███       | 39/130 [38:15<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.468:  31%|███       | 40/130 [38:16<01:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.479:  32%|███▏      | 41/130 [38:18<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.816:  32%|███▏      | 42/130 [38:19<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.440:  33%|███▎      | 43/130 [38:20<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.588:  34%|███▍      | 44/130 [38:21<01:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.768:  35%|███▍      | 45/130 [38:23<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.781:  35%|███▌      | 46/130 [38:24<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.178:  36%|███▌      | 47/130 [38:25<01:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.419:  37%|███▋      | 48/130 [38:27<01:45,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.667:  38%|███▊      | 49/130 [38:28<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.147:  38%|███▊      | 50/130 [38:29<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.902:  39%|███▉      | 51/130 [38:30<01:41,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.640:  40%|████      | 52/130 [38:32<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.823:  41%|████      | 53/130 [38:33<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.384:  42%|████▏     | 54/130 [38:34<01:36,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.720:  42%|████▏     | 55/130 [38:36<01:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.311:  43%|████▎     | 56/130 [38:37<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.834:  44%|████▍     | 57/130 [38:38<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.488:  45%|████▍     | 58/130 [38:39<01:32,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.491:  45%|████▌     | 59/130 [38:41<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.927:  46%|████▌     | 60/130 [38:42<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.925:  47%|████▋     | 61/130 [38:43<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.779:  48%|████▊     | 62/130 [38:44<01:26,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.306:  48%|████▊     | 63/130 [38:46<01:25,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.991:  49%|████▉     | 64/130 [38:47<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.889:  50%|█████     | 65/130 [38:48<01:22,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.958:  51%|█████     | 66/130 [38:50<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.869:  52%|█████▏    | 67/130 [38:51<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.241:  52%|█████▏    | 68/130 [38:52<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.200:  53%|█████▎    | 69/130 [38:53<01:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.837:  54%|█████▍    | 70/130 [38:55<01:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.811:  55%|█████▍    | 71/130 [38:56<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.072:  55%|█████▌    | 72/130 [38:57<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.103:  56%|█████▌    | 73/130 [38:59<01:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.265:  57%|█████▋    | 74/130 [39:00<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.157:  58%|█████▊    | 75/130 [39:01<01:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.754:  58%|█████▊    | 76/130 [39:02<01:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.449:  59%|█████▉    | 77/130 [39:04<01:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.035:  60%|██████    | 78/130 [39:05<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.624:  61%|██████    | 79/130 [39:06<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.898:  62%|██████▏   | 80/130 [39:07<01:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.540:  62%|██████▏   | 81/130 [39:09<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.959:  63%|██████▎   | 82/130 [39:10<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.659:  64%|██████▍   | 83/130 [39:11<00:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.546:  65%|██████▍   | 84/130 [39:13<00:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.187:  65%|██████▌   | 85/130 [39:14<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.041:  66%|██████▌   | 86/130 [39:15<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.582:  67%|██████▋   | 87/130 [39:16<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.831:  68%|██████▊   | 88/130 [39:18<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.016:  68%|██████▊   | 89/130 [39:19<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.243:  69%|██████▉   | 90/130 [39:20<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.216:  70%|███████   | 91/130 [39:22<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.403:  71%|███████   | 92/130 [39:23<00:48,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.151:  72%|███████▏  | 93/130 [39:24<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.740:  72%|███████▏  | 94/130 [39:25<00:45,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.031:  73%|███████▎  | 95/130 [39:27<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.365:  74%|███████▍  | 96/130 [39:28<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.523:  75%|███████▍  | 97/130 [39:29<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.341:  75%|███████▌  | 98/130 [39:30<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.044:  76%|███████▌  | 99/130 [39:32<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.064:  77%|███████▋  | 100/130 [39:33<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.590:  78%|███████▊  | 101/130 [39:34<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.828:  78%|███████▊  | 102/130 [39:36<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.672:  79%|███████▉  | 103/130 [39:37<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.807:  80%|████████  | 104/130 [39:38<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.091:  81%|████████  | 105/130 [39:39<00:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.172:  82%|████████▏ | 106/130 [39:41<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.739:  82%|████████▏ | 107/130 [39:42<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.166:  83%|████████▎ | 108/130 [39:43<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.916:  84%|████████▍ | 109/130 [39:45<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.471:  85%|████████▍ | 110/130 [39:46<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.180:  85%|████████▌ | 111/130 [39:47<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.916:  86%|████████▌ | 112/130 [39:48<00:22,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.271:  87%|████████▋ | 113/130 [39:50<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.628:  88%|████████▊ | 114/130 [39:51<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.881:  88%|████████▊ | 115/130 [39:52<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.530:  89%|████████▉ | 116/130 [39:53<00:17,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.748:  90%|█████████ | 117/130 [39:55<00:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.720:  91%|█████████ | 118/130 [39:56<00:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.551:  92%|█████████▏| 119/130 [39:57<00:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.192:  92%|█████████▏| 120/130 [39:59<00:12,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.632:  93%|█████████▎| 121/130 [40:00<00:11,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.128:  94%|█████████▍| 122/130 [40:01<00:10,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 5.838:  95%|█████████▍| 123/130 [40:02<00:08,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.841:  95%|█████████▌| 124/130 [40:04<00:07,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.757:  96%|█████████▌| 125/130 [40:05<00:06,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.107:  97%|█████████▋| 126/130 [40:06<00:05,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.678:  98%|█████████▊| 127/130 [40:07<00:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.560:  98%|█████████▊| 128/130 [40:09<00:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.539:  99%|█████████▉| 129/130 [40:10<00:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.624: 100%|██████████| 130/130 [40:11<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [43:30<02:22,  1.26s/it]\n",
            "ITERATION - loss: 7.624: 100%|██████████| 130/130 [42:56<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 7 Age L1-loss: 15.249 ** Gender accuracy: 0.827 ** Race accuracy: 0.646 ** Avg loss: 6.134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [44:07<02:22,  1.26s/it]\n",
            "ITERATION - loss: 7.624: 100%|██████████| 130/130 [43:33<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 7 Age L1-loss: 15.155 ** Gender accuracy: 0.812 ** Race accuracy: 0.607 ** Avg loss: 6.479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 6.775:   1%|          | 1/130 [43:37<2:14:51, 62.73s/it]\u001b[A\n",
            "ITERATION - loss: 6.788:   2%|▏         | 2/130 [43:39<1:34:31, 44.31s/it]\u001b[A\n",
            "ITERATION - loss: 6.872:   2%|▏         | 3/130 [43:40<1:06:27, 31.40s/it]\u001b[A\n",
            "ITERATION - loss: 6.167:   3%|▎         | 4/130 [43:41<46:57, 22.36s/it]  \u001b[A\n",
            "ITERATION - loss: 6.278:   4%|▍         | 5/130 [43:42<33:24, 16.03s/it]\u001b[A\n",
            "ITERATION - loss: 6.506:   5%|▍         | 6/130 [43:44<23:59, 11.61s/it]\u001b[A\n",
            "ITERATION - loss: 7.128:   5%|▌         | 7/130 [43:45<17:26,  8.51s/it]\u001b[A\n",
            "ITERATION - loss: 6.406:   6%|▌         | 8/130 [43:46<12:53,  6.34s/it]\u001b[A\n",
            "ITERATION - loss: 6.486:   7%|▋         | 9/130 [43:48<09:43,  4.82s/it]\u001b[A\n",
            "ITERATION - loss: 6.199:   8%|▊         | 10/130 [43:49<07:31,  3.76s/it]\u001b[A\n",
            "ITERATION - loss: 6.771:   8%|▊         | 11/130 [43:50<05:58,  3.01s/it]\u001b[A\n",
            "ITERATION - loss: 6.622:   9%|▉         | 12/130 [43:51<04:54,  2.49s/it]\u001b[A\n",
            "ITERATION - loss: 6.354:  10%|█         | 13/130 [43:53<04:09,  2.13s/it]\u001b[A\n",
            "ITERATION - loss: 6.564:  11%|█         | 14/130 [43:54<03:37,  1.87s/it]\u001b[A\n",
            "ITERATION - loss: 6.679:  12%|█▏        | 15/130 [43:55<03:14,  1.69s/it]\u001b[A\n",
            "ITERATION - loss: 6.559:  12%|█▏        | 16/130 [43:56<02:58,  1.57s/it]\u001b[A\n",
            "ITERATION - loss: 6.550:  13%|█▎        | 17/130 [43:58<02:47,  1.48s/it]\u001b[A\n",
            "ITERATION - loss: 6.641:  14%|█▍        | 18/130 [43:59<02:39,  1.42s/it]\u001b[A\n",
            "ITERATION - loss: 6.299:  15%|█▍        | 19/130 [44:00<02:33,  1.38s/it]\u001b[A\n",
            "ITERATION - loss: 6.491:  15%|█▌        | 20/130 [44:02<02:28,  1.35s/it]\u001b[A\n",
            "ITERATION - loss: 6.429:  16%|█▌        | 21/130 [44:03<02:24,  1.33s/it]\u001b[A\n",
            "ITERATION - loss: 5.926:  17%|█▋        | 22/130 [44:04<02:21,  1.31s/it]\u001b[A\n",
            "ITERATION - loss: 7.231:  18%|█▊        | 23/130 [44:05<02:19,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 5.959:  18%|█▊        | 24/130 [44:07<02:17,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.165:  19%|█▉        | 25/130 [44:08<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.141:  20%|██        | 26/130 [44:09<02:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.306:  21%|██        | 27/130 [44:11<02:12,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.623:  22%|██▏       | 28/130 [44:12<02:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.141:  22%|██▏       | 29/130 [44:13<02:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.214:  23%|██▎       | 30/130 [44:14<02:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.095:  24%|██▍       | 31/130 [44:16<02:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.755:  25%|██▍       | 32/130 [44:17<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.317:  25%|██▌       | 33/130 [44:18<02:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.928:  26%|██▌       | 34/130 [44:20<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.241:  27%|██▋       | 35/130 [44:21<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.420:  28%|██▊       | 36/130 [44:22<01:59,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.374:  28%|██▊       | 37/130 [44:23<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.616:  29%|██▉       | 38/130 [44:25<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.391:  30%|███       | 39/130 [44:26<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.909:  31%|███       | 40/130 [44:27<01:55,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.405:  32%|███▏      | 41/130 [44:28<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.501:  32%|███▏      | 42/130 [44:30<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.020:  33%|███▎      | 43/130 [44:31<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.457:  34%|███▍      | 44/130 [44:32<01:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.456:  35%|███▍      | 45/130 [44:34<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.957:  35%|███▌      | 46/130 [44:35<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.852:  36%|███▌      | 47/130 [44:36<01:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.440:  37%|███▋      | 48/130 [44:37<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.574:  38%|███▊      | 49/130 [44:39<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.199:  38%|███▊      | 50/130 [44:40<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.881:  39%|███▉      | 51/130 [44:41<01:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.810:  40%|████      | 52/130 [44:43<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.430:  41%|████      | 53/130 [44:44<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.939:  42%|████▏     | 54/130 [44:45<01:36,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.891:  42%|████▏     | 55/130 [44:46<01:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.751:  43%|████▎     | 56/130 [44:48<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.694:  44%|████▍     | 57/130 [44:49<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.069:  45%|████▍     | 58/130 [44:50<01:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.468:  45%|████▌     | 59/130 [44:51<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.283:  46%|████▌     | 60/130 [44:53<01:29,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.157:  47%|████▋     | 61/130 [44:54<01:27,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.801:  48%|████▊     | 62/130 [44:55<01:26,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.989:  48%|████▊     | 63/130 [44:57<01:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.231:  49%|████▉     | 64/130 [44:58<01:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.804:  50%|█████     | 65/130 [44:59<01:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.132:  51%|█████     | 66/130 [45:00<01:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.553:  52%|█████▏    | 67/130 [45:02<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.865:  52%|█████▏    | 68/130 [45:03<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.202:  53%|█████▎    | 69/130 [45:04<01:18,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.381:  54%|█████▍    | 70/130 [45:06<01:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.827:  55%|█████▍    | 71/130 [45:07<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.130:  55%|█████▌    | 72/130 [45:08<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.150:  56%|█████▌    | 73/130 [45:09<01:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.691:  57%|█████▋    | 74/130 [45:11<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.681:  58%|█████▊    | 75/130 [45:12<01:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.796:  58%|█████▊    | 76/130 [45:13<01:09,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.792:  59%|█████▉    | 77/130 [45:14<01:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.700:  60%|██████    | 78/130 [45:16<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.933:  61%|██████    | 79/130 [45:17<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.242:  62%|██████▏   | 80/130 [45:18<01:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.487:  62%|██████▏   | 81/130 [45:20<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.309:  63%|██████▎   | 82/130 [45:21<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.432:  64%|██████▍   | 83/130 [45:22<01:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.668:  65%|██████▍   | 84/130 [45:23<00:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.504:  65%|██████▌   | 85/130 [45:25<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.160:  66%|██████▌   | 86/130 [45:26<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.484:  67%|██████▋   | 87/130 [45:27<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.219:  68%|██████▊   | 88/130 [45:29<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.135:  68%|██████▊   | 89/130 [45:30<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.677:  69%|██████▉   | 90/130 [45:31<00:50,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.120:  70%|███████   | 91/130 [45:32<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.216:  71%|███████   | 92/130 [45:34<00:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.164:  72%|███████▏  | 93/130 [45:35<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.046:  72%|███████▏  | 94/130 [45:36<00:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.653:  73%|███████▎  | 95/130 [45:37<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.918:  74%|███████▍  | 96/130 [45:39<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.310:  75%|███████▍  | 97/130 [45:40<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.632:  75%|███████▌  | 98/130 [45:41<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.530:  76%|███████▌  | 99/130 [45:43<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.811:  77%|███████▋  | 100/130 [45:44<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.118:  78%|███████▊  | 101/130 [45:45<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.515:  78%|███████▊  | 102/130 [45:46<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.338:  79%|███████▉  | 103/130 [45:48<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.617:  80%|████████  | 104/130 [45:49<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.717:  81%|████████  | 105/130 [45:50<00:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.556:  82%|████████▏ | 106/130 [45:52<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.929:  82%|████████▏ | 107/130 [45:53<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.602:  83%|████████▎ | 108/130 [45:54<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.008:  84%|████████▍ | 109/130 [45:55<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.532:  85%|████████▍ | 110/130 [45:57<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.046:  85%|████████▌ | 111/130 [45:58<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.308:  86%|████████▌ | 112/130 [45:59<00:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.286:  87%|████████▋ | 113/130 [46:00<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.234:  88%|████████▊ | 114/130 [46:02<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.324:  88%|████████▊ | 115/130 [46:03<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.256:  89%|████████▉ | 116/130 [46:04<00:17,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.405:  90%|█████████ | 117/130 [46:06<00:16,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.538:  91%|█████████ | 118/130 [46:07<00:15,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.632:  92%|█████████▏| 119/130 [46:08<00:14,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 5.889:  92%|█████████▏| 120/130 [46:09<00:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.325:  93%|█████████▎| 121/130 [46:11<00:11,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.159:  94%|█████████▍| 122/130 [46:12<00:10,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.593:  95%|█████████▍| 123/130 [46:13<00:08,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.269:  95%|█████████▌| 124/130 [46:14<00:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.783:  96%|█████████▌| 125/130 [46:16<00:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.821:  97%|█████████▋| 126/130 [46:17<00:05,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.737:  98%|█████████▊| 127/130 [46:18<00:03,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.879:  98%|█████████▊| 128/130 [46:20<00:02,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.287:  99%|█████████▉| 129/130 [46:21<00:01,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 7.163: 100%|██████████| 130/130 [46:22<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [49:41<02:22,  1.26s/it]\n",
            "ITERATION - loss: 7.163: 100%|██████████| 130/130 [49:07<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 8 Age L1-loss: 15.627 ** Gender accuracy: 0.820 ** Race accuracy: 0.650 ** Avg loss: 6.163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [50:19<02:22,  1.26s/it]\n",
            "ITERATION - loss: 7.163: 100%|██████████| 130/130 [49:45<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 8 Age L1-loss: 15.476 ** Gender accuracy: 0.801 ** Race accuracy: 0.608 ** Avg loss: 6.538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 6.742:   1%|          | 1/130 [49:49<2:15:17, 62.92s/it]\u001b[A\n",
            "ITERATION - loss: 7.061:   2%|▏         | 2/130 [49:50<1:34:51, 44.46s/it]\u001b[A\n",
            "ITERATION - loss: 6.190:   2%|▏         | 3/130 [49:51<1:06:42, 31.51s/it]\u001b[A\n",
            "ITERATION - loss: 5.895:   3%|▎         | 4/130 [49:53<47:07, 22.44s/it]  \u001b[A\n",
            "ITERATION - loss: 6.580:   4%|▍         | 5/130 [49:54<33:31, 16.09s/it]\u001b[A\n",
            "ITERATION - loss: 6.546:   5%|▍         | 6/130 [49:55<24:04, 11.65s/it]\u001b[A\n",
            "ITERATION - loss: 6.108:   5%|▌         | 7/130 [49:57<17:30,  8.54s/it]\u001b[A\n",
            "ITERATION - loss: 6.859:   6%|▌         | 8/130 [49:58<12:55,  6.36s/it]\u001b[A\n",
            "ITERATION - loss: 6.716:   7%|▋         | 9/130 [49:59<09:45,  4.84s/it]\u001b[A\n",
            "ITERATION - loss: 6.873:   8%|▊         | 10/130 [50:00<07:33,  3.78s/it]\u001b[A\n",
            "ITERATION - loss: 7.165:   8%|▊         | 11/130 [50:02<05:59,  3.02s/it]\u001b[A\n",
            "ITERATION - loss: 6.160:   9%|▉         | 12/130 [50:03<04:55,  2.50s/it]\u001b[A\n",
            "ITERATION - loss: 6.513:  10%|█         | 13/130 [50:04<04:11,  2.15s/it]\u001b[A\n",
            "ITERATION - loss: 6.474:  11%|█         | 14/130 [50:06<03:38,  1.88s/it]\u001b[A\n",
            "ITERATION - loss: 7.707:  12%|█▏        | 15/130 [50:07<03:15,  1.70s/it]\u001b[A\n",
            "ITERATION - loss: 6.670:  12%|█▏        | 16/130 [50:08<02:59,  1.57s/it]\u001b[A\n",
            "ITERATION - loss: 6.237:  13%|█▎        | 17/130 [50:09<02:47,  1.49s/it]\u001b[A\n",
            "ITERATION - loss: 6.463:  14%|█▍        | 18/130 [50:11<02:40,  1.43s/it]\u001b[A\n",
            "ITERATION - loss: 6.449:  15%|█▍        | 19/130 [50:12<02:34,  1.39s/it]\u001b[A\n",
            "ITERATION - loss: 6.660:  15%|█▌        | 20/130 [50:13<02:29,  1.36s/it]\u001b[A\n",
            "ITERATION - loss: 6.495:  16%|█▌        | 21/130 [50:15<02:25,  1.34s/it]\u001b[A\n",
            "ITERATION - loss: 6.006:  17%|█▋        | 22/130 [50:16<02:22,  1.32s/it]\u001b[A\n",
            "ITERATION - loss: 7.456:  18%|█▊        | 23/130 [50:17<02:19,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.014:  18%|█▊        | 24/130 [50:18<02:17,  1.30s/it]\u001b[A\n",
            "ITERATION - loss: 6.305:  19%|█▉        | 25/130 [50:20<02:15,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.279:  20%|██        | 26/130 [50:21<02:13,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.861:  21%|██        | 27/130 [50:22<02:12,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.662:  22%|██▏       | 28/130 [50:24<02:11,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.238:  22%|██▏       | 29/130 [50:25<02:10,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.975:  23%|██▎       | 30/130 [50:26<02:08,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.197:  24%|██▍       | 31/130 [50:27<02:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.139:  25%|██▍       | 32/130 [50:29<02:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.149:  25%|██▌       | 33/130 [50:30<02:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.680:  26%|██▌       | 34/130 [50:31<02:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.020:  27%|██▋       | 35/130 [50:33<02:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.592:  28%|██▊       | 36/130 [50:34<02:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.555:  28%|██▊       | 37/130 [50:35<01:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.972:  29%|██▉       | 38/130 [50:36<01:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.214:  30%|███       | 39/130 [50:38<01:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.799:  31%|███       | 40/130 [50:39<01:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.635:  32%|███▏      | 41/130 [50:40<01:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.603:  32%|███▏      | 42/130 [50:41<01:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.963:  33%|███▎      | 43/130 [50:43<01:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.273:  34%|███▍      | 44/130 [50:44<01:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.954:  35%|███▍      | 45/130 [50:45<01:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.163:  35%|███▌      | 46/130 [50:47<01:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.021:  36%|███▌      | 47/130 [50:48<01:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.383:  37%|███▋      | 48/130 [50:49<01:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.193:  38%|███▊      | 49/130 [50:50<01:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.347:  38%|███▊      | 50/130 [50:52<01:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.566:  39%|███▉      | 51/130 [50:53<01:41,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.567:  40%|████      | 52/130 [50:54<01:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.173:  41%|████      | 53/130 [50:56<01:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.366:  42%|████▏     | 54/130 [50:57<01:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.457:  42%|████▏     | 55/130 [50:58<01:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.343:  43%|████▎     | 56/130 [50:59<01:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.605:  44%|████▍     | 57/130 [51:01<01:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.912:  45%|████▍     | 58/130 [51:02<01:32,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.130:  45%|████▌     | 59/130 [51:03<01:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.042:  46%|████▌     | 60/130 [51:04<01:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.211:  47%|████▋     | 61/130 [51:06<01:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.964:  48%|████▊     | 62/130 [51:07<01:27,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.790:  48%|████▊     | 63/130 [51:08<01:26,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.475:  49%|████▉     | 64/130 [51:10<01:25,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.863:  50%|█████     | 65/130 [51:11<01:23,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 7.349:  51%|█████     | 66/130 [51:12<01:22,  1.29s/it]\u001b[A\n",
            "ITERATION - loss: 6.039:  52%|█████▏    | 67/130 [51:14<01:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.720:  52%|█████▏    | 68/130 [51:15<01:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.117:  53%|█████▎    | 69/130 [51:16<01:18,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.359:  54%|█████▍    | 70/130 [51:17<01:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.161:  55%|█████▍    | 71/130 [51:19<01:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.033:  55%|█████▌    | 72/130 [51:20<01:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.162:  56%|█████▌    | 73/130 [51:21<01:13,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.036:  57%|█████▋    | 74/130 [51:22<01:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.292:  58%|█████▊    | 75/130 [51:24<01:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.947:  58%|█████▊    | 76/130 [51:25<01:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.058:  59%|█████▉    | 77/130 [51:26<01:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.468:  60%|██████    | 78/130 [51:28<01:06,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.478:  61%|██████    | 79/130 [51:29<01:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.790:  62%|██████▏   | 80/130 [51:30<01:04,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.901:  62%|██████▏   | 81/130 [51:31<01:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.094:  63%|██████▎   | 82/130 [51:33<01:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.590:  64%|██████▍   | 83/130 [51:34<01:00,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.865:  65%|██████▍   | 84/130 [51:35<00:58,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.721:  65%|██████▌   | 85/130 [51:37<00:57,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.388:  66%|██████▌   | 86/130 [51:38<00:56,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.244:  67%|██████▋   | 87/130 [51:39<00:54,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.351:  68%|██████▊   | 88/130 [51:40<00:53,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.257:  68%|██████▊   | 89/130 [51:42<00:52,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.625:  69%|██████▉   | 90/130 [51:43<00:51,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.843:  70%|███████   | 91/130 [51:44<00:49,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.019:  71%|███████   | 92/130 [51:45<00:48,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.192:  72%|███████▏  | 93/130 [51:47<00:47,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.818:  72%|███████▏  | 94/130 [51:48<00:46,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.237:  73%|███████▎  | 95/130 [51:49<00:44,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.570:  74%|███████▍  | 96/130 [51:51<00:43,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.256:  75%|███████▍  | 97/130 [51:52<00:42,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.654:  75%|███████▌  | 98/130 [51:53<00:40,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.203:  76%|███████▌  | 99/130 [51:54<00:39,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.248:  77%|███████▋  | 100/130 [51:56<00:38,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.926:  78%|███████▊  | 101/130 [51:57<00:37,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.514:  78%|███████▊  | 102/130 [51:58<00:35,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.952:  79%|███████▉  | 103/130 [52:00<00:34,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.618:  80%|████████  | 104/130 [52:01<00:33,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.596:  81%|████████  | 105/130 [52:02<00:31,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 5.741:  82%|████████▏ | 106/130 [52:03<00:30,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.212:  82%|████████▏ | 107/130 [52:05<00:29,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.301:  83%|████████▎ | 108/130 [52:06<00:28,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.294:  84%|████████▍ | 109/130 [52:07<00:26,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.824:  85%|████████▍ | 110/130 [52:09<00:25,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.663:  85%|████████▌ | 111/130 [52:10<00:24,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.333:  86%|████████▌ | 112/130 [52:11<00:23,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.802:  87%|████████▋ | 113/130 [52:12<00:21,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.611:  88%|████████▊ | 114/130 [52:14<00:20,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.978:  88%|████████▊ | 115/130 [52:15<00:19,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.659:  89%|████████▉ | 116/130 [52:16<00:17,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.067:  90%|█████████ | 117/130 [52:17<00:16,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.776:  91%|█████████ | 118/130 [52:19<00:15,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.514:  92%|█████████▏| 119/130 [52:20<00:14,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.224:  92%|█████████▏| 120/130 [52:21<00:12,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.225:  93%|█████████▎| 121/130 [52:23<00:11,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.897:  94%|█████████▍| 122/130 [52:24<00:10,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.551:  95%|█████████▍| 123/130 [52:25<00:08,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.581:  95%|█████████▌| 124/130 [52:26<00:07,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 7.299:  96%|█████████▌| 125/130 [52:28<00:06,  1.27s/it]\u001b[A\n",
            "ITERATION - loss: 6.328:  97%|█████████▋| 126/130 [52:29<00:05,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.619:  98%|█████████▊| 127/130 [52:30<00:03,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.569:  98%|█████████▊| 128/130 [52:32<00:02,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.690:  99%|█████████▉| 129/130 [52:33<00:01,  1.28s/it]\u001b[A\n",
            "ITERATION - loss: 6.055: 100%|██████████| 130/130 [52:34<00:00,  1.17s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [55:53<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.055: 100%|██████████| 130/130 [55:19<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 9 Age L1-loss: 15.477 ** Gender accuracy: 0.828 ** Race accuracy: 0.656 ** Avg loss: 6.131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [56:31<02:22,  1.26s/it]\n",
            "ITERATION - loss: 6.055: 100%|██████████| 130/130 [55:57<00:00,  1.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 9 Age L1-loss: 15.336 ** Gender accuracy: 0.811 ** Race accuracy: 0.608 ** Avg loss: 6.488\n",
            "****Unfreezing frozen layers ... ***\n",
            "Number of trainable parameters : 140,106,696\n",
            "Number of non-trainable parameters : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 6.580:   1%|          | 1/130 [56:03<2:17:03, 63.75s/it]\u001b[A\n",
            "ITERATION - loss: 6.318:   2%|▏         | 2/130 [56:07<1:37:33, 45.73s/it]\u001b[A\n",
            "ITERATION - loss: 6.178:   2%|▏         | 3/130 [56:11<1:10:05, 33.12s/it]\u001b[A\n",
            "ITERATION - loss: 6.014:   3%|▎         | 4/130 [56:15<50:58, 24.28s/it]  \u001b[A\n",
            "ITERATION - loss: 7.085:   4%|▍         | 5/130 [56:18<37:41, 18.09s/it]\u001b[A\n",
            "ITERATION - loss: 6.714:   5%|▍         | 6/130 [56:22<28:26, 13.77s/it]\u001b[A\n",
            "ITERATION - loss: 5.956:   5%|▌         | 7/130 [56:25<21:58, 10.72s/it]\u001b[A\n",
            "ITERATION - loss: 6.651:   6%|▌         | 8/130 [56:29<17:28,  8.59s/it]\u001b[A\n",
            "ITERATION - loss: 6.063:   7%|▋         | 9/130 [56:33<14:21,  7.12s/it]\u001b[A\n",
            "ITERATION - loss: 5.340:   8%|▊         | 10/130 [56:36<12:09,  6.08s/it]\u001b[A\n",
            "ITERATION - loss: 6.552:   8%|▊         | 11/130 [56:40<10:36,  5.35s/it]\u001b[A\n",
            "ITERATION - loss: 5.412:   9%|▉         | 12/130 [56:44<09:32,  4.85s/it]\u001b[A\n",
            "ITERATION - loss: 5.911:  10%|█         | 13/130 [56:47<08:46,  4.50s/it]\u001b[A\n",
            "ITERATION - loss: 5.560:  11%|█         | 14/130 [56:51<08:12,  4.25s/it]\u001b[A\n",
            "ITERATION - loss: 5.975:  12%|█▏        | 15/130 [56:55<07:47,  4.06s/it]\u001b[A\n",
            "ITERATION - loss: 5.290:  12%|█▏        | 16/130 [56:58<07:28,  3.94s/it]\u001b[A\n",
            "ITERATION - loss: 5.925:  13%|█▎        | 17/130 [57:02<07:15,  3.86s/it]\u001b[A\n",
            "ITERATION - loss: 5.721:  14%|█▍        | 18/130 [57:06<07:05,  3.80s/it]\u001b[A\n",
            "ITERATION - loss: 5.788:  15%|█▍        | 19/130 [57:09<06:56,  3.75s/it]\u001b[A\n",
            "ITERATION - loss: 6.154:  15%|█▌        | 20/130 [57:13<06:49,  3.72s/it]\u001b[A\n",
            "ITERATION - loss: 5.675:  16%|█▌        | 21/130 [57:17<06:43,  3.70s/it]\u001b[A\n",
            "ITERATION - loss: 5.693:  17%|█▋        | 22/130 [57:20<06:38,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 6.423:  18%|█▊        | 23/130 [57:24<06:34,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 5.623:  18%|█▊        | 24/130 [57:28<06:29,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 5.440:  19%|█▉        | 25/130 [57:31<06:25,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 5.231:  20%|██        | 26/130 [57:35<06:21,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 5.649:  21%|██        | 27/130 [57:39<06:18,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 5.460:  22%|██▏       | 28/130 [57:42<06:13,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.155:  22%|██▏       | 29/130 [57:46<06:09,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.950:  23%|██▎       | 30/130 [57:50<06:06,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.038:  24%|██▍       | 31/130 [57:53<06:02,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.720:  25%|██▍       | 32/130 [57:57<05:58,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.026:  25%|██▌       | 33/130 [58:01<05:54,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.921:  26%|██▌       | 34/130 [58:04<05:51,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.038:  27%|██▋       | 35/130 [58:08<05:47,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.194:  28%|██▊       | 36/130 [58:12<05:43,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.767:  28%|██▊       | 37/130 [58:15<05:40,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.469:  29%|██▉       | 38/130 [58:19<05:36,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.391:  30%|███       | 39/130 [58:23<05:32,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.148:  31%|███       | 40/130 [58:26<05:28,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.419:  32%|███▏      | 41/130 [58:30<05:25,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.966:  32%|███▏      | 42/130 [58:33<05:21,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.400:  33%|███▎      | 43/130 [58:37<05:17,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.318:  34%|███▍      | 44/130 [58:41<05:14,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.836:  35%|███▍      | 45/130 [58:44<05:10,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.888:  35%|███▌      | 46/130 [58:48<05:07,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.910:  36%|███▌      | 47/130 [58:52<05:04,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.076:  37%|███▋      | 48/130 [58:55<05:00,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.999:  38%|███▊      | 49/130 [58:59<04:56,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.861:  38%|███▊      | 50/130 [59:03<04:52,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.607:  39%|███▉      | 51/130 [59:06<04:48,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.810:  40%|████      | 52/130 [59:10<04:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.766:  41%|████      | 53/130 [59:14<04:41,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.307:  42%|████▏     | 54/130 [59:17<04:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.106:  42%|████▏     | 55/130 [59:21<04:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.829:  43%|████▎     | 56/130 [59:25<04:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.350:  44%|████▍     | 57/130 [59:28<04:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.938:  45%|████▍     | 58/130 [59:32<04:23,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.574:  45%|████▌     | 59/130 [59:36<04:19,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.965:  46%|████▌     | 60/130 [59:39<04:15,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.038:  47%|████▋     | 61/130 [59:43<04:12,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.400:  48%|████▊     | 62/130 [59:47<04:08,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.770:  48%|████▊     | 63/130 [59:50<04:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.977:  49%|████▉     | 64/130 [59:54<04:00,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.830:  50%|█████     | 65/130 [59:57<03:57,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.631:  51%|█████     | 66/130 [1:00:01<03:53,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.109:  52%|█████▏    | 67/130 [1:00:05<03:50,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.917:  52%|█████▏    | 68/130 [1:00:08<03:47,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.743:  53%|█████▎    | 69/130 [1:00:12<03:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.497:  54%|█████▍    | 70/130 [1:00:16<03:39,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.152:  55%|█████▍    | 71/130 [1:00:19<03:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.154:  55%|█████▌    | 72/130 [1:00:23<03:32,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.473:  56%|█████▌    | 73/130 [1:00:27<03:28,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.279:  57%|█████▋    | 74/130 [1:00:30<03:24,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.438:  58%|█████▊    | 75/130 [1:00:34<03:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.442:  58%|█████▊    | 76/130 [1:00:38<03:16,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.821:  59%|█████▉    | 77/130 [1:00:41<03:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.939:  60%|██████    | 78/130 [1:00:45<03:10,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 4.521:  61%|██████    | 79/130 [1:00:49<03:06,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.318:  62%|██████▏   | 80/130 [1:00:52<03:02,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.242:  62%|██████▏   | 81/130 [1:00:56<02:59,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 5.037:  63%|██████▎   | 82/130 [1:01:00<02:56,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 4.398:  64%|██████▍   | 83/130 [1:01:03<02:52,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.675:  65%|██████▍   | 84/130 [1:01:07<02:48,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.145:  65%|██████▌   | 85/130 [1:01:11<02:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.979:  66%|██████▌   | 86/130 [1:01:14<02:40,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.996:  67%|██████▋   | 87/130 [1:01:18<02:36,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.522:  68%|██████▊   | 88/130 [1:01:22<02:32,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 4.820:  68%|██████▊   | 89/130 [1:01:25<02:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 5.317:  69%|██████▉   | 90/130 [1:01:29<02:26,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.973:  70%|███████   | 91/130 [1:01:33<02:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.172:  71%|███████   | 92/130 [1:01:36<02:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.259:  72%|███████▏  | 93/130 [1:01:40<02:15,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.806:  72%|███████▏  | 94/130 [1:01:43<02:11,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.461:  73%|███████▎  | 95/130 [1:01:47<02:07,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.352:  74%|███████▍  | 96/130 [1:01:51<02:04,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.677:  75%|███████▍  | 97/130 [1:01:54<02:00,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.325:  75%|███████▌  | 98/130 [1:01:58<01:57,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.719:  76%|███████▌  | 99/130 [1:02:02<01:53,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.005:  77%|███████▋  | 100/130 [1:02:05<01:49,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.906:  78%|███████▊  | 101/130 [1:02:09<01:46,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.934:  78%|███████▊  | 102/130 [1:02:13<01:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.566:  79%|███████▉  | 103/130 [1:02:16<01:38,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.997:  80%|████████  | 104/130 [1:02:20<01:34,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.308:  81%|████████  | 105/130 [1:02:24<01:31,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.248:  82%|████████▏ | 106/130 [1:02:27<01:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 4.374:  82%|████████▏ | 107/130 [1:02:31<01:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 4.121:  83%|████████▎ | 108/130 [1:02:35<01:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.187:  84%|████████▍ | 109/130 [1:02:38<01:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 4.750:  85%|████████▍ | 110/130 [1:02:42<01:13,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 4.775:  85%|████████▌ | 111/130 [1:02:46<01:09,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.401:  86%|████████▌ | 112/130 [1:02:49<01:05,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.286:  87%|████████▋ | 113/130 [1:02:53<01:02,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.847:  88%|████████▊ | 114/130 [1:02:57<00:58,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.475:  88%|████████▊ | 115/130 [1:03:00<00:54,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.462:  89%|████████▉ | 116/130 [1:03:04<00:51,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.949:  90%|█████████ | 117/130 [1:03:07<00:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 4.600:  91%|█████████ | 118/130 [1:03:11<00:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 4.341:  92%|█████████▏| 119/130 [1:03:15<00:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 5.236:  92%|█████████▏| 120/130 [1:03:18<00:36,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.510:  93%|█████████▎| 121/130 [1:03:22<00:32,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.017:  94%|█████████▍| 122/130 [1:03:26<00:29,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.833:  95%|█████████▍| 123/130 [1:03:29<00:25,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.293:  95%|█████████▌| 124/130 [1:03:33<00:21,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.084:  96%|█████████▌| 125/130 [1:03:37<00:18,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 4.335:  97%|█████████▋| 126/130 [1:03:40<00:14,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.662:  98%|█████████▊| 127/130 [1:03:44<00:10,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.501:  98%|█████████▊| 128/130 [1:03:48<00:07,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.224:  99%|█████████▉| 129/130 [1:03:51<00:03,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.206: 100%|██████████| 130/130 [1:03:55<00:00,  3.52s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:06:58<02:22,  1.26s/it]\n",
            "ITERATION - loss: 4.206: 100%|██████████| 130/130 [1:06:24<00:00,  3.52s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 10 Age L1-loss: 15.270 ** Gender accuracy: 0.963 ** Race accuracy: 0.855 ** Avg loss: 3.193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:07:33<02:22,  1.26s/it]\n",
            "ITERATION - loss: 4.206: 100%|██████████| 130/130 [1:06:59<00:00,  3.52s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 10 Age L1-loss: 15.163 ** Gender accuracy: 0.909 ** Race accuracy: 0.802 ** Avg loss: 4.139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 3.384:   1%|          | 1/130 [1:07:09<2:10:51, 60.86s/it]\u001b[A\n",
            "ITERATION - loss: 3.313:   2%|▏         | 2/130 [1:07:13<1:33:13, 43.70s/it]\u001b[A\n",
            "ITERATION - loss: 3.056:   2%|▏         | 3/130 [1:07:17<1:07:04, 31.69s/it]\u001b[A\n",
            "ITERATION - loss: 2.843:   3%|▎         | 4/130 [1:07:20<48:52, 23.27s/it]  \u001b[A\n",
            "ITERATION - loss: 3.471:   4%|▍         | 5/130 [1:07:24<36:13, 17.39s/it]\u001b[A\n",
            "ITERATION - loss: 3.175:   5%|▍         | 6/130 [1:07:27<27:25, 13.27s/it]\u001b[A\n",
            "ITERATION - loss: 3.138:   5%|▌         | 7/130 [1:07:31<21:17, 10.38s/it]\u001b[A\n",
            "ITERATION - loss: 3.339:   6%|▌         | 8/130 [1:07:35<17:00,  8.37s/it]\u001b[A\n",
            "ITERATION - loss: 2.904:   7%|▋         | 9/130 [1:07:38<14:01,  6.96s/it]\u001b[A\n",
            "ITERATION - loss: 3.081:   8%|▊         | 10/130 [1:07:42<11:55,  5.96s/it]\u001b[A\n",
            "ITERATION - loss: 2.998:   8%|▊         | 11/130 [1:07:46<10:27,  5.27s/it]\u001b[A\n",
            "ITERATION - loss: 3.433:   9%|▉         | 12/130 [1:07:49<09:25,  4.79s/it]\u001b[A\n",
            "ITERATION - loss: 3.221:  10%|█         | 13/130 [1:07:53<08:41,  4.45s/it]\u001b[A\n",
            "ITERATION - loss: 3.370:  11%|█         | 14/130 [1:07:57<08:07,  4.21s/it]\u001b[A\n",
            "ITERATION - loss: 3.392:  12%|█▏        | 15/130 [1:08:00<07:43,  4.03s/it]\u001b[A\n",
            "ITERATION - loss: 3.766:  12%|█▏        | 16/130 [1:08:04<07:26,  3.92s/it]\u001b[A\n",
            "ITERATION - loss: 3.513:  13%|█▎        | 17/130 [1:08:08<07:14,  3.84s/it]\u001b[A\n",
            "ITERATION - loss: 4.029:  14%|█▍        | 18/130 [1:08:11<07:03,  3.78s/it]\u001b[A\n",
            "ITERATION - loss: 3.139:  15%|█▍        | 19/130 [1:08:15<06:55,  3.74s/it]\u001b[A\n",
            "ITERATION - loss: 3.249:  15%|█▌        | 20/130 [1:08:19<06:48,  3.71s/it]\u001b[A\n",
            "ITERATION - loss: 2.976:  16%|█▌        | 21/130 [1:08:22<06:43,  3.70s/it]\u001b[A\n",
            "ITERATION - loss: 3.850:  17%|█▋        | 22/130 [1:08:26<06:38,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 3.631:  18%|█▊        | 23/130 [1:08:30<06:33,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 3.425:  18%|█▊        | 24/130 [1:08:33<06:29,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 3.548:  19%|█▉        | 25/130 [1:08:37<06:24,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.959:  20%|██        | 26/130 [1:08:41<06:21,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.878:  21%|██        | 27/130 [1:08:44<06:17,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.977:  22%|██▏       | 28/130 [1:08:48<06:13,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.209:  22%|██▏       | 29/130 [1:08:52<06:09,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.886:  23%|██▎       | 30/130 [1:08:55<06:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.403:  24%|██▍       | 31/130 [1:08:59<06:01,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.210:  25%|██▍       | 32/130 [1:09:02<05:58,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.777:  25%|██▌       | 33/130 [1:09:06<05:55,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 3.196:  26%|██▌       | 34/130 [1:09:10<05:51,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.304:  27%|██▋       | 35/130 [1:09:13<05:47,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.421:  28%|██▊       | 36/130 [1:09:17<05:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.842:  28%|██▊       | 37/130 [1:09:21<05:39,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.960:  29%|██▉       | 38/130 [1:09:24<05:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.754:  30%|███       | 39/130 [1:09:28<05:32,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.390:  31%|███       | 40/130 [1:09:32<05:28,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.909:  32%|███▏      | 41/130 [1:09:35<05:25,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.607:  32%|███▏      | 42/130 [1:09:39<05:21,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.242:  33%|███▎      | 43/130 [1:09:43<05:17,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.924:  34%|███▍      | 44/130 [1:09:46<05:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.651:  35%|███▍      | 45/130 [1:09:50<05:10,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.523:  35%|███▌      | 46/130 [1:09:54<05:06,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.508:  36%|███▌      | 47/130 [1:09:57<05:02,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.159:  37%|███▋      | 48/130 [1:10:01<04:59,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.960:  38%|███▊      | 49/130 [1:10:05<04:56,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.268:  38%|███▊      | 50/130 [1:10:08<04:52,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.975:  39%|███▉      | 51/130 [1:10:12<04:48,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.280:  40%|████      | 52/130 [1:10:16<04:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.217:  41%|████      | 53/130 [1:10:19<04:41,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.144:  42%|████▏     | 54/130 [1:10:23<04:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.525:  42%|████▏     | 55/130 [1:10:26<04:33,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.923:  43%|████▎     | 56/130 [1:10:30<04:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.741:  44%|████▍     | 57/130 [1:10:34<04:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.161:  45%|████▍     | 58/130 [1:10:37<04:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.328:  45%|████▌     | 59/130 [1:10:41<04:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.408:  46%|████▌     | 60/130 [1:10:45<04:15,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.916:  47%|████▋     | 61/130 [1:10:48<04:11,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.991:  48%|████▊     | 62/130 [1:10:52<04:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.428:  48%|████▊     | 63/130 [1:10:56<04:04,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.870:  49%|████▉     | 64/130 [1:10:59<04:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.379:  50%|█████     | 65/130 [1:11:03<03:57,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.961:  51%|█████     | 66/130 [1:11:07<03:53,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.314:  52%|█████▏    | 67/130 [1:11:10<03:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.626:  52%|█████▏    | 68/130 [1:11:14<03:46,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.613:  53%|█████▎    | 69/130 [1:11:17<03:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.578:  54%|█████▍    | 70/130 [1:11:21<03:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.693:  55%|█████▍    | 71/130 [1:11:25<03:34,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.075:  55%|█████▌    | 72/130 [1:11:28<03:31,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.523:  56%|█████▌    | 73/130 [1:11:32<03:28,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.239:  57%|█████▋    | 74/130 [1:11:36<03:24,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.538:  58%|█████▊    | 75/130 [1:11:39<03:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.269:  58%|█████▊    | 76/130 [1:11:43<03:16,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.585:  59%|█████▉    | 77/130 [1:11:47<03:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.160:  60%|██████    | 78/130 [1:11:50<03:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.362:  61%|██████    | 79/130 [1:11:54<03:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.785:  62%|██████▏   | 80/130 [1:11:58<03:02,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.374:  62%|██████▏   | 81/130 [1:12:01<02:58,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.107:  63%|██████▎   | 82/130 [1:12:05<02:55,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.205:  64%|██████▍   | 83/130 [1:12:09<02:51,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.889:  65%|██████▍   | 84/130 [1:12:12<02:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.397:  65%|██████▌   | 85/130 [1:12:16<02:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.189:  66%|██████▌   | 86/130 [1:12:19<02:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.239:  67%|██████▋   | 87/130 [1:12:23<02:36,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.729:  68%|██████▊   | 88/130 [1:12:27<02:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.702:  68%|██████▊   | 89/130 [1:12:30<02:29,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.864:  69%|██████▉   | 90/130 [1:12:34<02:26,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.370:  70%|███████   | 91/130 [1:12:38<02:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.720:  71%|███████   | 92/130 [1:12:41<02:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.841:  72%|███████▏  | 93/130 [1:12:45<02:15,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 3.468:  72%|███████▏  | 94/130 [1:12:49<02:11,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.812:  73%|███████▎  | 95/130 [1:12:52<02:07,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.067:  74%|███████▍  | 96/130 [1:12:56<02:04,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.980:  75%|███████▍  | 97/130 [1:13:00<02:00,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 3.296:  75%|███████▌  | 98/130 [1:13:03<01:57,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.702:  76%|███████▌  | 99/130 [1:13:07<01:53,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.735:  77%|███████▋  | 100/130 [1:13:11<01:49,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.998:  78%|███████▊  | 101/130 [1:13:14<01:45,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 4.065:  78%|███████▊  | 102/130 [1:13:18<01:41,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.986:  79%|███████▉  | 103/130 [1:13:22<01:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.080:  80%|████████  | 104/130 [1:13:25<01:34,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.409:  81%|████████  | 105/130 [1:13:29<01:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.561:  82%|████████▏ | 106/130 [1:13:33<01:27,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.281:  82%|████████▏ | 107/130 [1:13:36<01:23,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.444:  83%|████████▎ | 108/130 [1:13:40<01:20,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.144:  84%|████████▍ | 109/130 [1:13:44<01:16,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.048:  85%|████████▍ | 110/130 [1:13:47<01:13,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.911:  85%|████████▌ | 111/130 [1:13:51<01:09,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.298:  86%|████████▌ | 112/130 [1:13:54<01:05,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.515:  87%|████████▋ | 113/130 [1:13:58<01:02,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.062:  88%|████████▊ | 114/130 [1:14:02<00:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.962:  88%|████████▊ | 115/130 [1:14:05<00:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.125:  89%|████████▉ | 116/130 [1:14:09<00:50,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.599:  90%|█████████ | 117/130 [1:14:13<00:47,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.418:  91%|█████████ | 118/130 [1:14:16<00:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.313:  92%|█████████▏| 119/130 [1:14:20<00:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.749:  92%|█████████▏| 120/130 [1:14:24<00:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.243:  93%|█████████▎| 121/130 [1:14:27<00:32,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.309:  94%|█████████▍| 122/130 [1:14:31<00:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.847:  95%|█████████▍| 123/130 [1:14:35<00:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.261:  95%|█████████▌| 124/130 [1:14:38<00:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.149:  96%|█████████▌| 125/130 [1:14:42<00:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.560:  97%|█████████▋| 126/130 [1:14:46<00:14,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.172:  98%|█████████▊| 127/130 [1:14:49<00:10,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.459:  98%|█████████▊| 128/130 [1:14:53<00:07,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 3.301:  99%|█████████▉| 129/130 [1:14:57<00:03,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 3.527: 100%|██████████| 130/130 [1:14:59<00:00,  3.42s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:18:14<02:22,  1.26s/it]\n",
            "ITERATION - loss: 3.527: 100%|██████████| 130/130 [1:17:39<00:00,  3.42s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 11 Age L1-loss: 15.548 ** Gender accuracy: 0.977 ** Race accuracy: 0.911 ** Avg loss: 2.581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:18:48<02:22,  1.26s/it]\n",
            "ITERATION - loss: 3.527: 100%|██████████| 130/130 [1:18:14<00:00,  3.42s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 11 Age L1-loss: 15.441 ** Gender accuracy: 0.900 ** Race accuracy: 0.804 ** Avg loss: 4.489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 2.658:   1%|          | 1/130 [1:18:20<2:14:27, 62.54s/it]\u001b[A\n",
            "ITERATION - loss: 2.679:   2%|▏         | 2/130 [1:18:24<1:35:43, 44.87s/it]\u001b[A\n",
            "ITERATION - loss: 2.248:   2%|▏         | 3/130 [1:18:27<1:08:47, 32.50s/it]\u001b[A\n",
            "ITERATION - loss: 2.697:   3%|▎         | 4/130 [1:18:31<50:05, 23.86s/it]  \u001b[A\n",
            "ITERATION - loss: 2.671:   4%|▍         | 5/130 [1:18:34<37:04, 17.79s/it]\u001b[A\n",
            "ITERATION - loss: 2.757:   5%|▍         | 6/130 [1:18:38<28:00, 13.55s/it]\u001b[A\n",
            "ITERATION - loss: 2.514:   5%|▌         | 7/130 [1:18:42<21:42, 10.59s/it]\u001b[A\n",
            "ITERATION - loss: 2.622:   6%|▌         | 8/130 [1:18:46<17:18,  8.52s/it]\u001b[A\n",
            "ITERATION - loss: 2.241:   7%|▋         | 9/130 [1:18:49<14:13,  7.06s/it]\u001b[A\n",
            "ITERATION - loss: 2.944:   8%|▊         | 10/130 [1:18:53<12:03,  6.03s/it]\u001b[A\n",
            "ITERATION - loss: 2.480:   8%|▊         | 11/130 [1:18:56<10:32,  5.31s/it]\u001b[A\n",
            "ITERATION - loss: 2.352:   9%|▉         | 12/130 [1:19:00<09:28,  4.82s/it]\u001b[A\n",
            "ITERATION - loss: 2.584:  10%|█         | 13/130 [1:19:04<08:42,  4.46s/it]\u001b[A\n",
            "ITERATION - loss: 2.309:  11%|█         | 14/130 [1:19:07<08:09,  4.22s/it]\u001b[A\n",
            "ITERATION - loss: 2.255:  12%|█▏        | 15/130 [1:19:11<07:45,  4.05s/it]\u001b[A\n",
            "ITERATION - loss: 3.191:  12%|█▏        | 16/130 [1:19:15<07:28,  3.93s/it]\u001b[A\n",
            "ITERATION - loss: 2.917:  13%|█▎        | 17/130 [1:19:18<07:14,  3.85s/it]\u001b[A\n",
            "ITERATION - loss: 2.553:  14%|█▍        | 18/130 [1:19:22<07:04,  3.79s/it]\u001b[A\n",
            "ITERATION - loss: 3.005:  15%|█▍        | 19/130 [1:19:26<06:56,  3.75s/it]\u001b[A\n",
            "ITERATION - loss: 2.513:  15%|█▌        | 20/130 [1:19:29<06:49,  3.73s/it]\u001b[A\n",
            "ITERATION - loss: 2.742:  16%|█▌        | 21/130 [1:19:33<06:43,  3.70s/it]\u001b[A\n",
            "ITERATION - loss: 2.962:  17%|█▋        | 22/130 [1:19:37<06:38,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 2.758:  18%|█▊        | 23/130 [1:19:40<06:33,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 3.213:  18%|█▊        | 24/130 [1:19:44<06:29,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 2.384:  19%|█▉        | 25/130 [1:19:48<06:25,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.226:  20%|██        | 26/130 [1:19:51<06:20,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.593:  21%|██        | 27/130 [1:19:55<06:16,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.969:  22%|██▏       | 28/130 [1:19:59<06:12,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.484:  22%|██▏       | 29/130 [1:20:02<06:08,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.218:  23%|██▎       | 30/130 [1:20:06<06:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.351:  24%|██▍       | 31/130 [1:20:09<06:01,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.489:  25%|██▍       | 32/130 [1:20:13<05:57,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.173:  25%|██▌       | 33/130 [1:20:17<05:54,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.078:  26%|██▌       | 34/130 [1:20:20<05:51,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.416:  27%|██▋       | 35/130 [1:20:24<05:47,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.200:  28%|██▊       | 36/130 [1:20:28<05:44,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.813:  28%|██▊       | 37/130 [1:20:31<05:40,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.635:  29%|██▉       | 38/130 [1:20:35<05:36,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.788:  30%|███       | 39/130 [1:20:39<05:33,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.791:  31%|███       | 40/130 [1:20:42<05:29,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.094:  32%|███▏      | 41/130 [1:20:46<05:25,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.916:  32%|███▏      | 42/130 [1:20:50<05:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.052:  33%|███▎      | 43/130 [1:20:53<05:17,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.084:  34%|███▍      | 44/130 [1:20:57<05:14,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.671:  35%|███▍      | 45/130 [1:21:01<05:10,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.336:  35%|███▌      | 46/130 [1:21:04<05:08,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.357:  36%|███▌      | 47/130 [1:21:08<05:04,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.436:  37%|███▋      | 48/130 [1:21:12<05:00,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.129:  38%|███▊      | 49/130 [1:21:15<04:56,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.328:  38%|███▊      | 50/130 [1:21:19<04:52,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.841:  39%|███▉      | 51/130 [1:21:23<04:48,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.731:  40%|████      | 52/130 [1:21:26<04:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.018:  41%|████      | 53/130 [1:21:30<04:41,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.488:  42%|████▏     | 54/130 [1:21:34<04:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.869:  42%|████▏     | 55/130 [1:21:37<04:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.190:  43%|████▎     | 56/130 [1:21:41<04:31,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.548:  44%|████▍     | 57/130 [1:21:45<04:27,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.384:  45%|████▍     | 58/130 [1:21:48<04:23,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.288:  45%|████▌     | 59/130 [1:21:52<04:20,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.618:  46%|████▌     | 60/130 [1:21:56<04:16,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.089:  47%|████▋     | 61/130 [1:21:59<04:12,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.322:  48%|████▊     | 62/130 [1:22:03<04:08,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.474:  48%|████▊     | 63/130 [1:22:07<04:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.743:  49%|████▉     | 64/130 [1:22:10<04:01,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.566:  50%|█████     | 65/130 [1:22:14<03:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.351:  51%|█████     | 66/130 [1:22:17<03:53,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.337:  52%|█████▏    | 67/130 [1:22:21<03:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.511:  52%|█████▏    | 68/130 [1:22:25<03:46,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.616:  53%|█████▎    | 69/130 [1:22:28<03:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.823:  54%|█████▍    | 70/130 [1:22:32<03:38,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.576:  55%|█████▍    | 71/130 [1:22:36<03:34,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.508:  55%|█████▌    | 72/130 [1:22:39<03:31,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.143:  56%|█████▌    | 73/130 [1:22:43<03:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.838:  57%|█████▋    | 74/130 [1:22:47<03:24,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.558:  58%|█████▊    | 75/130 [1:22:50<03:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.635:  58%|█████▊    | 76/130 [1:22:54<03:17,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.752:  59%|█████▉    | 77/130 [1:22:58<03:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.743:  60%|██████    | 78/130 [1:23:01<03:09,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.979:  61%|██████    | 79/130 [1:23:05<03:06,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.747:  62%|██████▏   | 80/130 [1:23:09<03:03,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.517:  62%|██████▏   | 81/130 [1:23:12<02:59,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.657:  63%|██████▎   | 82/130 [1:23:16<02:55,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.667:  64%|██████▍   | 83/130 [1:23:20<02:51,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.649:  65%|██████▍   | 84/130 [1:23:23<02:48,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.424:  65%|██████▌   | 85/130 [1:23:27<02:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.792:  66%|██████▌   | 86/130 [1:23:31<02:40,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.628:  67%|██████▋   | 87/130 [1:23:34<02:36,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.838:  68%|██████▊   | 88/130 [1:23:38<02:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.308:  68%|██████▊   | 89/130 [1:23:41<02:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.218:  69%|██████▉   | 90/130 [1:23:45<02:25,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.635:  70%|███████   | 91/130 [1:23:49<02:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.446:  71%|███████   | 92/130 [1:23:52<02:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.543:  72%|███████▏  | 93/130 [1:23:56<02:14,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.245:  72%|███████▏  | 94/130 [1:24:00<02:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.317:  73%|███████▎  | 95/130 [1:24:03<02:07,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.463:  74%|███████▍  | 96/130 [1:24:07<02:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.567:  75%|███████▍  | 97/130 [1:24:11<02:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.675:  75%|███████▌  | 98/130 [1:24:14<01:56,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.442:  76%|███████▌  | 99/130 [1:24:18<01:53,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.486:  77%|███████▋  | 100/130 [1:24:22<01:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.505:  78%|███████▊  | 101/130 [1:24:25<01:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.489:  78%|███████▊  | 102/130 [1:24:29<01:41,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.548:  79%|███████▉  | 103/130 [1:24:32<01:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.452:  80%|████████  | 104/130 [1:24:36<01:34,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.439:  81%|████████  | 105/130 [1:24:40<01:31,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.829:  82%|████████▏ | 106/130 [1:24:43<01:27,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.223:  82%|████████▏ | 107/130 [1:24:47<01:23,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.446:  83%|████████▎ | 108/130 [1:24:51<01:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.596:  84%|████████▍ | 109/130 [1:24:54<01:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.518:  85%|████████▍ | 110/130 [1:24:58<01:12,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.809:  85%|████████▌ | 111/130 [1:25:02<01:09,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.049:  86%|████████▌ | 112/130 [1:25:05<01:05,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.591:  87%|████████▋ | 113/130 [1:25:09<01:02,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.505:  88%|████████▊ | 114/130 [1:25:13<00:58,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.335:  88%|████████▊ | 115/130 [1:25:16<00:54,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.654:  89%|████████▉ | 116/130 [1:25:20<00:51,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 3.005:  90%|█████████ | 117/130 [1:25:24<00:47,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.523:  91%|█████████ | 118/130 [1:25:27<00:43,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.608:  92%|█████████▏| 119/130 [1:25:31<00:40,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.468:  92%|█████████▏| 120/130 [1:25:35<00:36,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.484:  93%|█████████▎| 121/130 [1:25:38<00:32,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.557:  94%|█████████▍| 122/130 [1:25:42<00:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 3.534:  95%|█████████▍| 123/130 [1:25:45<00:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.404:  95%|█████████▌| 124/130 [1:25:49<00:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.558:  96%|█████████▌| 125/130 [1:25:53<00:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 3.031:  97%|█████████▋| 126/130 [1:25:56<00:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.838:  98%|█████████▊| 127/130 [1:26:00<00:10,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.715:  98%|█████████▊| 128/130 [1:26:04<00:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.192:  99%|█████████▉| 129/130 [1:26:07<00:03,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.840: 100%|██████████| 130/130 [1:26:10<00:00,  3.40s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:29:13<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.840: 100%|██████████| 130/130 [1:28:39<00:00,  3.40s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 12 Age L1-loss: 15.249 ** Gender accuracy: 0.990 ** Race accuracy: 0.936 ** Avg loss: 2.180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:29:48<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.840: 100%|██████████| 130/130 [1:29:14<00:00,  3.40s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 12 Age L1-loss: 15.163 ** Gender accuracy: 0.918 ** Race accuracy: 0.808 ** Avg loss: 4.437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 2.409:   1%|          | 1/130 [1:29:20<2:07:33, 59.33s/it]\u001b[A\n",
            "ITERATION - loss: 2.280:   2%|▏         | 2/130 [1:29:24<1:30:54, 42.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.076:   2%|▏         | 3/130 [1:29:27<1:05:29, 30.94s/it]\u001b[A\n",
            "ITERATION - loss: 2.141:   3%|▎         | 4/130 [1:29:31<47:45, 22.74s/it]  \u001b[A\n",
            "ITERATION - loss: 2.496:   4%|▍         | 5/130 [1:29:35<35:34, 17.08s/it]\u001b[A\n",
            "ITERATION - loss: 2.284:   5%|▍         | 6/130 [1:29:38<26:58, 13.05s/it]\u001b[A\n",
            "ITERATION - loss: 2.234:   5%|▌         | 7/130 [1:29:42<20:58, 10.23s/it]\u001b[A\n",
            "ITERATION - loss: 2.051:   6%|▌         | 8/130 [1:29:46<16:46,  8.25s/it]\u001b[A\n",
            "ITERATION - loss: 1.876:   7%|▋         | 9/130 [1:29:49<13:50,  6.87s/it]\u001b[A\n",
            "ITERATION - loss: 2.396:   8%|▊         | 10/130 [1:29:53<11:48,  5.90s/it]\u001b[A\n",
            "ITERATION - loss: 1.995:   8%|▊         | 11/130 [1:29:57<10:22,  5.23s/it]\u001b[A\n",
            "ITERATION - loss: 2.000:   9%|▉         | 12/130 [1:30:00<09:20,  4.75s/it]\u001b[A\n",
            "ITERATION - loss: 2.498:  10%|█         | 13/130 [1:30:04<08:36,  4.42s/it]\u001b[A\n",
            "ITERATION - loss: 2.408:  11%|█         | 14/130 [1:30:08<08:04,  4.18s/it]\u001b[A\n",
            "ITERATION - loss: 2.108:  12%|█▏        | 15/130 [1:30:11<07:42,  4.02s/it]\u001b[A\n",
            "ITERATION - loss: 2.170:  12%|█▏        | 16/130 [1:30:15<07:23,  3.89s/it]\u001b[A\n",
            "ITERATION - loss: 2.271:  13%|█▎        | 17/130 [1:30:18<07:11,  3.82s/it]\u001b[A\n",
            "ITERATION - loss: 2.285:  14%|█▍        | 18/130 [1:30:22<07:00,  3.76s/it]\u001b[A\n",
            "ITERATION - loss: 1.873:  15%|█▍        | 19/130 [1:30:26<06:53,  3.73s/it]\u001b[A\n",
            "ITERATION - loss: 2.313:  15%|█▌        | 20/130 [1:30:29<06:46,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 2.513:  16%|█▌        | 21/130 [1:30:33<06:40,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.205:  17%|█▋        | 22/130 [1:30:37<06:34,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.290:  18%|█▊        | 23/130 [1:30:40<06:30,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.158:  18%|█▊        | 24/130 [1:30:44<06:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.306:  19%|█▉        | 25/130 [1:30:47<06:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.172:  20%|██        | 26/130 [1:30:51<06:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.105:  21%|██        | 27/130 [1:30:55<06:13,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.736:  22%|██▏       | 28/130 [1:30:58<06:09,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.593:  22%|██▏       | 29/130 [1:31:02<06:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.970:  23%|██▎       | 30/130 [1:31:06<06:02,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.041:  24%|██▍       | 31/130 [1:31:09<05:59,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.105:  25%|██▍       | 32/130 [1:31:13<05:55,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.219:  25%|██▌       | 33/130 [1:31:16<05:51,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.041:  26%|██▌       | 34/130 [1:31:20<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.902:  27%|██▋       | 35/130 [1:31:24<05:47,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.908:  28%|██▊       | 36/130 [1:31:27<05:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.153:  28%|██▊       | 37/130 [1:31:31<05:39,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.025:  29%|██▉       | 38/130 [1:31:35<05:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.195:  30%|███       | 39/130 [1:31:38<05:32,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.502:  31%|███       | 40/130 [1:31:42<05:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.132:  32%|███▏      | 41/130 [1:31:46<05:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.265:  32%|███▏      | 42/130 [1:31:49<05:21,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.438:  33%|███▎      | 43/130 [1:31:53<05:17,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.242:  34%|███▍      | 44/130 [1:31:57<05:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.287:  35%|███▍      | 45/130 [1:32:00<05:10,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.007:  35%|███▌      | 46/130 [1:32:04<05:07,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.247:  36%|███▌      | 47/130 [1:32:08<05:03,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.895:  37%|███▋      | 48/130 [1:32:11<04:59,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.178:  38%|███▊      | 49/130 [1:32:15<04:56,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.051:  38%|███▊      | 50/130 [1:32:19<04:52,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.674:  39%|███▉      | 51/130 [1:32:22<04:49,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.219:  40%|████      | 52/130 [1:32:26<04:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.196:  41%|████      | 53/130 [1:32:29<04:40,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.699:  42%|████▏     | 54/130 [1:32:33<04:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.160:  42%|████▏     | 55/130 [1:32:37<04:33,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.651:  43%|████▎     | 56/130 [1:32:40<04:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.258:  44%|████▍     | 57/130 [1:32:44<04:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.172:  45%|████▍     | 58/130 [1:32:48<04:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.556:  45%|████▌     | 59/130 [1:32:51<04:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.059:  46%|████▌     | 60/130 [1:32:55<04:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.894:  47%|████▋     | 61/130 [1:32:59<04:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.961:  48%|████▊     | 62/130 [1:33:02<04:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.377:  48%|████▊     | 63/130 [1:33:06<04:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.929:  49%|████▉     | 64/130 [1:33:10<04:01,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.206:  50%|█████     | 65/130 [1:33:13<03:57,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.107:  51%|█████     | 66/130 [1:33:17<03:53,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.242:  52%|█████▏    | 67/130 [1:33:20<03:50,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.008:  52%|█████▏    | 68/130 [1:33:24<03:46,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.143:  53%|█████▎    | 69/130 [1:33:28<03:42,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.638:  54%|█████▍    | 70/130 [1:33:31<03:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.631:  55%|█████▍    | 71/130 [1:33:35<03:35,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.082:  55%|█████▌    | 72/130 [1:33:39<03:31,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.300:  56%|█████▌    | 73/130 [1:33:42<03:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.717:  57%|█████▋    | 74/130 [1:33:46<03:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.990:  58%|█████▊    | 75/130 [1:33:50<03:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.203:  58%|█████▊    | 76/130 [1:33:53<03:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.501:  59%|█████▉    | 77/130 [1:33:57<03:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.443:  60%|██████    | 78/130 [1:34:01<03:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.253:  61%|██████    | 79/130 [1:34:04<03:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.897:  62%|██████▏   | 80/130 [1:34:08<03:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.170:  62%|██████▏   | 81/130 [1:34:11<02:57,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.384:  63%|██████▎   | 82/130 [1:34:15<02:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.497:  64%|██████▍   | 83/130 [1:34:19<02:51,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.503:  65%|██████▍   | 84/130 [1:34:22<02:46,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.230:  65%|██████▌   | 85/130 [1:34:26<02:43,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.171:  66%|██████▌   | 86/130 [1:34:30<02:39,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.794:  67%|██████▋   | 87/130 [1:34:33<02:35,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.293:  68%|██████▊   | 88/130 [1:34:37<02:31,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.929:  68%|██████▊   | 89/130 [1:34:40<02:27,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.653:  69%|██████▉   | 90/130 [1:34:44<02:24,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 3.052:  70%|███████   | 91/130 [1:34:48<02:20,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.136:  71%|███████   | 92/130 [1:34:51<02:17,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.729:  72%|███████▏  | 93/130 [1:34:55<02:13,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.367:  72%|███████▏  | 94/130 [1:34:58<02:09,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.227:  73%|███████▎  | 95/130 [1:35:02<02:06,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.553:  74%|███████▍  | 96/130 [1:35:06<02:02,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.395:  75%|███████▍  | 97/130 [1:35:09<01:58,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.463:  75%|███████▌  | 98/130 [1:35:13<01:55,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.351:  76%|███████▌  | 99/130 [1:35:16<01:51,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.709:  77%|███████▋  | 100/130 [1:35:20<01:48,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.110:  78%|███████▊  | 101/130 [1:35:24<01:44,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.005:  78%|███████▊  | 102/130 [1:35:27<01:40,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.405:  79%|███████▉  | 103/130 [1:35:31<01:37,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.050:  80%|████████  | 104/130 [1:35:34<01:33,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.417:  81%|████████  | 105/130 [1:35:38<01:30,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.339:  82%|████████▏ | 106/130 [1:35:42<01:26,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.235:  82%|████████▏ | 107/130 [1:35:45<01:23,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.582:  83%|████████▎ | 108/130 [1:35:49<01:19,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.179:  84%|████████▍ | 109/130 [1:35:52<01:15,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.707:  85%|████████▍ | 110/130 [1:35:56<01:12,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.142:  85%|████████▌ | 111/130 [1:36:00<01:08,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.544:  86%|████████▌ | 112/130 [1:36:03<01:04,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.233:  87%|████████▋ | 113/130 [1:36:07<01:01,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.102:  88%|████████▊ | 114/130 [1:36:10<00:57,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.842:  88%|████████▊ | 115/130 [1:36:14<00:54,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.349:  89%|████████▉ | 116/130 [1:36:18<00:50,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.316:  90%|█████████ | 117/130 [1:36:21<00:46,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 3.140:  91%|█████████ | 118/130 [1:36:25<00:43,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.441:  92%|█████████▏| 119/130 [1:36:28<00:39,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.459:  92%|█████████▏| 120/130 [1:36:32<00:36,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.074:  93%|█████████▎| 121/130 [1:36:36<00:32,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.429:  94%|█████████▍| 122/130 [1:36:39<00:28,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.631:  95%|█████████▍| 123/130 [1:36:43<00:25,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.124:  95%|█████████▌| 124/130 [1:36:46<00:21,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.481:  96%|█████████▌| 125/130 [1:36:50<00:18,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.154:  97%|█████████▋| 126/130 [1:36:54<00:14,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.236:  98%|█████████▊| 127/130 [1:36:57<00:10,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.406:  98%|█████████▊| 128/130 [1:37:01<00:07,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.304:  99%|█████████▉| 129/130 [1:37:04<00:03,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.449: 100%|██████████| 130/130 [1:37:07<00:00,  3.37s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:40:10<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.449: 100%|██████████| 130/130 [1:39:36<00:00,  3.37s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 13 Age L1-loss: 15.341 ** Gender accuracy: 0.993 ** Race accuracy: 0.954 ** Avg loss: 1.996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:40:44<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.449: 100%|██████████| 130/130 [1:40:10<00:00,  3.37s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 13 Age L1-loss: 15.247 ** Gender accuracy: 0.915 ** Race accuracy: 0.795 ** Avg loss: 5.263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.982:   1%|          | 1/130 [1:40:16<2:06:46, 58.96s/it]\u001b[A\n",
            "ITERATION - loss: 2.276:   2%|▏         | 2/130 [1:40:20<1:30:21, 42.36s/it]\u001b[A\n",
            "ITERATION - loss: 2.088:   2%|▏         | 3/130 [1:40:23<1:05:02, 30.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.848:   3%|▎         | 4/130 [1:40:27<47:25, 22.58s/it]  \u001b[A\n",
            "ITERATION - loss: 1.702:   4%|▍         | 5/130 [1:40:30<35:10, 16.89s/it]\u001b[A\n",
            "ITERATION - loss: 1.890:   5%|▍         | 6/130 [1:40:34<26:40, 12.90s/it]\u001b[A\n",
            "ITERATION - loss: 1.829:   5%|▌         | 7/130 [1:40:38<20:43, 10.11s/it]\u001b[A\n",
            "ITERATION - loss: 1.988:   6%|▌         | 8/130 [1:40:41<16:34,  8.15s/it]\u001b[A\n",
            "ITERATION - loss: 2.178:   7%|▋         | 9/130 [1:40:45<13:40,  6.78s/it]\u001b[A\n",
            "ITERATION - loss: 2.267:   8%|▊         | 10/130 [1:40:48<11:39,  5.83s/it]\u001b[A\n",
            "ITERATION - loss: 2.281:   8%|▊         | 11/130 [1:40:52<10:14,  5.16s/it]\u001b[A\n",
            "ITERATION - loss: 1.966:   9%|▉         | 12/130 [1:40:56<09:13,  4.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.745:  10%|█         | 13/130 [1:40:59<08:30,  4.36s/it]\u001b[A\n",
            "ITERATION - loss: 2.157:  11%|█         | 14/130 [1:41:03<07:59,  4.13s/it]\u001b[A\n",
            "ITERATION - loss: 1.966:  12%|█▏        | 15/130 [1:41:06<07:36,  3.97s/it]\u001b[A\n",
            "ITERATION - loss: 1.929:  12%|█▏        | 16/130 [1:41:10<07:20,  3.86s/it]\u001b[A\n",
            "ITERATION - loss: 1.869:  13%|█▎        | 17/130 [1:41:14<07:07,  3.78s/it]\u001b[A\n",
            "ITERATION - loss: 2.124:  14%|█▍        | 18/130 [1:41:17<06:58,  3.73s/it]\u001b[A\n",
            "ITERATION - loss: 1.964:  15%|█▍        | 19/130 [1:41:21<06:49,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 2.023:  15%|█▌        | 20/130 [1:41:24<06:43,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.779:  16%|█▌        | 21/130 [1:41:28<06:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.247:  17%|█▋        | 22/130 [1:41:32<06:32,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.977:  18%|█▊        | 23/130 [1:41:35<06:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.063:  18%|█▊        | 24/130 [1:41:39<06:23,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.883:  19%|█▉        | 25/130 [1:41:42<06:19,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.713:  20%|██        | 26/130 [1:41:46<06:15,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.216:  21%|██        | 27/130 [1:41:50<06:11,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.850:  22%|██▏       | 28/130 [1:41:53<06:08,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.776:  22%|██▏       | 29/130 [1:41:57<06:04,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.787:  23%|██▎       | 30/130 [1:42:00<06:00,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.117:  24%|██▍       | 31/130 [1:42:04<05:57,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.870:  25%|██▍       | 32/130 [1:42:08<05:53,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.920:  25%|██▌       | 33/130 [1:42:11<05:50,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.994:  26%|██▌       | 34/130 [1:42:15<05:46,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.012:  27%|██▋       | 35/130 [1:42:18<05:42,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.013:  28%|██▊       | 36/130 [1:42:22<05:38,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.005:  28%|██▊       | 37/130 [1:42:26<05:34,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.715:  29%|██▉       | 38/130 [1:42:29<05:31,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.867:  30%|███       | 39/130 [1:42:33<05:27,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 2.119:  31%|███       | 40/130 [1:42:36<05:24,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  32%|███▏      | 41/130 [1:42:40<05:20,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.988:  32%|███▏      | 42/130 [1:42:44<05:17,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.600:  33%|███▎      | 43/130 [1:42:47<05:13,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.963:  34%|███▍      | 44/130 [1:42:51<05:09,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.878:  35%|███▍      | 45/130 [1:42:54<05:06,  3.60s/it]\u001b[A\n",
            "ITERATION - loss: 1.967:  35%|███▌      | 46/130 [1:42:58<05:03,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 2.338:  36%|███▌      | 47/130 [1:43:02<04:59,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.895:  37%|███▋      | 48/130 [1:43:05<04:56,  3.61s/it]\u001b[A\n",
            "ITERATION - loss: 1.980:  38%|███▊      | 49/130 [1:43:09<04:52,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.779:  38%|███▊      | 50/130 [1:43:13<04:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.965:  39%|███▉      | 51/130 [1:43:16<04:46,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.404:  40%|████      | 52/130 [1:43:20<04:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.809:  41%|████      | 53/130 [1:43:24<04:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.308:  42%|████▏     | 54/130 [1:43:27<04:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.860:  42%|████▏     | 55/130 [1:43:31<04:33,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.907:  43%|████▎     | 56/130 [1:43:35<04:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.063:  44%|████▍     | 57/130 [1:43:38<04:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.343:  45%|████▍     | 58/130 [1:43:42<04:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.266:  45%|████▌     | 59/130 [1:43:45<04:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.901:  46%|████▌     | 60/130 [1:43:49<04:15,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.055:  47%|████▋     | 61/130 [1:43:53<04:11,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.352:  48%|████▊     | 62/130 [1:43:56<04:08,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.978:  48%|████▊     | 63/130 [1:44:00<04:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.647:  49%|████▉     | 64/130 [1:44:04<04:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.973:  50%|█████     | 65/130 [1:44:07<03:57,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.254:  51%|█████     | 66/130 [1:44:11<03:53,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.926:  52%|█████▏    | 67/130 [1:44:15<03:49,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.874:  52%|█████▏    | 68/130 [1:44:18<03:46,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.374:  53%|█████▎    | 69/130 [1:44:22<03:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.185:  54%|█████▍    | 70/130 [1:44:26<03:39,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.060:  55%|█████▍    | 71/130 [1:44:29<03:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.725:  55%|█████▌    | 72/130 [1:44:33<03:31,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.113:  56%|█████▌    | 73/130 [1:44:37<03:28,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.128:  57%|█████▋    | 74/130 [1:44:40<03:24,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.670:  58%|█████▊    | 75/130 [1:44:44<03:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.412:  58%|█████▊    | 76/130 [1:44:48<03:16,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.076:  59%|█████▉    | 77/130 [1:44:51<03:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.588:  60%|██████    | 78/130 [1:44:55<03:10,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.178:  61%|██████    | 79/130 [1:44:58<03:05,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.172:  62%|██████▏   | 80/130 [1:45:02<03:02,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.029:  62%|██████▏   | 81/130 [1:45:06<02:58,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.956:  63%|██████▎   | 82/130 [1:45:09<02:55,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.093:  64%|██████▍   | 83/130 [1:45:13<02:51,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.745:  65%|██████▍   | 84/130 [1:45:17<02:47,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.909:  65%|██████▌   | 85/130 [1:45:20<02:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.306:  66%|██████▌   | 86/130 [1:45:24<02:40,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.041:  67%|██████▋   | 87/130 [1:45:28<02:36,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.164:  68%|██████▊   | 88/130 [1:45:31<02:33,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.776:  68%|██████▊   | 89/130 [1:45:35<02:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.237:  69%|██████▉   | 90/130 [1:45:39<02:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.932:  70%|███████   | 91/130 [1:45:42<02:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.375:  71%|███████   | 92/130 [1:45:46<02:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.990:  72%|███████▏  | 93/130 [1:45:50<02:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.185:  72%|███████▏  | 94/130 [1:45:53<02:11,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.590:  73%|███████▎  | 95/130 [1:45:57<02:07,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.715:  74%|███████▍  | 96/130 [1:46:00<02:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.811:  75%|███████▍  | 97/130 [1:46:04<02:00,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.145:  75%|███████▌  | 98/130 [1:46:08<01:56,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.902:  76%|███████▌  | 99/130 [1:46:11<01:53,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.024:  77%|███████▋  | 100/130 [1:46:15<01:49,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.796:  78%|███████▊  | 101/130 [1:46:19<01:45,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.833:  78%|███████▊  | 102/130 [1:46:22<01:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.253:  79%|███████▉  | 103/130 [1:46:26<01:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.123:  80%|████████  | 104/130 [1:46:30<01:34,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.376:  81%|████████  | 105/130 [1:46:33<01:31,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.941:  82%|████████▏ | 106/130 [1:46:37<01:27,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.188:  82%|████████▏ | 107/130 [1:46:41<01:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.170:  83%|████████▎ | 108/130 [1:46:44<01:20,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.803:  84%|████████▍ | 109/130 [1:46:48<01:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.061:  85%|████████▍ | 110/130 [1:46:51<01:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.089:  85%|████████▌ | 111/130 [1:46:55<01:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.807:  86%|████████▌ | 112/130 [1:46:59<01:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.075:  87%|████████▋ | 113/130 [1:47:02<01:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.093:  88%|████████▊ | 114/130 [1:47:06<00:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.019:  88%|████████▊ | 115/130 [1:47:10<00:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.697:  89%|████████▉ | 116/130 [1:47:13<00:50,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.133:  90%|█████████ | 117/130 [1:47:17<00:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.936:  91%|█████████ | 118/130 [1:47:21<00:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.078:  92%|█████████▏| 119/130 [1:47:24<00:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.011:  92%|█████████▏| 120/130 [1:47:28<00:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.440:  93%|█████████▎| 121/130 [1:47:31<00:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.608:  94%|█████████▍| 122/130 [1:47:35<00:29,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.497:  95%|█████████▍| 123/130 [1:47:39<00:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.883:  95%|█████████▌| 124/130 [1:47:42<00:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.616:  96%|█████████▌| 125/130 [1:47:46<00:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.859:  97%|█████████▋| 126/130 [1:47:50<00:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.461:  98%|█████████▊| 127/130 [1:47:53<00:10,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.831:  98%|█████████▊| 128/130 [1:47:57<00:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.154:  99%|█████████▉| 129/130 [1:48:01<00:03,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.297: 100%|██████████| 130/130 [1:48:03<00:00,  3.41s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:51:06<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.297: 100%|██████████| 130/130 [1:50:32<00:00,  3.41s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 14 Age L1-loss: 15.312 ** Gender accuracy: 0.994 ** Race accuracy: 0.972 ** Avg loss: 1.845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [1:51:40<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.297: 100%|██████████| 130/130 [1:51:06<00:00,  3.41s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 14 Age L1-loss: 15.210 ** Gender accuracy: 0.914 ** Race accuracy: 0.812 ** Avg loss: 5.414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.939:   1%|          | 1/130 [1:51:13<2:07:08, 59.13s/it]\u001b[A\n",
            "ITERATION - loss: 1.797:   2%|▏         | 2/130 [1:51:16<1:30:37, 42.48s/it]\u001b[A\n",
            "ITERATION - loss: 1.918:   2%|▏         | 3/130 [1:51:20<1:05:14, 30.82s/it]\u001b[A\n",
            "ITERATION - loss: 1.950:   3%|▎         | 4/130 [1:51:24<47:36, 22.67s/it]  \u001b[A\n",
            "ITERATION - loss: 1.886:   4%|▍         | 5/130 [1:51:27<35:20, 16.96s/it]\u001b[A\n",
            "ITERATION - loss: 1.691:   5%|▍         | 6/130 [1:51:31<26:45, 12.95s/it]\u001b[A\n",
            "ITERATION - loss: 2.078:   5%|▌         | 7/130 [1:51:34<20:48, 10.15s/it]\u001b[A\n",
            "ITERATION - loss: 1.731:   6%|▌         | 8/130 [1:51:38<16:39,  8.19s/it]\u001b[A\n",
            "ITERATION - loss: 1.900:   7%|▋         | 9/130 [1:51:42<13:46,  6.83s/it]\u001b[A\n",
            "ITERATION - loss: 1.759:   8%|▊         | 10/130 [1:51:45<11:44,  5.87s/it]\u001b[A\n",
            "ITERATION - loss: 1.865:   8%|▊         | 11/130 [1:51:49<10:18,  5.20s/it]\u001b[A\n",
            "ITERATION - loss: 1.711:   9%|▉         | 12/130 [1:51:53<09:17,  4.72s/it]\u001b[A\n",
            "ITERATION - loss: 2.060:  10%|█         | 13/130 [1:51:56<08:34,  4.39s/it]\u001b[A\n",
            "ITERATION - loss: 1.867:  11%|█         | 14/130 [1:52:00<08:02,  4.16s/it]\u001b[A\n",
            "ITERATION - loss: 1.898:  12%|█▏        | 15/130 [1:52:03<07:39,  4.00s/it]\u001b[A\n",
            "ITERATION - loss: 1.849:  12%|█▏        | 16/130 [1:52:07<07:23,  3.89s/it]\u001b[A\n",
            "ITERATION - loss: 1.668:  13%|█▎        | 17/130 [1:52:11<07:12,  3.83s/it]\u001b[A\n",
            "ITERATION - loss: 1.869:  14%|█▍        | 18/130 [1:52:14<07:01,  3.76s/it]\u001b[A\n",
            "ITERATION - loss: 2.113:  15%|█▍        | 19/130 [1:52:18<06:52,  3.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.731:  15%|█▌        | 20/130 [1:52:22<06:46,  3.70s/it]\u001b[A\n",
            "ITERATION - loss: 1.801:  16%|█▌        | 21/130 [1:52:25<06:41,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 2.247:  17%|█▋        | 22/130 [1:52:29<06:35,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.601:  18%|█▊        | 23/130 [1:52:32<06:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.774:  18%|█▊        | 24/130 [1:52:36<06:27,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.775:  19%|█▉        | 25/130 [1:52:40<06:23,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.507:  20%|██        | 26/130 [1:52:43<06:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.115:  21%|██        | 27/130 [1:52:47<06:15,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.075:  22%|██▏       | 28/130 [1:52:51<06:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.933:  22%|██▏       | 29/130 [1:52:54<06:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.627:  23%|██▎       | 30/130 [1:52:58<06:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.850:  24%|██▍       | 31/130 [1:53:02<06:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.662:  25%|██▍       | 32/130 [1:53:05<05:56,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.545:  25%|██▌       | 33/130 [1:53:09<05:53,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.087:  26%|██▌       | 34/130 [1:53:12<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.879:  27%|██▋       | 35/130 [1:53:16<05:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.692:  28%|██▊       | 36/130 [1:53:20<05:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.990:  28%|██▊       | 37/130 [1:53:23<05:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.684:  29%|██▉       | 38/130 [1:53:27<05:34,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.624:  30%|███       | 39/130 [1:53:31<05:31,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.549:  31%|███       | 40/130 [1:53:34<05:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.186:  32%|███▏      | 41/130 [1:53:38<05:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.070:  32%|███▏      | 42/130 [1:53:42<05:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.969:  33%|███▎      | 43/130 [1:53:45<05:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.828:  34%|███▍      | 44/130 [1:53:49<05:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.152:  35%|███▍      | 45/130 [1:53:52<05:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.967:  35%|███▌      | 46/130 [1:53:56<05:04,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  36%|███▌      | 47/130 [1:54:00<05:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.001:  37%|███▋      | 48/130 [1:54:03<04:57,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.693:  38%|███▊      | 49/130 [1:54:07<04:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.647:  38%|███▊      | 50/130 [1:54:11<04:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.953:  39%|███▉      | 51/130 [1:54:14<04:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.858:  40%|████      | 52/130 [1:54:18<04:44,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.746:  41%|████      | 53/130 [1:54:22<04:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.851:  42%|████▏     | 54/130 [1:54:25<04:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.878:  42%|████▏     | 55/130 [1:54:29<04:31,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.009:  43%|████▎     | 56/130 [1:54:32<04:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.027:  44%|████▍     | 57/130 [1:54:36<04:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.842:  45%|████▍     | 58/130 [1:54:40<04:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.867:  45%|████▌     | 59/130 [1:54:43<04:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.132:  46%|████▌     | 60/130 [1:54:47<04:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.980:  47%|████▋     | 61/130 [1:54:51<04:10,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.729:  48%|████▊     | 62/130 [1:54:54<04:06,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.965:  48%|████▊     | 63/130 [1:54:58<04:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.778:  49%|████▉     | 64/130 [1:55:02<04:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.598:  50%|█████     | 65/130 [1:55:05<03:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.746:  51%|█████     | 66/130 [1:55:09<03:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.257:  52%|█████▏    | 67/130 [1:55:12<03:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.924:  52%|█████▏    | 68/130 [1:55:16<03:45,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.221:  53%|█████▎    | 69/130 [1:55:20<03:42,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.753:  54%|█████▍    | 70/130 [1:55:23<03:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.717:  55%|█████▍    | 71/130 [1:55:27<03:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.074:  55%|█████▌    | 72/130 [1:55:31<03:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.260:  56%|█████▌    | 73/130 [1:55:34<03:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.945:  57%|█████▋    | 74/130 [1:55:38<03:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.639:  58%|█████▊    | 75/130 [1:55:41<03:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.418:  58%|█████▊    | 76/130 [1:55:45<03:15,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.804:  59%|█████▉    | 77/130 [1:55:49<03:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.793:  60%|██████    | 78/130 [1:55:52<03:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.722:  61%|██████    | 79/130 [1:55:56<03:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.025:  62%|██████▏   | 80/130 [1:56:00<03:01,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.179:  62%|██████▏   | 81/130 [1:56:03<02:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.611:  63%|██████▎   | 82/130 [1:56:07<02:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.625:  64%|██████▍   | 83/130 [1:56:11<02:50,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.962:  65%|██████▍   | 84/130 [1:56:14<02:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.292:  65%|██████▌   | 85/130 [1:56:18<02:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.038:  66%|██████▌   | 86/130 [1:56:22<02:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.269:  67%|██████▋   | 87/130 [1:56:25<02:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.873:  68%|██████▊   | 88/130 [1:56:29<02:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.089:  68%|██████▊   | 89/130 [1:56:32<02:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.694:  69%|██████▉   | 90/130 [1:56:36<02:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.806:  70%|███████   | 91/130 [1:56:40<02:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.400:  71%|███████   | 92/130 [1:56:43<02:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.074:  72%|███████▏  | 93/130 [1:56:47<02:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.961:  72%|███████▏  | 94/130 [1:56:51<02:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.350:  73%|███████▎  | 95/130 [1:56:54<02:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.317:  74%|███████▍  | 96/130 [1:56:58<02:03,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.954:  75%|███████▍  | 97/130 [1:57:01<02:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.054:  75%|███████▌  | 98/130 [1:57:05<01:56,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.943:  76%|███████▌  | 99/130 [1:57:09<01:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.189:  77%|███████▋  | 100/130 [1:57:12<01:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.296:  78%|███████▊  | 101/130 [1:57:16<01:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.102:  78%|███████▊  | 102/130 [1:57:20<01:41,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.965:  79%|███████▉  | 103/130 [1:57:23<01:38,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.285:  80%|████████  | 104/130 [1:57:27<01:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.131:  81%|████████  | 105/130 [1:57:31<01:31,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.114:  82%|████████▏ | 106/130 [1:57:34<01:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.311:  82%|████████▏ | 107/130 [1:57:38<01:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.899:  83%|████████▎ | 108/130 [1:57:41<01:20,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.135:  84%|████████▍ | 109/130 [1:57:45<01:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.047:  85%|████████▍ | 110/130 [1:57:49<01:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.135:  85%|████████▌ | 111/130 [1:57:52<01:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.936:  86%|████████▌ | 112/130 [1:57:56<01:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.155:  87%|████████▋ | 113/130 [1:58:00<01:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.072:  88%|████████▊ | 114/130 [1:58:03<00:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.627:  88%|████████▊ | 115/130 [1:58:07<00:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.107:  89%|████████▉ | 116/130 [1:58:10<00:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.977:  90%|█████████ | 117/130 [1:58:14<00:47,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.833:  91%|█████████ | 118/130 [1:58:18<00:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.590:  92%|█████████▏| 119/130 [1:58:21<00:39,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.375:  92%|█████████▏| 120/130 [1:58:25<00:36,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.821:  93%|█████████▎| 121/130 [1:58:29<00:32,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.979:  94%|█████████▍| 122/130 [1:58:32<00:29,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.784:  95%|█████████▍| 123/130 [1:58:36<00:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.002:  95%|█████████▌| 124/130 [1:58:40<00:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.968:  96%|█████████▌| 125/130 [1:58:43<00:18,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.159:  97%|█████████▋| 126/130 [1:58:47<00:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.786:  98%|█████████▊| 127/130 [1:58:50<00:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.813:  98%|█████████▊| 128/130 [1:58:54<00:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.655:  99%|█████████▉| 129/130 [1:58:58<00:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.905: 100%|██████████| 130/130 [1:59:01<00:00,  3.39s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:02:03<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.905: 100%|██████████| 130/130 [2:01:29<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 15 Age L1-loss: 15.187 ** Gender accuracy: 0.996 ** Race accuracy: 0.981 ** Avg loss: 1.724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:02:37<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.905: 100%|██████████| 130/130 [2:02:03<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 15 Age L1-loss: 15.087 ** Gender accuracy: 0.914 ** Race accuracy: 0.816 ** Avg loss: 5.545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.697:   1%|          | 1/130 [2:02:23<2:15:38, 63.09s/it]\u001b[A\n",
            "ITERATION - loss: 1.848:   2%|▏         | 2/130 [2:02:27<1:36:32, 45.25s/it]\u001b[A\n",
            "ITERATION - loss: 1.605:   2%|▏         | 3/130 [2:02:30<1:09:20, 32.76s/it]\u001b[A\n",
            "ITERATION - loss: 1.771:   3%|▎         | 4/130 [2:02:34<50:27, 24.03s/it]  \u001b[A\n",
            "ITERATION - loss: 1.678:   4%|▍         | 5/130 [2:02:37<37:16, 17.90s/it]\u001b[A\n",
            "ITERATION - loss: 2.380:   5%|▍         | 6/130 [2:02:41<28:08, 13.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.791:   5%|▌         | 7/130 [2:02:45<21:46, 10.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.823:   6%|▌         | 8/130 [2:02:48<17:19,  8.52s/it]\u001b[A\n",
            "ITERATION - loss: 1.453:   7%|▋         | 9/130 [2:02:52<14:12,  7.04s/it]\u001b[A\n",
            "ITERATION - loss: 1.724:   8%|▊         | 10/130 [2:02:55<12:02,  6.02s/it]\u001b[A\n",
            "ITERATION - loss: 1.968:   8%|▊         | 11/130 [2:02:59<10:39,  5.37s/it]\u001b[A\n",
            "ITERATION - loss: 1.711:   9%|▉         | 12/130 [2:03:03<09:32,  4.85s/it]\u001b[A\n",
            "ITERATION - loss: 1.795:  10%|█         | 13/130 [2:03:07<08:45,  4.49s/it]\u001b[A\n",
            "ITERATION - loss: 1.951:  11%|█         | 14/130 [2:03:10<08:11,  4.24s/it]\u001b[A\n",
            "ITERATION - loss: 1.860:  12%|█▏        | 15/130 [2:03:14<07:46,  4.06s/it]\u001b[A\n",
            "ITERATION - loss: 1.797:  12%|█▏        | 16/130 [2:03:18<07:28,  3.93s/it]\u001b[A\n",
            "ITERATION - loss: 1.885:  13%|█▎        | 17/130 [2:03:21<07:13,  3.84s/it]\u001b[A\n",
            "ITERATION - loss: 1.806:  14%|█▍        | 18/130 [2:03:25<07:03,  3.78s/it]\u001b[A\n",
            "ITERATION - loss: 1.980:  15%|█▍        | 19/130 [2:03:28<06:55,  3.74s/it]\u001b[A\n",
            "ITERATION - loss: 1.856:  15%|█▌        | 20/130 [2:03:32<06:48,  3.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.586:  16%|█▌        | 21/130 [2:03:36<06:41,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.636:  17%|█▋        | 22/130 [2:03:39<06:36,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.913:  18%|█▊        | 23/130 [2:03:43<06:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.774:  18%|█▊        | 24/130 [2:03:47<06:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.723:  19%|█▉        | 25/130 [2:03:50<06:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.270:  20%|██        | 26/130 [2:03:54<06:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.706:  21%|██        | 27/130 [2:03:58<06:15,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.857:  22%|██▏       | 28/130 [2:04:01<06:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.578:  22%|██▏       | 29/130 [2:04:05<06:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.627:  23%|██▎       | 30/130 [2:04:08<06:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  24%|██▍       | 31/130 [2:04:12<06:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.581:  25%|██▍       | 32/130 [2:04:16<05:56,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.934:  25%|██▌       | 33/130 [2:04:19<05:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.666:  26%|██▌       | 34/130 [2:04:23<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.000:  27%|██▋       | 35/130 [2:04:27<05:44,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.738:  28%|██▊       | 36/130 [2:04:30<05:40,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.840:  28%|██▊       | 37/130 [2:04:34<05:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.889:  29%|██▉       | 38/130 [2:04:38<05:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.014:  30%|███       | 39/130 [2:04:41<05:31,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.505:  31%|███       | 40/130 [2:04:45<05:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.366:  32%|███▏      | 41/130 [2:04:48<05:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.003:  32%|███▏      | 42/130 [2:04:52<05:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.778:  33%|███▎      | 43/130 [2:04:56<05:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.751:  34%|███▍      | 44/130 [2:04:59<05:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.868:  35%|███▍      | 45/130 [2:05:03<05:10,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.477:  35%|███▌      | 46/130 [2:05:07<05:07,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.605:  36%|███▌      | 47/130 [2:05:10<05:03,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.466:  37%|███▋      | 48/130 [2:05:14<05:00,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.899:  38%|███▊      | 49/130 [2:05:18<04:56,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.752:  38%|███▊      | 50/130 [2:05:21<04:52,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.869:  39%|███▉      | 51/130 [2:05:25<04:49,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.923:  40%|████      | 52/130 [2:05:29<04:45,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.653:  41%|████      | 53/130 [2:05:32<04:40,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.947:  42%|████▏     | 54/130 [2:05:36<04:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.839:  42%|████▏     | 55/130 [2:05:40<04:32,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.869:  43%|████▎     | 56/130 [2:05:43<04:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.260:  44%|████▍     | 57/130 [2:05:47<04:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.127:  45%|████▍     | 58/130 [2:05:50<04:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.217:  45%|████▌     | 59/130 [2:05:54<04:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.755:  46%|████▌     | 60/130 [2:05:58<04:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.686:  47%|████▋     | 61/130 [2:06:01<04:10,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.814:  48%|████▊     | 62/130 [2:06:05<04:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.008:  48%|████▊     | 63/130 [2:06:09<04:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.036:  49%|████▉     | 64/130 [2:06:12<04:01,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.635:  50%|█████     | 65/130 [2:06:16<03:57,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.912:  51%|█████     | 66/130 [2:06:20<03:54,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.618:  52%|█████▏    | 67/130 [2:06:23<03:50,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  52%|█████▏    | 68/130 [2:06:27<03:46,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.785:  53%|█████▎    | 69/130 [2:06:31<03:41,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.848:  54%|█████▍    | 70/130 [2:06:34<03:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.776:  55%|█████▍    | 71/130 [2:06:38<03:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.628:  55%|█████▌    | 72/130 [2:06:41<03:30,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.616:  56%|█████▌    | 73/130 [2:06:45<03:26,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.679:  57%|█████▋    | 74/130 [2:06:49<03:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.813:  58%|█████▊    | 75/130 [2:06:52<03:19,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.621:  58%|█████▊    | 76/130 [2:06:56<03:17,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.091:  59%|█████▉    | 77/130 [2:07:00<03:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.451:  60%|██████    | 78/130 [2:07:03<03:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.758:  61%|██████    | 79/130 [2:07:07<03:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.796:  62%|██████▏   | 80/130 [2:07:11<03:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.221:  62%|██████▏   | 81/130 [2:07:14<02:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.002:  63%|██████▎   | 82/130 [2:07:18<02:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.934:  64%|██████▍   | 83/130 [2:07:22<02:51,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.075:  65%|██████▍   | 84/130 [2:07:25<02:47,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.715:  65%|██████▌   | 85/130 [2:07:29<02:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.591:  66%|██████▌   | 86/130 [2:07:32<02:39,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.096:  67%|██████▋   | 87/130 [2:07:36<02:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.831:  68%|██████▊   | 88/130 [2:07:40<02:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.622:  68%|██████▊   | 89/130 [2:07:43<02:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.593:  69%|██████▉   | 90/130 [2:07:47<02:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.203:  70%|███████   | 91/130 [2:07:51<02:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.899:  71%|███████   | 92/130 [2:07:54<02:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.069:  72%|███████▏  | 93/130 [2:07:58<02:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.887:  72%|███████▏  | 94/130 [2:08:02<02:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.771:  73%|███████▎  | 95/130 [2:08:05<02:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.926:  74%|███████▍  | 96/130 [2:08:09<02:04,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.053:  75%|███████▍  | 97/130 [2:08:13<02:00,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.286:  75%|███████▌  | 98/130 [2:08:16<01:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.977:  76%|███████▌  | 99/130 [2:08:20<01:53,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.904:  77%|███████▋  | 100/130 [2:08:23<01:49,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.735:  78%|███████▊  | 101/130 [2:08:27<01:45,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.844:  78%|███████▊  | 102/130 [2:08:31<01:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.776:  79%|███████▉  | 103/130 [2:08:34<01:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.948:  80%|████████  | 104/130 [2:08:38<01:34,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.131:  81%|████████  | 105/130 [2:08:42<01:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.811:  82%|████████▏ | 106/130 [2:08:45<01:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.547:  82%|████████▏ | 107/130 [2:08:49<01:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.969:  83%|████████▎ | 108/130 [2:08:53<01:20,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.223:  84%|████████▍ | 109/130 [2:08:56<01:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.957:  85%|████████▍ | 110/130 [2:09:00<01:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.788:  85%|████████▌ | 111/130 [2:09:03<01:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.657:  86%|████████▌ | 112/130 [2:09:07<01:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.315:  87%|████████▋ | 113/130 [2:09:11<01:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.760:  88%|████████▊ | 114/130 [2:09:14<00:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.024:  88%|████████▊ | 115/130 [2:09:18<00:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.047:  89%|████████▉ | 116/130 [2:09:22<00:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.879:  90%|█████████ | 117/130 [2:09:25<00:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.014:  91%|█████████ | 118/130 [2:09:29<00:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.921:  92%|█████████▏| 119/130 [2:09:33<00:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.949:  92%|█████████▏| 120/130 [2:09:36<00:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.276:  93%|█████████▎| 121/130 [2:09:40<00:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.752:  94%|█████████▍| 122/130 [2:09:43<00:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.823:  95%|█████████▍| 123/130 [2:09:47<00:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.876:  95%|█████████▌| 124/130 [2:09:51<00:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.777:  96%|█████████▌| 125/130 [2:09:54<00:18,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.612:  97%|█████████▋| 126/130 [2:09:58<00:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.831:  98%|█████████▊| 127/130 [2:10:02<00:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.324:  98%|█████████▊| 128/130 [2:10:05<00:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.071:  99%|█████████▉| 129/130 [2:10:09<00:03,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.531: 100%|██████████| 130/130 [2:10:12<00:00,  3.39s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:13:14<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.531: 100%|██████████| 130/130 [2:12:40<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 16 Age L1-loss: 15.199 ** Gender accuracy: 0.991 ** Race accuracy: 0.978 ** Avg loss: 1.820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:13:48<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.531: 100%|██████████| 130/130 [2:13:14<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 16 Age L1-loss: 15.087 ** Gender accuracy: 0.922 ** Race accuracy: 0.808 ** Avg loss: 5.748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.733:   1%|          | 1/130 [2:13:20<2:06:34, 58.87s/it]\u001b[A\n",
            "ITERATION - loss: 1.959:   2%|▏         | 2/130 [2:13:24<1:30:14, 42.30s/it]\u001b[A\n",
            "ITERATION - loss: 1.634:   2%|▏         | 3/130 [2:13:27<1:04:59, 30.70s/it]\u001b[A\n",
            "ITERATION - loss: 1.566:   3%|▎         | 4/130 [2:13:31<47:24, 22.58s/it]  \u001b[A\n",
            "ITERATION - loss: 1.905:   4%|▍         | 5/130 [2:13:35<35:10, 16.89s/it]\u001b[A\n",
            "ITERATION - loss: 1.922:   5%|▍         | 6/130 [2:13:38<26:40, 12.91s/it]\u001b[A\n",
            "ITERATION - loss: 1.777:   5%|▌         | 7/130 [2:13:42<20:45, 10.13s/it]\u001b[A\n",
            "ITERATION - loss: 1.640:   6%|▌         | 8/130 [2:13:45<16:38,  8.18s/it]\u001b[A\n",
            "ITERATION - loss: 2.099:   7%|▋         | 9/130 [2:13:49<13:44,  6.82s/it]\u001b[A\n",
            "ITERATION - loss: 2.290:   8%|▊         | 10/130 [2:13:53<11:43,  5.86s/it]\u001b[A\n",
            "ITERATION - loss: 1.705:   8%|▊         | 11/130 [2:13:56<10:17,  5.19s/it]\u001b[A\n",
            "ITERATION - loss: 1.674:   9%|▉         | 12/130 [2:14:00<09:17,  4.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.617:  10%|█         | 13/130 [2:14:04<08:34,  4.40s/it]\u001b[A\n",
            "ITERATION - loss: 1.868:  11%|█         | 14/130 [2:14:07<08:03,  4.17s/it]\u001b[A\n",
            "ITERATION - loss: 1.666:  12%|█▏        | 15/130 [2:14:11<07:42,  4.02s/it]\u001b[A\n",
            "ITERATION - loss: 1.592:  12%|█▏        | 16/130 [2:14:15<07:25,  3.91s/it]\u001b[A\n",
            "ITERATION - loss: 1.513:  13%|█▎        | 17/130 [2:14:18<07:12,  3.83s/it]\u001b[A\n",
            "ITERATION - loss: 1.715:  14%|█▍        | 18/130 [2:14:22<07:02,  3.78s/it]\u001b[A\n",
            "ITERATION - loss: 1.681:  15%|█▍        | 19/130 [2:14:25<06:55,  3.74s/it]\u001b[A\n",
            "ITERATION - loss: 1.722:  15%|█▌        | 20/130 [2:14:29<06:47,  3.70s/it]\u001b[A\n",
            "ITERATION - loss: 1.685:  16%|█▌        | 21/130 [2:14:33<06:41,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 1.481:  17%|█▋        | 22/130 [2:14:37<06:43,  3.73s/it]\u001b[A\n",
            "ITERATION - loss: 1.853:  18%|█▊        | 23/130 [2:14:40<06:37,  3.71s/it]\u001b[A\n",
            "ITERATION - loss: 2.178:  18%|█▊        | 24/130 [2:14:44<06:30,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 1.702:  19%|█▉        | 25/130 [2:14:48<06:25,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.480:  20%|██        | 26/130 [2:14:51<06:20,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.011:  21%|██        | 27/130 [2:14:55<06:16,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.895:  22%|██▏       | 28/130 [2:14:58<06:14,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.746:  22%|██▏       | 29/130 [2:15:02<06:09,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.769:  23%|██▎       | 30/130 [2:15:06<06:05,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.781:  24%|██▍       | 31/130 [2:15:09<06:01,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.762:  25%|██▍       | 32/130 [2:15:13<05:57,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.681:  25%|██▌       | 33/130 [2:15:17<05:52,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.815:  26%|██▌       | 34/130 [2:15:20<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.836:  27%|██▋       | 35/130 [2:15:24<05:44,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.689:  28%|██▊       | 36/130 [2:15:28<05:40,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.885:  28%|██▊       | 37/130 [2:15:31<05:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.030:  29%|██▉       | 38/130 [2:15:35<05:33,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.847:  30%|███       | 39/130 [2:15:38<05:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.503:  31%|███       | 40/130 [2:15:42<05:26,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.921:  32%|███▏      | 41/130 [2:15:46<05:22,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.695:  32%|███▏      | 42/130 [2:15:49<05:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.733:  33%|███▎      | 43/130 [2:15:53<05:15,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.757:  34%|███▍      | 44/130 [2:15:57<05:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.059:  35%|███▍      | 45/130 [2:16:00<05:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.720:  35%|███▌      | 46/130 [2:16:04<05:06,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.644:  36%|███▌      | 47/130 [2:16:08<05:03,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.812:  37%|███▋      | 48/130 [2:16:11<04:59,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.920:  38%|███▊      | 49/130 [2:16:15<04:55,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.651:  38%|███▊      | 50/130 [2:16:18<04:51,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.875:  39%|███▉      | 51/130 [2:16:22<04:48,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.979:  40%|████      | 52/130 [2:16:26<04:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.857:  41%|████      | 53/130 [2:16:29<04:41,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.805:  42%|████▏     | 54/130 [2:16:33<04:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.879:  42%|████▏     | 55/130 [2:16:37<04:35,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.751:  43%|████▎     | 56/130 [2:16:40<04:30,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 2.032:  44%|████▍     | 57/130 [2:16:44<04:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.535:  45%|████▍     | 58/130 [2:16:48<04:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.077:  45%|████▌     | 59/130 [2:16:51<04:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.660:  46%|████▌     | 60/130 [2:16:55<04:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.852:  47%|████▋     | 61/130 [2:16:59<04:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.569:  48%|████▊     | 62/130 [2:17:02<04:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.486:  48%|████▊     | 63/130 [2:17:06<04:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.048:  49%|████▉     | 64/130 [2:17:10<04:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.743:  50%|█████     | 65/130 [2:17:13<03:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.987:  51%|█████     | 66/130 [2:17:17<03:52,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.307:  52%|█████▏    | 67/130 [2:17:21<03:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.591:  52%|█████▏    | 68/130 [2:17:24<03:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.510:  53%|█████▎    | 69/130 [2:17:28<03:42,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  54%|█████▍    | 70/130 [2:17:31<03:38,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.928:  55%|█████▍    | 71/130 [2:17:35<03:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.620:  55%|█████▌    | 72/130 [2:17:39<03:31,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.892:  56%|█████▌    | 73/130 [2:17:42<03:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.864:  57%|█████▋    | 74/130 [2:17:46<03:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.948:  58%|█████▊    | 75/130 [2:17:50<03:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.559:  58%|█████▊    | 76/130 [2:17:53<03:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.553:  59%|█████▉    | 77/130 [2:17:57<03:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.267:  60%|██████    | 78/130 [2:18:00<03:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.966:  61%|██████    | 79/130 [2:18:04<03:05,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.768:  62%|██████▏   | 80/130 [2:18:08<03:01,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.051:  62%|██████▏   | 81/130 [2:18:11<02:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.572:  63%|██████▎   | 82/130 [2:18:15<02:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.587:  64%|██████▍   | 83/130 [2:18:19<02:51,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.029:  65%|██████▍   | 84/130 [2:18:22<02:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.804:  65%|██████▌   | 85/130 [2:18:26<02:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.845:  66%|██████▌   | 86/130 [2:18:30<02:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.698:  67%|██████▋   | 87/130 [2:18:33<02:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.897:  68%|██████▊   | 88/130 [2:18:37<02:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.063:  68%|██████▊   | 89/130 [2:18:41<02:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.874:  69%|██████▉   | 90/130 [2:18:44<02:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.032:  70%|███████   | 91/130 [2:18:48<02:22,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.927:  71%|███████   | 92/130 [2:18:51<02:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  72%|███████▏  | 93/130 [2:18:55<02:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.798:  72%|███████▏  | 94/130 [2:18:59<02:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.938:  73%|███████▎  | 95/130 [2:19:02<02:07,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.927:  74%|███████▍  | 96/130 [2:19:06<02:03,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.891:  75%|███████▍  | 97/130 [2:19:10<02:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.923:  75%|███████▌  | 98/130 [2:19:13<01:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.665:  76%|███████▌  | 99/130 [2:19:17<01:52,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.167:  77%|███████▋  | 100/130 [2:19:21<01:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.911:  78%|███████▊  | 101/130 [2:19:24<01:45,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.083:  78%|███████▊  | 102/130 [2:19:28<01:41,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.776:  79%|███████▉  | 103/130 [2:19:32<01:38,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.216:  80%|████████  | 104/130 [2:19:35<01:34,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.089:  81%|████████  | 105/130 [2:19:39<01:30,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.708:  82%|████████▏ | 106/130 [2:19:42<01:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.805:  82%|████████▏ | 107/130 [2:19:46<01:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.781:  83%|████████▎ | 108/130 [2:19:50<01:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.152:  84%|████████▍ | 109/130 [2:19:53<01:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.039:  85%|████████▍ | 110/130 [2:19:57<01:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.650:  85%|████████▌ | 111/130 [2:20:01<01:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.532:  86%|████████▌ | 112/130 [2:20:04<01:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.768:  87%|████████▋ | 113/130 [2:20:08<01:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.494:  88%|████████▊ | 114/130 [2:20:11<00:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.029:  88%|████████▊ | 115/130 [2:20:15<00:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.658:  89%|████████▉ | 116/130 [2:20:19<00:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.626:  90%|█████████ | 117/130 [2:20:22<00:47,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.802:  91%|█████████ | 118/130 [2:20:26<00:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.682:  92%|█████████▏| 119/130 [2:20:30<00:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.946:  92%|█████████▏| 120/130 [2:20:33<00:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.663:  93%|█████████▎| 121/130 [2:20:37<00:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.125:  94%|█████████▍| 122/130 [2:20:41<00:29,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.887:  95%|█████████▍| 123/130 [2:20:44<00:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.839:  95%|█████████▌| 124/130 [2:20:48<00:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.728:  96%|█████████▌| 125/130 [2:20:51<00:18,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.666:  97%|█████████▋| 126/130 [2:20:55<00:14,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.725:  98%|█████████▊| 127/130 [2:20:59<00:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.657:  98%|█████████▊| 128/130 [2:21:02<00:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.791:  99%|█████████▉| 129/130 [2:21:06<00:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.612: 100%|██████████| 130/130 [2:21:09<00:00,  3.39s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:24:11<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.612: 100%|██████████| 130/130 [2:23:37<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 17 Age L1-loss: 15.246 ** Gender accuracy: 0.996 ** Race accuracy: 0.985 ** Avg loss: 1.705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:24:45<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.612: 100%|██████████| 130/130 [2:24:11<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 17 Age L1-loss: 15.141 ** Gender accuracy: 0.923 ** Race accuracy: 0.805 ** Avg loss: 5.789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.632:   1%|          | 1/130 [2:24:17<2:06:45, 58.95s/it]\u001b[A\n",
            "ITERATION - loss: 2.181:   2%|▏         | 2/130 [2:24:21<1:30:22, 42.36s/it]\u001b[A\n",
            "ITERATION - loss: 1.622:   2%|▏         | 3/130 [2:24:25<1:05:03, 30.73s/it]\u001b[A\n",
            "ITERATION - loss: 1.507:   3%|▎         | 4/130 [2:24:28<47:28, 22.61s/it]  \u001b[A\n",
            "ITERATION - loss: 1.813:   4%|▍         | 5/130 [2:24:32<35:13, 16.91s/it]\u001b[A\n",
            "ITERATION - loss: 1.831:   5%|▍         | 6/130 [2:24:36<26:43, 12.93s/it]\u001b[A\n",
            "ITERATION - loss: 1.320:   5%|▌         | 7/130 [2:24:39<20:45, 10.13s/it]\u001b[A\n",
            "ITERATION - loss: 1.673:   6%|▌         | 8/130 [2:24:43<16:37,  8.18s/it]\u001b[A\n",
            "ITERATION - loss: 1.932:   7%|▋         | 9/130 [2:24:46<13:44,  6.82s/it]\u001b[A\n",
            "ITERATION - loss: 2.275:   8%|▊         | 10/130 [2:24:50<11:43,  5.86s/it]\u001b[A\n",
            "ITERATION - loss: 1.738:   8%|▊         | 11/130 [2:24:54<10:17,  5.19s/it]\u001b[A\n",
            "ITERATION - loss: 2.118:   9%|▉         | 12/130 [2:24:57<09:17,  4.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.834:  10%|█         | 13/130 [2:25:01<08:33,  4.39s/it]\u001b[A\n",
            "ITERATION - loss: 1.698:  11%|█         | 14/130 [2:25:05<08:03,  4.16s/it]\u001b[A\n",
            "ITERATION - loss: 1.971:  12%|█▏        | 15/130 [2:25:08<07:39,  4.00s/it]\u001b[A\n",
            "ITERATION - loss: 1.685:  12%|█▏        | 16/130 [2:25:12<07:22,  3.88s/it]\u001b[A\n",
            "ITERATION - loss: 1.528:  13%|█▎        | 17/130 [2:25:15<07:10,  3.81s/it]\u001b[A\n",
            "ITERATION - loss: 1.690:  14%|█▍        | 18/130 [2:25:19<07:00,  3.76s/it]\u001b[A\n",
            "ITERATION - loss: 1.659:  15%|█▍        | 19/130 [2:25:23<06:52,  3.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.553:  15%|█▌        | 20/130 [2:25:26<06:46,  3.70s/it]\u001b[A\n",
            "ITERATION - loss: 1.757:  16%|█▌        | 21/130 [2:25:30<06:40,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 1.741:  17%|█▋        | 22/130 [2:25:34<06:36,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.694:  18%|█▊        | 23/130 [2:25:37<06:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.673:  18%|█▊        | 24/130 [2:25:41<06:27,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.685:  19%|█▉        | 25/130 [2:25:44<06:23,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.695:  20%|██        | 26/130 [2:25:48<06:19,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.454:  21%|██        | 27/130 [2:25:52<06:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.537:  22%|██▏       | 28/130 [2:25:55<06:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.651:  22%|██▏       | 29/130 [2:25:59<06:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.686:  23%|██▎       | 30/130 [2:26:03<06:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.894:  24%|██▍       | 31/130 [2:26:06<05:58,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.715:  25%|██▍       | 32/130 [2:26:10<05:55,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.640:  25%|██▌       | 33/130 [2:26:13<05:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.656:  26%|██▌       | 34/130 [2:26:17<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.569:  27%|██▋       | 35/130 [2:26:21<05:44,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.915:  28%|██▊       | 36/130 [2:26:24<05:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.022:  28%|██▊       | 37/130 [2:26:28<05:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.794:  29%|██▉       | 38/130 [2:26:32<05:33,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.044:  30%|███       | 39/130 [2:26:35<05:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.080:  31%|███       | 40/130 [2:26:39<05:26,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.059:  32%|███▏      | 41/130 [2:26:43<05:22,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.920:  32%|███▏      | 42/130 [2:26:46<05:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.748:  33%|███▎      | 43/130 [2:26:50<05:15,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.653:  34%|███▍      | 44/130 [2:26:53<05:11,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.692:  35%|███▍      | 45/130 [2:26:57<05:08,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.059:  35%|███▌      | 46/130 [2:27:01<05:04,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.107:  36%|███▌      | 47/130 [2:27:04<05:00,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.906:  37%|███▋      | 48/130 [2:27:08<04:56,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.681:  38%|███▊      | 49/130 [2:27:12<04:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.878:  38%|███▊      | 50/130 [2:27:15<04:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.595:  39%|███▉      | 51/130 [2:27:19<04:46,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.518:  40%|████      | 52/130 [2:27:22<04:42,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.883:  41%|████      | 53/130 [2:27:26<04:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.189:  42%|████▏     | 54/130 [2:27:30<04:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.797:  42%|████▏     | 55/130 [2:27:33<04:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.236:  43%|████▎     | 56/130 [2:27:37<04:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.721:  44%|████▍     | 57/130 [2:27:41<04:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.881:  45%|████▍     | 58/130 [2:27:44<04:22,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.747:  45%|████▌     | 59/130 [2:27:48<04:18,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.772:  46%|████▌     | 60/130 [2:27:52<04:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.589:  47%|████▋     | 61/130 [2:27:55<04:10,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.988:  48%|████▊     | 62/130 [2:27:59<04:06,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.809:  48%|████▊     | 63/130 [2:28:02<04:02,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.653:  49%|████▉     | 64/130 [2:28:06<03:58,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.670:  50%|█████     | 65/130 [2:28:10<03:55,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.762:  51%|█████     | 66/130 [2:28:13<03:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.777:  52%|█████▏    | 67/130 [2:28:17<03:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.733:  52%|█████▏    | 68/130 [2:28:20<03:44,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.854:  53%|█████▎    | 69/130 [2:28:24<03:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.737:  54%|█████▍    | 70/130 [2:28:28<03:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.049:  55%|█████▍    | 71/130 [2:28:31<03:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.655:  55%|█████▌    | 72/130 [2:28:35<03:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.739:  56%|█████▌    | 73/130 [2:28:39<03:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.820:  57%|█████▋    | 74/130 [2:28:42<03:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.680:  58%|█████▊    | 75/130 [2:28:46<03:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.798:  58%|█████▊    | 76/130 [2:28:50<03:15,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.659:  59%|█████▉    | 77/130 [2:28:53<03:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.357:  60%|██████    | 78/130 [2:28:57<03:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.748:  61%|██████    | 79/130 [2:29:00<03:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.468:  62%|██████▏   | 80/130 [2:29:04<03:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.798:  62%|██████▏   | 81/130 [2:29:08<02:57,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.616:  63%|██████▎   | 82/130 [2:29:11<02:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.176:  64%|██████▍   | 83/130 [2:29:15<02:50,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.810:  65%|██████▍   | 84/130 [2:29:19<02:46,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.771:  65%|██████▌   | 85/130 [2:29:22<02:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.824:  66%|██████▌   | 86/130 [2:29:26<02:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.750:  67%|██████▋   | 87/130 [2:29:29<02:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.556:  68%|██████▊   | 88/130 [2:29:33<02:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.698:  68%|██████▊   | 89/130 [2:29:37<02:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.703:  69%|██████▉   | 90/130 [2:29:40<02:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.962:  70%|███████   | 91/130 [2:29:44<02:21,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.628:  71%|███████   | 92/130 [2:29:48<02:17,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.274:  72%|███████▏  | 93/130 [2:29:51<02:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.632:  72%|███████▏  | 94/130 [2:29:55<02:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.729:  73%|███████▎  | 95/130 [2:29:58<02:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.525:  74%|███████▍  | 96/130 [2:30:02<02:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.808:  75%|███████▍  | 97/130 [2:30:06<01:59,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.767:  75%|███████▌  | 98/130 [2:30:09<01:55,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.719:  76%|███████▌  | 99/130 [2:30:13<01:52,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.682:  77%|███████▋  | 100/130 [2:30:17<01:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.459:  78%|███████▊  | 101/130 [2:30:20<01:45,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.132:  78%|███████▊  | 102/130 [2:30:24<01:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.504:  79%|███████▉  | 103/130 [2:30:27<01:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.848:  80%|████████  | 104/130 [2:30:31<01:34,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.909:  81%|████████  | 105/130 [2:30:35<01:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.684:  82%|████████▏ | 106/130 [2:30:38<01:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.937:  82%|████████▏ | 107/130 [2:30:42<01:23,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.969:  83%|████████▎ | 108/130 [2:30:46<01:19,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.035:  84%|████████▍ | 109/130 [2:30:49<01:16,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.971:  85%|████████▍ | 110/130 [2:30:53<01:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.599:  85%|████████▌ | 111/130 [2:30:56<01:08,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.780:  86%|████████▌ | 112/130 [2:31:00<01:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.853:  87%|████████▋ | 113/130 [2:31:04<01:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.056:  88%|████████▊ | 114/130 [2:31:07<00:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.494:  88%|████████▊ | 115/130 [2:31:11<00:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.769:  89%|████████▉ | 116/130 [2:31:15<00:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.763:  90%|█████████ | 117/130 [2:31:18<00:47,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.569:  91%|█████████ | 118/130 [2:31:22<00:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.850:  92%|█████████▏| 119/130 [2:31:26<00:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.141:  92%|█████████▏| 120/130 [2:31:29<00:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.655:  93%|█████████▎| 121/130 [2:31:33<00:32,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.099:  94%|█████████▍| 122/130 [2:31:36<00:29,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.885:  95%|█████████▍| 123/130 [2:31:40<00:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.936:  95%|█████████▌| 124/130 [2:31:44<00:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.751:  96%|█████████▌| 125/130 [2:31:47<00:18,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.456:  97%|█████████▋| 126/130 [2:31:51<00:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.723:  98%|█████████▊| 127/130 [2:31:55<00:10,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.537:  98%|█████████▊| 128/130 [2:31:58<00:07,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.876:  99%|█████████▉| 129/130 [2:32:02<00:03,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.907: 100%|██████████| 130/130 [2:32:05<00:00,  3.38s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:35:07<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.907: 100%|██████████| 130/130 [2:34:33<00:00,  3.38s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 18 Age L1-loss: 15.145 ** Gender accuracy: 0.996 ** Race accuracy: 0.988 ** Avg loss: 1.660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:35:41<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.907: 100%|██████████| 130/130 [2:35:07<00:00,  3.38s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 18 Age L1-loss: 15.025 ** Gender accuracy: 0.917 ** Race accuracy: 0.805 ** Avg loss: 6.035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 2.112:   1%|          | 1/130 [2:35:13<2:06:42, 58.94s/it]\u001b[A\n",
            "ITERATION - loss: 1.552:   2%|▏         | 2/130 [2:35:17<1:30:19, 42.34s/it]\u001b[A\n",
            "ITERATION - loss: 1.782:   2%|▏         | 3/130 [2:35:20<1:05:01, 30.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.783:   3%|▎         | 4/130 [2:35:24<47:27, 22.60s/it]  \u001b[A\n",
            "ITERATION - loss: 1.847:   4%|▍         | 5/130 [2:35:28<35:15, 16.93s/it]\u001b[A\n",
            "ITERATION - loss: 1.853:   5%|▍         | 6/130 [2:35:31<26:43, 12.93s/it]\u001b[A\n",
            "ITERATION - loss: 1.596:   5%|▌         | 7/130 [2:35:35<20:46, 10.14s/it]\u001b[A\n",
            "ITERATION - loss: 1.947:   6%|▌         | 8/130 [2:35:39<16:38,  8.18s/it]\u001b[A\n",
            "ITERATION - loss: 1.575:   7%|▋         | 9/130 [2:35:42<13:45,  6.82s/it]\u001b[A\n",
            "ITERATION - loss: 1.489:   8%|▊         | 10/130 [2:35:46<11:44,  5.87s/it]\u001b[A\n",
            "ITERATION - loss: 1.881:   8%|▊         | 11/130 [2:35:49<10:18,  5.20s/it]\u001b[A\n",
            "ITERATION - loss: 1.702:   9%|▉         | 12/130 [2:35:53<09:17,  4.73s/it]\u001b[A\n",
            "ITERATION - loss: 1.860:  10%|█         | 13/130 [2:35:57<08:35,  4.40s/it]\u001b[A\n",
            "ITERATION - loss: 2.456:  11%|█         | 14/130 [2:36:00<08:03,  4.16s/it]\u001b[A\n",
            "ITERATION - loss: 1.899:  12%|█▏        | 15/130 [2:36:04<07:40,  4.01s/it]\u001b[A\n",
            "ITERATION - loss: 1.859:  12%|█▏        | 16/130 [2:36:08<07:23,  3.89s/it]\u001b[A\n",
            "ITERATION - loss: 1.721:  13%|█▎        | 17/130 [2:36:11<07:10,  3.81s/it]\u001b[A\n",
            "ITERATION - loss: 1.665:  14%|█▍        | 18/130 [2:36:15<07:00,  3.75s/it]\u001b[A\n",
            "ITERATION - loss: 1.803:  15%|█▍        | 19/130 [2:36:19<06:52,  3.71s/it]\u001b[A\n",
            "ITERATION - loss: 1.726:  15%|█▌        | 20/130 [2:36:22<06:45,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.800:  16%|█▌        | 21/130 [2:36:26<06:42,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.788:  17%|█▋        | 22/130 [2:36:29<06:36,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 2.138:  18%|█▊        | 23/130 [2:36:33<06:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.362:  18%|█▊        | 24/130 [2:36:37<06:27,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.680:  19%|█▉        | 25/130 [2:36:40<06:23,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.861:  20%|██        | 26/130 [2:36:44<06:19,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.601:  21%|██        | 27/130 [2:36:48<06:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.759:  22%|██▏       | 28/130 [2:36:51<06:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.821:  22%|██▏       | 29/130 [2:36:55<06:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.798:  23%|██▎       | 30/130 [2:36:59<06:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.923:  24%|██▍       | 31/130 [2:37:02<06:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.949:  25%|██▍       | 32/130 [2:37:06<05:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.746:  25%|██▌       | 33/130 [2:37:09<05:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.077:  26%|██▌       | 34/130 [2:37:13<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.677:  27%|██▋       | 35/130 [2:37:17<05:44,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.673:  28%|██▊       | 36/130 [2:37:20<05:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.783:  28%|██▊       | 37/130 [2:37:24<05:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.689:  29%|██▉       | 38/130 [2:37:28<05:33,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.009:  30%|███       | 39/130 [2:37:31<05:29,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.722:  31%|███       | 40/130 [2:37:35<05:26,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.733:  32%|███▏      | 41/130 [2:37:38<05:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.615:  32%|███▏      | 42/130 [2:37:42<05:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.871:  33%|███▎      | 43/130 [2:37:46<05:15,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.676:  34%|███▍      | 44/130 [2:37:49<05:11,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.768:  35%|███▍      | 45/130 [2:37:53<05:08,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.953:  35%|███▌      | 46/130 [2:37:57<05:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.838:  36%|███▌      | 47/130 [2:38:00<05:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.671:  37%|███▋      | 48/130 [2:38:04<04:57,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.841:  38%|███▊      | 49/130 [2:38:07<04:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.638:  38%|███▊      | 50/130 [2:38:11<04:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  39%|███▉      | 51/130 [2:38:15<04:46,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.784:  40%|████      | 52/130 [2:38:18<04:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.784:  41%|████      | 53/130 [2:38:22<04:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.835:  42%|████▏     | 54/130 [2:38:26<04:35,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.430:  42%|████▏     | 55/130 [2:38:29<04:31,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.764:  43%|████▎     | 56/130 [2:38:33<04:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.624:  44%|████▍     | 57/130 [2:38:37<04:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.898:  45%|████▍     | 58/130 [2:38:40<04:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.637:  45%|████▌     | 59/130 [2:38:44<04:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.901:  46%|████▌     | 60/130 [2:38:47<04:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.890:  47%|████▋     | 61/130 [2:38:51<04:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.853:  48%|████▊     | 62/130 [2:38:55<04:06,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.777:  48%|████▊     | 63/130 [2:38:58<04:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.928:  49%|████▉     | 64/130 [2:39:02<03:59,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.372:  50%|█████     | 65/130 [2:39:06<03:56,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.671:  51%|█████     | 66/130 [2:39:09<03:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.828:  52%|█████▏    | 67/130 [2:39:13<03:48,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.572:  52%|█████▏    | 68/130 [2:39:16<03:44,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.728:  53%|█████▎    | 69/130 [2:39:20<03:40,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.777:  54%|█████▍    | 70/130 [2:39:24<03:37,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.798:  55%|█████▍    | 71/130 [2:39:27<03:33,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.809:  55%|█████▌    | 72/130 [2:39:31<03:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.674:  56%|█████▌    | 73/130 [2:39:35<03:26,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.048:  57%|█████▋    | 74/130 [2:39:38<03:22,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.497:  58%|█████▊    | 75/130 [2:39:42<03:19,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.856:  58%|█████▊    | 76/130 [2:39:45<03:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.742:  59%|█████▉    | 77/130 [2:39:49<03:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.603:  60%|██████    | 78/130 [2:39:53<03:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.768:  61%|██████    | 79/130 [2:39:56<03:04,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.719:  62%|██████▏   | 80/130 [2:40:00<03:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.667:  62%|██████▏   | 81/130 [2:40:04<02:57,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.804:  63%|██████▎   | 82/130 [2:40:07<02:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.751:  64%|██████▍   | 83/130 [2:40:11<02:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.806:  65%|██████▍   | 84/130 [2:40:14<02:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.624:  65%|██████▌   | 85/130 [2:40:18<02:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  66%|██████▌   | 86/130 [2:40:22<02:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.405:  67%|██████▋   | 87/130 [2:40:25<02:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.868:  68%|██████▊   | 88/130 [2:40:29<02:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.716:  68%|██████▊   | 89/130 [2:40:33<02:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.944:  69%|██████▉   | 90/130 [2:40:36<02:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.901:  70%|███████   | 91/130 [2:40:40<02:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.638:  71%|███████   | 92/130 [2:40:44<02:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.020:  72%|███████▏  | 93/130 [2:40:47<02:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.688:  72%|███████▏  | 94/130 [2:40:51<02:10,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.961:  73%|███████▎  | 95/130 [2:40:54<02:06,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.857:  74%|███████▍  | 96/130 [2:40:58<02:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.002:  75%|███████▍  | 97/130 [2:41:02<01:59,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.487:  75%|███████▌  | 98/130 [2:41:05<01:56,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.800:  76%|███████▌  | 99/130 [2:41:09<01:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.778:  77%|███████▋  | 100/130 [2:41:13<01:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.061:  78%|███████▊  | 101/130 [2:41:16<01:45,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.841:  78%|███████▊  | 102/130 [2:41:20<01:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.853:  79%|███████▉  | 103/130 [2:41:23<01:38,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.876:  80%|████████  | 104/130 [2:41:27<01:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.879:  81%|████████  | 105/130 [2:41:31<01:30,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.837:  82%|████████▏ | 106/130 [2:41:34<01:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.068:  82%|████████▏ | 107/130 [2:41:38<01:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.728:  83%|████████▎ | 108/130 [2:41:42<01:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.177:  84%|████████▍ | 109/130 [2:41:45<01:16,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.840:  85%|████████▍ | 110/130 [2:41:49<01:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.676:  85%|████████▌ | 111/130 [2:41:53<01:09,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.619:  86%|████████▌ | 112/130 [2:41:56<01:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.723:  87%|████████▋ | 113/130 [2:42:00<01:01,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.701:  88%|████████▊ | 114/130 [2:42:03<00:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.657:  88%|████████▊ | 115/130 [2:42:07<00:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.810:  89%|████████▉ | 116/130 [2:42:11<00:50,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.713:  90%|█████████ | 117/130 [2:42:14<00:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.878:  91%|█████████ | 118/130 [2:42:18<00:43,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  92%|█████████▏| 119/130 [2:42:22<00:39,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.701:  92%|█████████▏| 120/130 [2:42:25<00:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.910:  93%|█████████▎| 121/130 [2:42:29<00:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.564:  94%|█████████▍| 122/130 [2:42:33<00:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.586:  95%|█████████▍| 123/130 [2:42:36<00:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.537:  95%|█████████▌| 124/130 [2:42:40<00:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.607:  96%|█████████▌| 125/130 [2:42:43<00:18,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.611:  97%|█████████▋| 126/130 [2:42:47<00:14,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.685:  98%|█████████▊| 127/130 [2:42:51<00:10,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.781:  98%|█████████▊| 128/130 [2:42:54<00:07,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.457:  99%|█████████▉| 129/130 [2:42:58<00:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.062: 100%|██████████| 130/130 [2:43:01<00:00,  3.39s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:46:03<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.062: 100%|██████████| 130/130 [2:45:29<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 19 Age L1-loss: 15.226 ** Gender accuracy: 0.997 ** Race accuracy: 0.992 ** Avg loss: 1.631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:46:37<02:22,  1.26s/it]\n",
            "ITERATION - loss: 2.062: 100%|██████████| 130/130 [2:46:03<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 19 Age L1-loss: 15.123 ** Gender accuracy: 0.924 ** Race accuracy: 0.812 ** Avg loss: 6.024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.378:   1%|          | 1/130 [2:46:09<2:06:18, 58.75s/it]\u001b[A\n",
            "ITERATION - loss: 1.653:   2%|▏         | 2/130 [2:46:12<1:30:03, 42.22s/it]\u001b[A\n",
            "ITERATION - loss: 1.638:   2%|▏         | 3/130 [2:46:16<1:04:50, 30.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.831:   3%|▎         | 4/130 [2:46:20<47:19, 22.53s/it]  \u001b[A\n",
            "ITERATION - loss: 1.805:   4%|▍         | 5/130 [2:46:23<35:07, 16.86s/it]\u001b[A\n",
            "ITERATION - loss: 1.599:   5%|▍         | 6/130 [2:46:27<26:38, 12.89s/it]\u001b[A\n",
            "ITERATION - loss: 1.654:   5%|▌         | 7/130 [2:46:31<20:50, 10.17s/it]\u001b[A\n",
            "ITERATION - loss: 1.575:   6%|▌         | 8/130 [2:46:34<16:43,  8.22s/it]\u001b[A\n",
            "ITERATION - loss: 2.149:   7%|▋         | 9/130 [2:46:38<13:47,  6.84s/it]\u001b[A\n",
            "ITERATION - loss: 1.609:   8%|▊         | 10/130 [2:46:42<11:45,  5.88s/it]\u001b[A\n",
            "ITERATION - loss: 1.550:   8%|▊         | 11/130 [2:46:45<10:20,  5.21s/it]\u001b[A\n",
            "ITERATION - loss: 1.903:   9%|▉         | 12/130 [2:46:49<09:19,  4.74s/it]\u001b[A\n",
            "ITERATION - loss: 2.995:  10%|█         | 13/130 [2:46:52<08:35,  4.41s/it]\u001b[A\n",
            "ITERATION - loss: 1.746:  11%|█         | 14/130 [2:46:56<08:04,  4.17s/it]\u001b[A\n",
            "ITERATION - loss: 1.959:  12%|█▏        | 15/130 [2:47:00<07:40,  4.00s/it]\u001b[A\n",
            "ITERATION - loss: 1.689:  12%|█▏        | 16/130 [2:47:03<07:24,  3.90s/it]\u001b[A\n",
            "ITERATION - loss: 1.889:  13%|█▎        | 17/130 [2:47:07<07:10,  3.81s/it]\u001b[A\n",
            "ITERATION - loss: 2.856:  14%|█▍        | 18/130 [2:47:11<07:00,  3.76s/it]\u001b[A\n",
            "ITERATION - loss: 2.235:  15%|█▍        | 19/130 [2:47:14<06:52,  3.71s/it]\u001b[A\n",
            "ITERATION - loss: 2.326:  15%|█▌        | 20/130 [2:47:18<06:45,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.613:  16%|█▌        | 21/130 [2:47:21<06:39,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.569:  17%|█▋        | 22/130 [2:47:25<06:34,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.571:  18%|█▊        | 23/130 [2:47:29<06:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.866:  18%|█▊        | 24/130 [2:47:32<06:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.846:  19%|█▉        | 25/130 [2:47:36<06:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.668:  20%|██        | 26/130 [2:47:40<06:16,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.908:  21%|██        | 27/130 [2:47:43<06:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.686:  22%|██▏       | 28/130 [2:47:47<06:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.741:  22%|██▏       | 29/130 [2:47:50<06:06,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.660:  23%|██▎       | 30/130 [2:47:54<06:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.684:  24%|██▍       | 31/130 [2:47:58<05:59,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.183:  25%|██▍       | 32/130 [2:48:01<05:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.644:  25%|██▌       | 33/130 [2:48:05<05:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.668:  26%|██▌       | 34/130 [2:48:09<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.694:  27%|██▋       | 35/130 [2:48:12<05:44,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.061:  28%|██▊       | 36/130 [2:48:16<05:41,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.708:  28%|██▊       | 37/130 [2:48:20<05:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.877:  29%|██▉       | 38/130 [2:48:23<05:33,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.547:  30%|███       | 39/130 [2:48:27<05:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.879:  31%|███       | 40/130 [2:48:30<05:28,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.972:  32%|███▏      | 41/130 [2:48:34<05:24,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.739:  32%|███▏      | 42/130 [2:48:38<05:20,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.142:  33%|███▎      | 43/130 [2:48:41<05:17,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.610:  34%|███▍      | 44/130 [2:48:45<05:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.892:  35%|███▍      | 45/130 [2:48:49<05:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.789:  35%|███▌      | 46/130 [2:48:52<05:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.666:  36%|███▌      | 47/130 [2:48:56<05:02,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.764:  37%|███▋      | 48/130 [2:49:00<04:59,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.660:  38%|███▊      | 49/130 [2:49:03<04:55,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.732:  38%|███▊      | 50/130 [2:49:07<04:52,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.742:  39%|███▉      | 51/130 [2:49:11<04:48,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.736:  40%|████      | 52/130 [2:49:14<04:44,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.966:  41%|████      | 53/130 [2:49:18<04:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.663:  42%|████▏     | 54/130 [2:49:22<04:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.906:  42%|████▏     | 55/130 [2:49:25<04:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.752:  43%|████▎     | 56/130 [2:49:29<04:30,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.611:  44%|████▍     | 57/130 [2:49:32<04:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.471:  45%|████▍     | 58/130 [2:49:36<04:23,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.771:  45%|████▌     | 59/130 [2:49:40<04:19,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.674:  46%|████▌     | 60/130 [2:49:43<04:16,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.710:  47%|████▋     | 61/130 [2:49:47<04:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.435:  48%|████▊     | 62/130 [2:49:51<04:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.881:  48%|████▊     | 63/130 [2:49:54<04:03,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.002:  49%|████▉     | 64/130 [2:49:58<04:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.459:  50%|█████     | 65/130 [2:50:02<03:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.657:  51%|█████     | 66/130 [2:50:05<03:52,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.506:  52%|█████▏    | 67/130 [2:50:09<03:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.556:  52%|█████▏    | 68/130 [2:50:13<03:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.671:  53%|█████▎    | 69/130 [2:50:16<03:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.770:  54%|█████▍    | 70/130 [2:50:20<03:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.602:  55%|█████▍    | 71/130 [2:50:23<03:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.864:  55%|█████▌    | 72/130 [2:50:27<03:30,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.697:  56%|█████▌    | 73/130 [2:50:31<03:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.655:  57%|█████▋    | 74/130 [2:50:34<03:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.704:  58%|█████▊    | 75/130 [2:50:38<03:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.953:  58%|█████▊    | 76/130 [2:50:42<03:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.976:  59%|█████▉    | 77/130 [2:50:45<03:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.964:  60%|██████    | 78/130 [2:50:49<03:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.801:  61%|██████    | 79/130 [2:50:53<03:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  62%|██████▏   | 80/130 [2:50:56<03:02,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.052:  62%|██████▏   | 81/130 [2:51:00<02:58,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.662:  63%|██████▎   | 82/130 [2:51:03<02:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.809:  64%|██████▍   | 83/130 [2:51:07<02:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.530:  65%|██████▍   | 84/130 [2:51:11<02:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.523:  65%|██████▌   | 85/130 [2:51:14<02:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.649:  66%|██████▌   | 86/130 [2:51:18<02:39,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.000:  67%|██████▋   | 87/130 [2:51:22<02:37,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.078:  68%|██████▊   | 88/130 [2:51:25<02:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.788:  68%|██████▊   | 89/130 [2:51:29<02:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.461:  69%|██████▉   | 90/130 [2:51:33<02:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.661:  70%|███████   | 91/130 [2:51:36<02:22,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.656:  71%|███████   | 92/130 [2:51:40<02:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.597:  72%|███████▏  | 93/130 [2:51:44<02:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.758:  72%|███████▏  | 94/130 [2:51:47<02:10,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.765:  73%|███████▎  | 95/130 [2:51:51<02:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.880:  74%|███████▍  | 96/130 [2:51:54<02:03,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.688:  75%|███████▍  | 97/130 [2:51:58<02:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.810:  75%|███████▌  | 98/130 [2:52:02<01:56,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.635:  76%|███████▌  | 99/130 [2:52:05<01:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.688:  77%|███████▋  | 100/130 [2:52:09<01:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  78%|███████▊  | 101/130 [2:52:13<01:45,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.871:  78%|███████▊  | 102/130 [2:52:16<01:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.505:  79%|███████▉  | 103/130 [2:52:20<01:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.795:  80%|████████  | 104/130 [2:52:23<01:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.654:  81%|████████  | 105/130 [2:52:27<01:30,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.558:  82%|████████▏ | 106/130 [2:52:31<01:27,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.154:  82%|████████▏ | 107/130 [2:52:34<01:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.691:  83%|████████▎ | 108/130 [2:52:38<01:19,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.687:  84%|████████▍ | 109/130 [2:52:42<01:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.816:  85%|████████▍ | 110/130 [2:52:45<01:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.786:  85%|████████▌ | 111/130 [2:52:49<01:08,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.667:  86%|████████▌ | 112/130 [2:52:52<01:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.779:  87%|████████▋ | 113/130 [2:52:56<01:01,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.935:  88%|████████▊ | 114/130 [2:53:00<00:57,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.992:  88%|████████▊ | 115/130 [2:53:03<00:54,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.984:  89%|████████▉ | 116/130 [2:53:07<00:50,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.747:  90%|█████████ | 117/130 [2:53:11<00:47,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.036:  91%|█████████ | 118/130 [2:53:14<00:43,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.971:  92%|█████████▏| 119/130 [2:53:18<00:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.688:  92%|█████████▏| 120/130 [2:53:21<00:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.007:  93%|█████████▎| 121/130 [2:53:25<00:32,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.194:  94%|█████████▍| 122/130 [2:53:29<00:28,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.591:  95%|█████████▍| 123/130 [2:53:32<00:25,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.919:  95%|█████████▌| 124/130 [2:53:36<00:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.056:  96%|█████████▌| 125/130 [2:53:40<00:18,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.805:  97%|█████████▋| 126/130 [2:53:43<00:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.785:  98%|█████████▊| 127/130 [2:53:47<00:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.068:  98%|█████████▊| 128/130 [2:53:51<00:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.025:  99%|█████████▉| 129/130 [2:53:54<00:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.949: 100%|██████████| 130/130 [2:53:57<00:00,  3.39s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:56:59<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.949: 100%|██████████| 130/130 [2:56:25<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 20 Age L1-loss: 15.133 ** Gender accuracy: 0.995 ** Race accuracy: 0.974 ** Avg loss: 1.788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [2:57:34<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.949: 100%|██████████| 130/130 [2:56:59<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 20 Age L1-loss: 15.038 ** Gender accuracy: 0.918 ** Race accuracy: 0.792 ** Avg loss: 6.086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.803:   1%|          | 1/130 [2:57:21<2:16:31, 63.50s/it]\u001b[A\n",
            "ITERATION - loss: 1.604:   2%|▏         | 2/130 [2:57:24<1:37:09, 45.54s/it]\u001b[A\n",
            "ITERATION - loss: 1.662:   2%|▏         | 3/130 [2:57:28<1:09:47, 32.97s/it]\u001b[A\n",
            "ITERATION - loss: 1.700:   3%|▎         | 4/130 [2:57:32<50:44, 24.16s/it]  \u001b[A\n",
            "ITERATION - loss: 1.938:   4%|▍         | 5/130 [2:57:35<37:29, 18.00s/it]\u001b[A\n",
            "ITERATION - loss: 1.761:   5%|▍         | 6/130 [2:57:39<28:15, 13.68s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:   5%|▌         | 7/130 [2:57:42<21:51, 10.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.852:   6%|▌         | 8/130 [2:57:46<17:22,  8.55s/it]\u001b[A\n",
            "ITERATION - loss: 1.700:   7%|▋         | 9/130 [2:57:50<14:15,  7.07s/it]\u001b[A\n",
            "ITERATION - loss: 1.672:   8%|▊         | 10/130 [2:57:53<12:03,  6.03s/it]\u001b[A\n",
            "ITERATION - loss: 1.597:   8%|▊         | 11/130 [2:57:57<10:32,  5.31s/it]\u001b[A\n",
            "ITERATION - loss: 1.547:   9%|▉         | 12/130 [2:58:01<09:26,  4.80s/it]\u001b[A\n",
            "ITERATION - loss: 1.841:  10%|█         | 13/130 [2:58:04<08:42,  4.46s/it]\u001b[A\n",
            "ITERATION - loss: 1.698:  11%|█         | 14/130 [2:58:08<08:08,  4.21s/it]\u001b[A\n",
            "ITERATION - loss: 1.899:  12%|█▏        | 15/130 [2:58:11<07:43,  4.03s/it]\u001b[A\n",
            "ITERATION - loss: 1.578:  12%|█▏        | 16/130 [2:58:15<07:24,  3.90s/it]\u001b[A\n",
            "ITERATION - loss: 1.917:  13%|█▎        | 17/130 [2:58:19<07:12,  3.82s/it]\u001b[A\n",
            "ITERATION - loss: 1.854:  14%|█▍        | 18/130 [2:58:22<07:00,  3.76s/it]\u001b[A\n",
            "ITERATION - loss: 1.759:  15%|█▍        | 19/130 [2:58:26<06:53,  3.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.897:  15%|█▌        | 20/130 [2:58:30<06:46,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.486:  16%|█▌        | 21/130 [2:58:33<06:41,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 1.548:  17%|█▋        | 22/130 [2:58:37<06:36,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.634:  18%|█▊        | 23/130 [2:58:40<06:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.851:  18%|█▊        | 24/130 [2:58:44<06:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.850:  19%|█▉        | 25/130 [2:58:48<06:24,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.763:  20%|██        | 26/130 [2:58:51<06:20,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.730:  21%|██        | 27/130 [2:58:55<06:16,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.723:  22%|██▏       | 28/130 [2:58:59<06:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.733:  22%|██▏       | 29/130 [2:59:02<06:09,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.629:  23%|██▎       | 30/130 [2:59:06<06:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.687:  24%|██▍       | 31/130 [2:59:10<06:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.717:  25%|██▍       | 32/130 [2:59:13<05:55,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.932:  25%|██▌       | 33/130 [2:59:17<05:51,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.933:  26%|██▌       | 34/130 [2:59:21<05:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.043:  27%|██▋       | 35/130 [2:59:24<05:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.639:  28%|██▊       | 36/130 [2:59:28<05:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.453:  28%|██▊       | 37/130 [2:59:31<05:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.518:  29%|██▉       | 38/130 [2:59:35<05:33,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.548:  30%|███       | 39/130 [2:59:39<05:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.676:  31%|███       | 40/130 [2:59:42<05:26,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.552:  32%|███▏      | 41/130 [2:59:46<05:22,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.626:  32%|███▏      | 42/130 [2:59:50<05:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.468:  33%|███▎      | 43/130 [2:59:53<05:15,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.659:  34%|███▍      | 44/130 [2:59:57<05:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.537:  35%|███▍      | 45/130 [3:00:00<05:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.672:  35%|███▌      | 46/130 [3:00:04<05:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.629:  36%|███▌      | 47/130 [3:00:08<05:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.647:  37%|███▋      | 48/130 [3:00:11<04:57,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.848:  38%|███▊      | 49/130 [3:00:15<04:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.714:  38%|███▊      | 50/130 [3:00:19<04:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.762:  39%|███▉      | 51/130 [3:00:22<04:46,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.814:  40%|████      | 52/130 [3:00:26<04:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.656:  41%|████      | 53/130 [3:00:30<04:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.851:  42%|████▏     | 54/130 [3:00:33<04:35,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.646:  42%|████▏     | 55/130 [3:00:37<04:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.853:  43%|████▎     | 56/130 [3:00:40<04:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.713:  44%|████▍     | 57/130 [3:00:44<04:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.549:  45%|████▍     | 58/130 [3:00:48<04:20,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.813:  45%|████▌     | 59/130 [3:00:51<04:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.747:  46%|████▌     | 60/130 [3:00:55<04:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.972:  47%|████▋     | 61/130 [3:00:59<04:10,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.662:  48%|████▊     | 62/130 [3:01:02<04:06,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.799:  48%|████▊     | 63/130 [3:01:06<04:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.747:  49%|████▉     | 64/130 [3:01:10<04:00,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.697:  50%|█████     | 65/130 [3:01:13<03:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.780:  51%|█████     | 66/130 [3:01:17<03:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.887:  52%|█████▏    | 67/130 [3:01:20<03:48,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.583:  52%|█████▏    | 68/130 [3:01:24<03:44,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.867:  53%|█████▎    | 69/130 [3:01:28<03:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.016:  54%|█████▍    | 70/130 [3:01:31<03:37,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.861:  55%|█████▍    | 71/130 [3:01:35<03:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.805:  55%|█████▌    | 72/130 [3:01:39<03:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.651:  56%|█████▌    | 73/130 [3:01:42<03:26,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.072:  57%|█████▋    | 74/130 [3:01:46<03:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.449:  58%|█████▊    | 75/130 [3:01:49<03:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.807:  58%|█████▊    | 76/130 [3:01:53<03:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.110:  59%|█████▉    | 77/130 [3:01:57<03:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.056:  60%|██████    | 78/130 [3:02:00<03:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.806:  61%|██████    | 79/130 [3:02:04<03:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.650:  62%|██████▏   | 80/130 [3:02:08<03:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.695:  62%|██████▏   | 81/130 [3:02:11<02:57,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.722:  63%|██████▎   | 82/130 [3:02:15<02:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.721:  64%|██████▍   | 83/130 [3:02:18<02:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.597:  65%|██████▍   | 84/130 [3:02:22<02:47,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.852:  65%|██████▌   | 85/130 [3:02:26<02:43,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.031:  66%|██████▌   | 86/130 [3:02:29<02:39,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.878:  67%|██████▋   | 87/130 [3:02:33<02:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  68%|██████▊   | 88/130 [3:02:37<02:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.830:  68%|██████▊   | 89/130 [3:02:40<02:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.742:  69%|██████▉   | 90/130 [3:02:44<02:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.828:  70%|███████   | 91/130 [3:02:48<02:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.688:  71%|███████   | 92/130 [3:02:51<02:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.619:  72%|███████▏  | 93/130 [3:02:55<02:14,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.345:  72%|███████▏  | 94/130 [3:02:58<02:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.953:  73%|███████▎  | 95/130 [3:03:02<02:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.098:  74%|███████▍  | 96/130 [3:03:06<02:03,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.023:  75%|███████▍  | 97/130 [3:03:09<01:59,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.665:  75%|███████▌  | 98/130 [3:03:13<01:56,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.985:  76%|███████▌  | 99/130 [3:03:17<01:52,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.898:  77%|███████▋  | 100/130 [3:03:20<01:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.645:  78%|███████▊  | 101/130 [3:03:24<01:45,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.870:  78%|███████▊  | 102/130 [3:03:27<01:41,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.697:  79%|███████▉  | 103/130 [3:03:31<01:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.900:  80%|████████  | 104/130 [3:03:35<01:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.989:  81%|████████  | 105/130 [3:03:38<01:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.912:  82%|████████▏ | 106/130 [3:03:42<01:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.908:  82%|████████▏ | 107/130 [3:03:46<01:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.817:  83%|████████▎ | 108/130 [3:03:49<01:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.897:  84%|████████▍ | 109/130 [3:03:53<01:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.682:  85%|████████▍ | 110/130 [3:03:57<01:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.782:  85%|████████▌ | 111/130 [3:04:00<01:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.935:  86%|████████▌ | 112/130 [3:04:04<01:05,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.453:  87%|████████▋ | 113/130 [3:04:07<01:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.422:  88%|████████▊ | 114/130 [3:04:11<00:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.667:  88%|████████▊ | 115/130 [3:04:15<00:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.879:  89%|████████▉ | 116/130 [3:04:18<00:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.954:  90%|█████████ | 117/130 [3:04:22<00:47,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.948:  91%|█████████ | 118/130 [3:04:26<00:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.364:  92%|█████████▏| 119/130 [3:04:29<00:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.614:  92%|█████████▏| 120/130 [3:04:33<00:36,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.691:  93%|█████████▎| 121/130 [3:04:36<00:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.465:  94%|█████████▍| 122/130 [3:04:40<00:29,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.676:  95%|█████████▍| 123/130 [3:04:44<00:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.995:  95%|█████████▌| 124/130 [3:04:47<00:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.942:  96%|█████████▌| 125/130 [3:04:51<00:18,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.802:  97%|█████████▋| 126/130 [3:04:55<00:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.731:  98%|█████████▊| 127/130 [3:04:58<00:10,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.586:  98%|█████████▊| 128/130 [3:05:02<00:07,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.745:  99%|█████████▉| 129/130 [3:05:05<00:03,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.541: 100%|██████████| 130/130 [3:05:08<00:00,  3.39s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [3:08:11<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.541: 100%|██████████| 130/130 [3:07:36<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 21 Age L1-loss: 15.258 ** Gender accuracy: 0.993 ** Race accuracy: 0.988 ** Avg loss: 1.704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [3:08:44<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.541: 100%|██████████| 130/130 [3:08:10<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 21 Age L1-loss: 15.139 ** Gender accuracy: 0.920 ** Race accuracy: 0.814 ** Avg loss: 6.430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.540:   1%|          | 1/130 [3:08:17<2:06:32, 58.86s/it]\u001b[A\n",
            "ITERATION - loss: 1.478:   2%|▏         | 2/130 [3:08:20<1:30:12, 42.29s/it]\u001b[A\n",
            "ITERATION - loss: 2.188:   2%|▏         | 3/130 [3:08:24<1:04:57, 30.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.778:   3%|▎         | 4/130 [3:08:27<47:23, 22.56s/it]  \u001b[A\n",
            "ITERATION - loss: 1.819:   4%|▍         | 5/130 [3:08:31<35:09, 16.88s/it]\u001b[A\n",
            "ITERATION - loss: 1.633:   5%|▍         | 6/130 [3:08:35<26:40, 12.90s/it]\u001b[A\n",
            "ITERATION - loss: 1.526:   5%|▌         | 7/130 [3:08:38<20:44, 10.12s/it]\u001b[A\n",
            "ITERATION - loss: 1.667:   6%|▌         | 8/130 [3:08:42<16:36,  8.17s/it]\u001b[A\n",
            "ITERATION - loss: 1.632:   7%|▋         | 9/130 [3:08:46<13:43,  6.81s/it]\u001b[A\n",
            "ITERATION - loss: 1.620:   8%|▊         | 10/130 [3:08:49<11:42,  5.86s/it]\u001b[A\n",
            "ITERATION - loss: 1.987:   8%|▊         | 11/130 [3:08:53<10:16,  5.18s/it]\u001b[A\n",
            "ITERATION - loss: 1.607:   9%|▉         | 12/130 [3:08:56<09:15,  4.71s/it]\u001b[A\n",
            "ITERATION - loss: 1.537:  10%|█         | 13/130 [3:09:00<08:33,  4.39s/it]\u001b[A\n",
            "ITERATION - loss: 1.902:  11%|█         | 14/130 [3:09:04<08:03,  4.16s/it]\u001b[A\n",
            "ITERATION - loss: 1.618:  12%|█▏        | 15/130 [3:09:07<07:41,  4.01s/it]\u001b[A\n",
            "ITERATION - loss: 1.428:  12%|█▏        | 16/130 [3:09:11<07:23,  3.89s/it]\u001b[A\n",
            "ITERATION - loss: 1.508:  13%|█▎        | 17/130 [3:09:15<07:13,  3.84s/it]\u001b[A\n",
            "ITERATION - loss: 1.590:  14%|█▍        | 18/130 [3:09:18<07:06,  3.81s/it]\u001b[A\n",
            "ITERATION - loss: 1.873:  15%|█▍        | 19/130 [3:09:22<06:56,  3.75s/it]\u001b[A\n",
            "ITERATION - loss: 1.561:  15%|█▌        | 20/130 [3:09:26<06:48,  3.71s/it]\u001b[A\n",
            "ITERATION - loss: 1.899:  16%|█▌        | 21/130 [3:09:29<06:42,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.766:  17%|█▋        | 22/130 [3:09:33<06:36,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.665:  18%|█▊        | 23/130 [3:09:37<06:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.612:  18%|█▊        | 24/130 [3:09:40<06:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.672:  19%|█▉        | 25/130 [3:09:44<06:22,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.697:  20%|██        | 26/130 [3:09:47<06:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.707:  21%|██        | 27/130 [3:09:51<06:13,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.478:  22%|██▏       | 28/130 [3:09:55<06:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.514:  22%|██▏       | 29/130 [3:09:58<06:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.640:  23%|██▎       | 30/130 [3:10:02<06:04,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.763:  24%|██▍       | 31/130 [3:10:06<06:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.873:  25%|██▍       | 32/130 [3:10:09<05:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.697:  25%|██▌       | 33/130 [3:10:13<05:52,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.710:  26%|██▌       | 34/130 [3:10:17<05:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.383:  27%|██▋       | 35/130 [3:10:20<05:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.776:  28%|██▊       | 36/130 [3:10:24<05:42,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.506:  28%|██▊       | 37/130 [3:10:27<05:38,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.536:  29%|██▉       | 38/130 [3:10:31<05:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  30%|███       | 39/130 [3:10:35<05:29,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.773:  31%|███       | 40/130 [3:10:38<05:25,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.000:  32%|███▏      | 41/130 [3:10:42<05:22,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.416:  32%|███▏      | 42/130 [3:10:46<05:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.528:  33%|███▎      | 43/130 [3:10:49<05:15,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.843:  34%|███▍      | 44/130 [3:10:53<05:12,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 2.050:  35%|███▍      | 45/130 [3:10:56<05:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.646:  35%|███▌      | 46/130 [3:11:00<05:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.546:  36%|███▌      | 47/130 [3:11:04<05:01,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.650:  37%|███▋      | 48/130 [3:11:07<04:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.628:  38%|███▊      | 49/130 [3:11:11<04:55,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.743:  38%|███▊      | 50/130 [3:11:15<04:51,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.587:  39%|███▉      | 51/130 [3:11:18<04:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.637:  40%|████      | 52/130 [3:11:22<04:44,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.498:  41%|████      | 53/130 [3:11:26<04:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.468:  42%|████▏     | 54/130 [3:11:29<04:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.510:  42%|████▏     | 55/130 [3:11:33<04:33,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.131:  43%|████▎     | 56/130 [3:11:37<04:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.541:  44%|████▍     | 57/130 [3:11:40<04:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.723:  45%|████▍     | 58/130 [3:11:44<04:22,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.919:  45%|████▌     | 59/130 [3:11:47<04:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.970:  46%|████▌     | 60/130 [3:11:51<04:13,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.715:  47%|████▋     | 61/130 [3:11:55<04:09,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.909:  48%|████▊     | 62/130 [3:11:58<04:06,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.882:  48%|████▊     | 63/130 [3:12:02<04:02,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.797:  49%|████▉     | 64/130 [3:12:06<04:00,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.611:  50%|█████     | 65/130 [3:12:09<03:57,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.726:  51%|█████     | 66/130 [3:12:13<03:54,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.708:  52%|█████▏    | 67/130 [3:12:17<03:50,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.832:  52%|█████▏    | 68/130 [3:12:20<03:46,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.729:  53%|█████▎    | 69/130 [3:12:24<03:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.830:  54%|█████▍    | 70/130 [3:12:27<03:38,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.528:  55%|█████▍    | 71/130 [3:12:31<03:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.729:  55%|█████▌    | 72/130 [3:12:35<03:31,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.805:  56%|█████▌    | 73/130 [3:12:38<03:28,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  57%|█████▋    | 74/130 [3:12:42<03:25,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.584:  58%|█████▊    | 75/130 [3:12:46<03:20,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.612:  58%|█████▊    | 76/130 [3:12:49<03:17,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.727:  59%|█████▉    | 77/130 [3:12:53<03:13,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 2.026:  60%|██████    | 78/130 [3:12:57<03:09,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.635:  61%|██████    | 79/130 [3:13:00<03:05,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.664:  62%|██████▏   | 80/130 [3:13:04<03:02,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.761:  62%|██████▏   | 81/130 [3:13:08<02:58,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.794:  63%|██████▎   | 82/130 [3:13:11<02:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.914:  64%|██████▍   | 83/130 [3:13:15<02:50,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.582:  65%|██████▍   | 84/130 [3:13:19<02:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.744:  65%|██████▌   | 85/130 [3:13:22<02:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.743:  66%|██████▌   | 86/130 [3:13:26<02:40,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.950:  67%|██████▋   | 87/130 [3:13:29<02:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.064:  68%|██████▊   | 88/130 [3:13:33<02:33,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.850:  68%|██████▊   | 89/130 [3:13:37<02:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.561:  69%|██████▉   | 90/130 [3:13:40<02:26,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.694:  70%|███████   | 91/130 [3:13:44<02:22,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.603:  71%|███████   | 92/130 [3:13:48<02:18,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.690:  72%|███████▏  | 93/130 [3:13:51<02:15,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.775:  72%|███████▏  | 94/130 [3:13:55<02:12,  3.67s/it]\u001b[A\n",
            "ITERATION - loss: 1.606:  73%|███████▎  | 95/130 [3:13:59<02:07,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.913:  74%|███████▍  | 96/130 [3:14:02<02:03,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.555:  75%|███████▍  | 97/130 [3:14:06<02:00,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.794:  75%|███████▌  | 98/130 [3:14:10<01:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.720:  76%|███████▌  | 99/130 [3:14:13<01:52,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.690:  77%|███████▋  | 100/130 [3:14:17<01:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.921:  78%|███████▊  | 101/130 [3:14:21<01:45,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.406:  78%|███████▊  | 102/130 [3:14:24<01:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.974:  79%|███████▉  | 103/130 [3:14:28<01:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.683:  80%|████████  | 104/130 [3:14:31<01:34,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.931:  81%|████████  | 105/130 [3:14:35<01:31,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.519:  82%|████████▏ | 106/130 [3:14:39<01:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.825:  82%|████████▏ | 107/130 [3:14:42<01:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.654:  83%|████████▎ | 108/130 [3:14:46<01:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.575:  84%|████████▍ | 109/130 [3:14:50<01:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.594:  85%|████████▍ | 110/130 [3:14:53<01:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.689:  85%|████████▌ | 111/130 [3:14:57<01:09,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.070:  86%|████████▌ | 112/130 [3:15:01<01:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.731:  87%|████████▋ | 113/130 [3:15:04<01:01,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.689:  88%|████████▊ | 114/130 [3:15:08<00:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.691:  88%|████████▊ | 115/130 [3:15:12<00:54,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.595:  89%|████████▉ | 116/130 [3:15:15<00:51,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.746:  90%|█████████ | 117/130 [3:15:19<00:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.875:  91%|█████████ | 118/130 [3:15:22<00:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.499:  92%|█████████▏| 119/130 [3:15:26<00:40,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.977:  92%|█████████▏| 120/130 [3:15:30<00:36,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.780:  93%|█████████▎| 121/130 [3:15:33<00:32,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.672:  94%|█████████▍| 122/130 [3:15:37<00:29,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.599:  95%|█████████▍| 123/130 [3:15:41<00:25,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.680:  95%|█████████▌| 124/130 [3:15:44<00:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.626:  96%|█████████▌| 125/130 [3:15:48<00:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.786:  97%|█████████▋| 126/130 [3:15:52<00:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.660:  98%|█████████▊| 127/130 [3:15:55<00:10,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.548:  98%|█████████▊| 128/130 [3:15:59<00:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.534:  99%|█████████▉| 129/130 [3:16:02<00:03,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.426: 100%|██████████| 130/130 [3:16:05<00:00,  3.39s/it]\u001b[A\n",
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [3:19:08<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.426: 100%|██████████| 130/130 [3:18:34<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch: 22 Age L1-loss: 15.827 ** Gender accuracy: 0.995 ** Race accuracy: 0.993 ** Avg loss: 1.701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 8.544:  13%|█▎        | 17/130 [3:19:42<02:22,  1.26s/it]\n",
            "ITERATION - loss: 1.426: 100%|██████████| 130/130 [3:19:08<00:00,  3.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 22 Age L1-loss: 15.673 ** Gender accuracy: 0.920 ** Race accuracy: 0.811 ** Avg loss: 5.796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ITERATION - loss: 1.602:   1%|          | 1/130 [3:19:14<2:06:45, 58.96s/it]\u001b[A\n",
            "ITERATION - loss: 2.016:   2%|▏         | 2/130 [3:19:18<1:30:22, 42.36s/it]\u001b[A\n",
            "ITERATION - loss: 1.480:   2%|▏         | 3/130 [3:19:21<1:05:04, 30.74s/it]\u001b[A\n",
            "ITERATION - loss: 1.579:   3%|▎         | 4/130 [3:19:25<47:28, 22.61s/it]  \u001b[A\n",
            "ITERATION - loss: 1.531:   4%|▍         | 5/130 [3:19:28<35:14, 16.91s/it]\u001b[A\n",
            "ITERATION - loss: 1.674:   5%|▍         | 6/130 [3:19:32<26:43, 12.93s/it]\u001b[A\n",
            "ITERATION - loss: 1.848:   5%|▌         | 7/130 [3:19:36<20:46, 10.13s/it]\u001b[A\n",
            "ITERATION - loss: 1.644:   6%|▌         | 8/130 [3:19:39<16:37,  8.18s/it]\u001b[A\n",
            "ITERATION - loss: 1.875:   7%|▋         | 9/130 [3:19:43<13:45,  6.82s/it]\u001b[A\n",
            "ITERATION - loss: 1.652:   8%|▊         | 10/130 [3:19:47<11:42,  5.86s/it]\u001b[A\n",
            "ITERATION - loss: 1.600:   8%|▊         | 11/130 [3:19:50<10:16,  5.18s/it]\u001b[A\n",
            "ITERATION - loss: 1.648:   9%|▉         | 12/130 [3:19:54<09:16,  4.71s/it]\u001b[A\n",
            "ITERATION - loss: 1.621:  10%|█         | 13/130 [3:19:57<08:33,  4.39s/it]\u001b[A\n",
            "ITERATION - loss: 1.796:  11%|█         | 14/130 [3:20:01<08:02,  4.16s/it]\u001b[A\n",
            "ITERATION - loss: 1.634:  12%|█▏        | 15/130 [3:20:05<07:39,  3.99s/it]\u001b[A\n",
            "ITERATION - loss: 1.584:  12%|█▏        | 16/130 [3:20:08<07:22,  3.88s/it]\u001b[A\n",
            "ITERATION - loss: 1.553:  13%|█▎        | 17/130 [3:20:12<07:10,  3.81s/it]\u001b[A\n",
            "ITERATION - loss: 1.507:  14%|█▍        | 18/130 [3:20:16<07:00,  3.75s/it]\u001b[A\n",
            "ITERATION - loss: 1.858:  15%|█▍        | 19/130 [3:20:19<06:52,  3.72s/it]\u001b[A\n",
            "ITERATION - loss: 1.756:  15%|█▌        | 20/130 [3:20:23<06:46,  3.69s/it]\u001b[A\n",
            "ITERATION - loss: 1.677:  16%|█▌        | 21/130 [3:20:26<06:40,  3.68s/it]\u001b[A\n",
            "ITERATION - loss: 1.581:  17%|█▋        | 22/130 [3:20:30<06:35,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.518:  18%|█▊        | 23/130 [3:20:34<06:31,  3.66s/it]\u001b[A\n",
            "ITERATION - loss: 1.512:  18%|█▊        | 24/130 [3:20:37<06:27,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.635:  19%|█▉        | 25/130 [3:20:41<06:23,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.602:  20%|██        | 26/130 [3:20:45<06:19,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.585:  21%|██        | 27/130 [3:20:48<06:15,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.745:  22%|██▏       | 28/130 [3:20:52<06:12,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.512:  22%|██▏       | 29/130 [3:20:56<06:08,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.560:  23%|██▎       | 30/130 [3:20:59<06:04,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.685:  24%|██▍       | 31/130 [3:21:03<06:01,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.798:  25%|██▍       | 32/130 [3:21:07<05:57,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.745:  25%|██▌       | 33/130 [3:21:10<05:54,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.573:  26%|██▌       | 34/130 [3:21:14<05:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.845:  27%|██▋       | 35/130 [3:21:17<05:46,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.742:  28%|██▊       | 36/130 [3:21:21<05:42,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.778:  28%|██▊       | 37/130 [3:21:25<05:39,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.836:  29%|██▉       | 38/130 [3:21:28<05:35,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.831:  30%|███       | 39/130 [3:21:32<05:31,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.601:  31%|███       | 40/130 [3:21:36<05:28,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.381:  32%|███▏      | 41/130 [3:21:39<05:24,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.548:  32%|███▏      | 42/130 [3:21:43<05:20,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.957:  33%|███▎      | 43/130 [3:21:47<05:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.709:  34%|███▍      | 44/130 [3:21:50<05:13,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.640:  35%|███▍      | 45/130 [3:21:54<05:09,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.822:  35%|███▌      | 46/130 [3:21:58<05:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.733:  36%|███▌      | 47/130 [3:22:01<05:01,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.831:  37%|███▋      | 48/130 [3:22:05<04:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.550:  38%|███▊      | 49/130 [3:22:09<04:55,  3.65s/it]\u001b[A\n",
            "ITERATION - loss: 1.696:  38%|███▊      | 50/130 [3:22:12<04:51,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.893:  39%|███▉      | 51/130 [3:22:16<04:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.697:  40%|████      | 52/130 [3:22:19<04:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.837:  41%|████      | 53/130 [3:22:23<04:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.750:  42%|████▏     | 54/130 [3:22:27<04:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.901:  42%|████▏     | 55/130 [3:22:30<04:32,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.598:  43%|████▎     | 56/130 [3:22:34<04:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.396:  44%|████▍     | 57/130 [3:22:38<04:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.534:  45%|████▍     | 58/130 [3:22:41<04:21,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.920:  45%|████▌     | 59/130 [3:22:45<04:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.672:  46%|████▌     | 60/130 [3:22:49<04:14,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.599:  47%|████▋     | 61/130 [3:22:52<04:11,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.870:  48%|████▊     | 62/130 [3:22:56<04:07,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.002:  48%|████▊     | 63/130 [3:22:59<04:03,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.994:  49%|████▉     | 64/130 [3:23:03<03:59,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.693:  50%|█████     | 65/130 [3:23:07<03:56,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.424:  51%|█████     | 66/130 [3:23:10<03:53,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.637:  52%|█████▏    | 67/130 [3:23:14<03:49,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.589:  52%|█████▏    | 68/130 [3:23:18<03:45,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.609:  53%|█████▎    | 69/130 [3:23:21<03:41,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.615:  54%|█████▍    | 70/130 [3:23:25<03:38,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.631:  55%|█████▍    | 71/130 [3:23:29<03:34,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.773:  55%|█████▌    | 72/130 [3:23:32<03:30,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.901:  56%|█████▌    | 73/130 [3:23:36<03:27,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.457:  57%|█████▋    | 74/130 [3:23:39<03:23,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.865:  58%|█████▊    | 75/130 [3:23:43<03:20,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.932:  58%|█████▊    | 76/130 [3:23:47<03:16,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.444:  59%|█████▉    | 77/130 [3:23:50<03:12,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.979:  60%|██████    | 78/130 [3:23:54<03:08,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.776:  61%|██████    | 79/130 [3:23:58<03:05,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.596:  62%|██████▏   | 80/130 [3:24:01<03:01,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.536:  62%|██████▏   | 81/130 [3:24:05<02:58,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.744:  63%|██████▎   | 82/130 [3:24:09<02:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.618:  64%|██████▍   | 83/130 [3:24:12<02:50,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.911:  65%|██████▍   | 84/130 [3:24:16<02:47,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.737:  65%|██████▌   | 85/130 [3:24:19<02:43,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.552:  66%|██████▌   | 86/130 [3:24:23<02:39,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.395:  67%|██████▋   | 87/130 [3:24:27<02:35,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.823:  68%|██████▊   | 88/130 [3:24:30<02:32,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.656:  68%|██████▊   | 89/130 [3:24:34<02:28,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.351:  69%|██████▉   | 90/130 [3:24:38<02:25,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.517:  70%|███████   | 91/130 [3:24:41<02:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.571:  71%|███████   | 92/130 [3:24:45<02:17,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.486:  72%|███████▏  | 93/130 [3:24:48<02:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.821:  72%|███████▏  | 94/130 [3:24:52<02:10,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.732:  73%|███████▎  | 95/130 [3:24:56<02:06,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.498:  74%|███████▍  | 96/130 [3:24:59<02:03,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.733:  75%|███████▍  | 97/130 [3:25:03<01:59,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.566:  75%|███████▌  | 98/130 [3:25:07<01:55,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.744:  76%|███████▌  | 99/130 [3:25:10<01:52,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.679:  77%|███████▋  | 100/130 [3:25:14<01:48,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.588:  78%|███████▊  | 101/130 [3:25:17<01:45,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.521:  78%|███████▊  | 102/130 [3:25:21<01:41,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.492:  79%|███████▉  | 103/130 [3:25:25<01:37,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.536:  80%|████████  | 104/130 [3:25:28<01:34,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.685:  81%|████████  | 105/130 [3:25:32<01:30,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.628:  82%|████████▏ | 106/130 [3:25:36<01:26,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.464:  82%|████████▏ | 107/130 [3:25:39<01:23,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.610:  83%|████████▎ | 108/130 [3:25:43<01:19,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.778:  84%|████████▍ | 109/130 [3:25:46<01:16,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.722:  85%|████████▍ | 110/130 [3:25:50<01:12,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.583:  85%|████████▌ | 111/130 [3:25:54<01:08,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 1.760:  86%|████████▌ | 112/130 [3:25:57<01:05,  3.62s/it]\u001b[A\n",
            "ITERATION - loss: 2.385:  87%|████████▋ | 113/130 [3:26:01<01:01,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.488:  88%|████████▊ | 114/130 [3:26:05<00:58,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.701:  88%|████████▊ | 115/130 [3:26:08<00:54,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.758:  89%|████████▉ | 116/130 [3:26:12<00:50,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.648:  90%|█████████ | 117/130 [3:26:15<00:47,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.740:  91%|█████████ | 118/130 [3:26:19<00:43,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.862:  92%|█████████▏| 119/130 [3:26:23<00:40,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.826:  92%|█████████▏| 120/130 [3:26:26<00:36,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.827:  93%|█████████▎| 121/130 [3:26:30<00:32,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.482:  94%|█████████▍| 122/130 [3:26:34<00:29,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.646:  95%|█████████▍| 123/130 [3:26:37<00:25,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 2.908:  95%|█████████▌| 124/130 [3:26:41<00:21,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.836:  96%|█████████▌| 125/130 [3:26:45<00:18,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.820:  97%|█████████▋| 126/130 [3:26:48<00:14,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.599:  98%|█████████▊| 127/130 [3:26:52<00:10,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.583:  98%|█████████▊| 128/130 [3:26:55<00:07,  3.63s/it]\u001b[A\n",
            "ITERATION - loss: 1.901:  99%|█████████▉| 129/130 [3:26:59<00:03,  3.64s/it]\u001b[A\n",
            "ITERATION - loss: 1.976: 100%|██████████| 130/130 [3:27:02<00:00,  3.40s/it]\u001b[A\n",
            "ITERATION - loss: 1.976: 100%|██████████| 130/130 [3:27:02<00:00,  3.40s/it]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_YbhF27yVNWF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "4afPqkJNVR2p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Evaluation\n",
        "\n",
        "Now that our 3 models are trained we can evaluate them on the test set"
      ]
    },
    {
      "metadata": {
        "id": "YKSDOR02Z2_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d27c6f7c-83e4-40df-ba42-46494b682e62"
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/resnet_adam\"\n",
        "!ls \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/sep_conv_adam\"\n",
        "!ls \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/vgg_adam\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'resnet_model_21_val_loss=4.275671.pth'\n",
            "'resnet_optimizer_21_val_loss=4.275671.pth'\n",
            "'sep_conv_adam_model_33_val_loss=4.714899.pth'\n",
            "'sep_conv_adam_optimizer_33_val_loss=4.714899.pth'\n",
            "'vgg_model_21_val_loss=4.139335.pth'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bWc-PZXUVe2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create test data loader\n",
        "test_loader = get_utk_dataloader(batch_size=256, data_dir=DEST_DIR, data_transforms=data_transforms, flag='test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Da6oP4rhZyv0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the three models\n",
        "\n",
        "# paths to the saved models\n",
        "path_sep_conv = \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/sep_conv_adam/sep_conv_adam_model_33_val_loss=4.714899.pth\"\n",
        "path_resnet = \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/resnet_adam/resnet_model_21_val_loss=4.275671.pth\"\n",
        "path_vgg = \"/content/gdrive/My Drive/DeepLearning/Face_detection/checkpoints/vgg_adam/vgg_model_21_val_loss=4.139335.pth\"\n",
        "\n",
        "cpu_or_gpu = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "sep_conv_model = SepConvModelMT()\n",
        "sep_conv_model.load_state_dict(torch.load(path_sep_conv, map_location=cpu_or_gpu))\n",
        "\n",
        "resnet_model = PretrainedMT(model_name='resnet')\n",
        "resnet_model.load_state_dict(torch.load(path_resnet, map_location=cpu_or_gpu))\n",
        "\n",
        "vgg_model = PretrainedMT(model_name='vgg')\n",
        "vgg_model.load_state_dict(torch.load(path_vgg, map_location=cpu_or_gpu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UWW3qOmwdy3T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate separable convolution model : "
      ]
    },
    {
      "metadata": {
        "id": "0ymWXjKqhAl0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from vision_utils.custom_torch_utils import plot_confusion_matrix\n",
        "from vision_utils.custom_torch_utils import processing_time\n",
        "from torchvision import transforms\n",
        "import time\n",
        "\n",
        "def processing_time(func):\n",
        "    \"\"\"\n",
        "    utility function to print execution time of a given function\n",
        "\n",
        "    :param func: a python function to track the execution time\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    def func_wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        func(*args, **kwargs)\n",
        "        seconds = time.time() - start\n",
        "        m, s = divmod(seconds, 60)\n",
        "        h, m = divmod(m, 60)\n",
        "        print(f\"The execution took {h} hours | {m} minutes | {s:.1f} seconds!\")\n",
        "    return func_wrapper\n",
        "\n",
        "\n",
        "@processing_time\n",
        "def evaluate_model(model, dataloader,\n",
        "                   title='Confusion matrix',\n",
        "                   labels_=[[0, 1], [0, 1, 2, 3, 4]],\n",
        "                   target_names=[['Male', 'Female'], ['White', 'Black', 'Asian', 'Indian', 'Unknown']],\n",
        "                   normalize=False):\n",
        "    \"\"\"\n",
        "        Function for evaluating a classification model by printing/plotting classification report and confusion matrix\n",
        "\n",
        "        :param model: a pytorch trained model\n",
        "        :param dataloader: a pytorch DataLoader object, or any object that yields pytorch tensors\n",
        "                ready to be used by the model\n",
        "        :param title: a string to be used as the plot title\n",
        "        :param labels_: list  of lists , each sublist is a list of integers (0 to number of classes - 1) representing\n",
        "                        labels for an output from the model\n",
        "        :param target_names: list of lists, each sublist is a list of strings or ints that describe the labels,\n",
        "                            and must have the same length as the corresponding labels it describes from `labels`list\n",
        "        :param normalize: whether to show the actual values or in % for the confusion matrix\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "    y_age = []\n",
        "    y_gender = []\n",
        "    y_race = []\n",
        "    y_pred_age = []\n",
        "    y_pred_gender = []\n",
        "    y_pred_race = []\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # first, get the predictions\n",
        "    model.eval()  # set model in evaluation mode\n",
        "    model = model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Iterate over data.\n",
        "        for inputs, age, gender, race in tqdm.tqdm(dataloader):\n",
        "            inputs = inputs.to(device, dtype=torch.float32)\n",
        "            y_age.append(age)\n",
        "            y_gender.append(gender)\n",
        "            y_race.append(race)\n",
        "\n",
        "            age_pred, gender_pred, race_pred = model(inputs)\n",
        "            y_pred_age.append(age_pred.to('cpu').numpy())\n",
        "            _, gender_pred = torch.max(gender_pred, 1)\n",
        "            _, race_pred = torch.max(race_pred, 1)\n",
        "            y_pred_gender.append(gender_pred.to('cpu').numpy())\n",
        "            y_pred_race.append(race_pred.to('cpu').numpy())\n",
        "\n",
        "    # print classification report\n",
        "    y_age, y_pred_age = np.concatenate(y_age), np.concatenate(y_pred_age)\n",
        "    y_gender, y_pred_gender = np.concatenate(y_gender), np.concatenate(y_pred_gender)\n",
        "    y_race, y_pred_race = np.concatenate(y_race), np.concatenate(y_pred_race)\n",
        "\n",
        "    print('----------------------- Age prediction -------------------------')\n",
        "    print(f\"Mean Absolute Error {np.abs(y_age - y_pred_age).mean():.4f}\")\n",
        "\n",
        "    print('----------------------- Gender prediction -------------------------')\n",
        "    plot_confusion_matrix(y_gender, y_pred_gender, title, labels_[0], target_names[0], normalize)\n",
        "\n",
        "    print('----------------------- Race prediction -------------------------')\n",
        "    plot_confusion_matrix(y_race, y_pred_race, title, labels_[1], target_names[1], normalize)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iUYupEgNZp14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1430
        },
        "outputId": "996456b1-60e5-4c39-90de-ad8408c094e5"
      },
      "cell_type": "code",
      "source": [
        "evaluate_model(sep_conv_model, test_loader, title='Evaluation on test set - Separable conv model')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:11<00:00,  1.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------- Age prediction -------------------------\n",
            "Mean Absolute Error 14.8096\n",
            "----------------------- Gender prediction -------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Male       0.93      0.92      0.92      1859\n",
            "      Female       0.91      0.92      0.92      1697\n",
            "\n",
            "   micro avg       0.92      0.92      0.92      3556\n",
            "   macro avg       0.92      0.92      0.92      3556\n",
            "weighted avg       0.92      0.92      0.92      3556\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHCCAYAAADywoA5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf/nA7jt4sg9SAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------- Race prediction -------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       White       0.80      0.88      0.84      1512\n",
            "       Black       0.91      0.70      0.79       679\n",
            "       Asian       0.78      0.85      0.81       515\n",
            "      Indian       0.55      0.74      0.63       596\n",
            "     Unknown       0.00      0.00      0.00       254\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      3556\n",
            "   macro avg       0.61      0.64      0.62      3556\n",
            "weighted avg       0.72      0.76      0.73      3556\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHCCAYAAADsC7CKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The execution took 0.0 hours | 0.0 minutes | 12.7 seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fKGkVc0wiZzR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate resnet model"
      ]
    },
    {
      "metadata": {
        "id": "XjwnrvI4icX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1631
        },
        "outputId": "86a97c47-29d5-4355-c159-b7b71e9a4cdc"
      },
      "cell_type": "code",
      "source": [
        "evaluate_model(resnet_model, test_loader, title='Evaluation on test set - Resnet conv model')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/14 [00:04<00:57,  4.45s/it]\u001b[A\n",
            " 14%|█▍        | 2/14 [00:05<00:40,  3.35s/it]\u001b[A\n",
            " 21%|██▏       | 3/14 [00:05<00:28,  2.57s/it]\u001b[A\n",
            " 29%|██▊       | 4/14 [00:06<00:20,  2.01s/it]\u001b[A\n",
            " 36%|███▌      | 5/14 [00:07<00:14,  1.60s/it]\u001b[A\n",
            " 43%|████▎     | 6/14 [00:07<00:10,  1.32s/it]\u001b[A\n",
            " 50%|█████     | 7/14 [00:08<00:07,  1.11s/it]\u001b[A\n",
            " 57%|█████▋    | 8/14 [00:09<00:05,  1.03it/s]\u001b[A\n",
            " 64%|██████▍   | 9/14 [00:09<00:04,  1.14it/s]\u001b[A\n",
            " 71%|███████▏  | 10/14 [00:10<00:03,  1.24it/s]\u001b[A\n",
            " 79%|███████▊  | 11/14 [00:11<00:02,  1.32it/s]\u001b[A\n",
            " 86%|████████▌ | 12/14 [00:11<00:01,  1.39it/s]\u001b[A\n",
            " 93%|█████████▎| 13/14 [00:12<00:00,  1.44it/s]\u001b[A\n",
            "100%|██████████| 14/14 [00:13<00:00,  1.51it/s]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------- Age prediction -------------------------\n",
            "Mean Absolute Error 14.8409\n",
            "----------------------- Gender prediction -------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Male       0.96      0.95      0.95      1859\n",
            "      Female       0.95      0.95      0.95      1697\n",
            "\n",
            "   micro avg       0.95      0.95      0.95      3556\n",
            "   macro avg       0.95      0.95      0.95      3556\n",
            "weighted avg       0.95      0.95      0.95      3556\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHCCAYAAADywoA5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbmZmljMO7mZmZjnz/45RfxxsGvg/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------- Race prediction -------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       White       0.85      0.96      0.90      1512\n",
            "       Black       0.92      0.88      0.90       679\n",
            "       Asian       0.91      0.90      0.91       515\n",
            "      Indian       0.89      0.79      0.83       596\n",
            "     Unknown       0.69      0.43      0.53       254\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      3556\n",
            "   macro avg       0.85      0.79      0.81      3556\n",
            "weighted avg       0.87      0.87      0.86      3556\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHCCAYAAADsC7CKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMsinlFJKFfX/Y2vVAiDpxiYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The execution took 0.0 hours | 0.0 minutes | 14.3 seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LEBDdKt6i_ed",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate VGG model"
      ]
    },
    {
      "metadata": {
        "id": "Km-8_WlBjEsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1631
        },
        "outputId": "f59b4a38-66d2-493e-955a-62aa418d8b1d"
      },
      "cell_type": "code",
      "source": [
        "evaluate_model(vgg_model, test_loader, title='Evaluation on test set - VGG model')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/14 [00:05<01:13,  5.66s/it]\u001b[A\n",
            " 14%|█▍        | 2/14 [00:07<00:55,  4.61s/it]\u001b[A\n",
            " 21%|██▏       | 3/14 [00:10<00:42,  3.88s/it]\u001b[A\n",
            " 29%|██▊       | 4/14 [00:12<00:33,  3.37s/it]\u001b[A\n",
            " 36%|███▌      | 5/14 [00:14<00:27,  3.02s/it]\u001b[A\n",
            " 43%|████▎     | 6/14 [00:16<00:22,  2.77s/it]\u001b[A\n",
            " 50%|█████     | 7/14 [00:18<00:18,  2.59s/it]\u001b[A\n",
            " 57%|█████▋    | 8/14 [00:20<00:14,  2.47s/it]\u001b[A\n",
            " 64%|██████▍   | 9/14 [00:23<00:11,  2.39s/it]\u001b[A\n",
            " 71%|███████▏  | 10/14 [00:25<00:09,  2.33s/it]\u001b[A\n",
            " 79%|███████▊  | 11/14 [00:27<00:06,  2.29s/it]\u001b[A\n",
            " 86%|████████▌ | 12/14 [00:29<00:04,  2.26s/it]\u001b[A\n",
            " 93%|█████████▎| 13/14 [00:31<00:02,  2.24s/it]\u001b[A\n",
            "100%|██████████| 14/14 [00:33<00:00,  2.19s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------- Age prediction -------------------------\n",
            "Mean Absolute Error 15.3566\n",
            "----------------------- Gender prediction -------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Male       0.98      0.93      0.96      1859\n",
            "      Female       0.93      0.98      0.95      1697\n",
            "\n",
            "   micro avg       0.95      0.95      0.95      3556\n",
            "   macro avg       0.95      0.96      0.95      3556\n",
            "weighted avg       0.96      0.95      0.95      3556\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHCCAYAAADywoA5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------- Race prediction -------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       White       0.93      0.92      0.93      1512\n",
            "       Black       0.84      0.96      0.90       679\n",
            "       Asian       0.91      0.94      0.93       515\n",
            "      Indian       0.83      0.90      0.86       596\n",
            "     Unknown       0.75      0.34      0.47       254\n",
            "\n",
            "   micro avg       0.88      0.88      0.88      3556\n",
            "   macro avg       0.85      0.81      0.82      3556\n",
            "weighted avg       0.88      0.88      0.88      3556\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHCCAYAAADsC7CKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqRB+X8NNCDGCTruUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The execution took 0.0 hours | 0.0 minutes | 35.3 seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}